"""Advanced RAG implementation with enhanced retrieval and processing."""

from typing import List, Dict, Any, Optional, Tuple
import time
import re
import streamlit as st
from langchain_core.documents import Document
from langchain_core.language_models import BaseLLM
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

from ..utils.vector_store import VectorStoreManager
from ..utils.llm_manager import LLMManager


class AdvancedRAG:
    """Advanced RAG implementation with pre-retrieval optimization and post-retrieval processing."""
    
    def __init__(self, vector_store_manager: VectorStoreManager, llm_manager: LLMManager):
        """Initialize Advanced RAG system.
        
        Args:
            vector_store_manager: Vector store manager instance
            llm_manager: LLM manager instance
        """
        self.vector_store_manager = vector_store_manager
        self.llm_manager = llm_manager
        self.name = "Advanced RAG"
        self.description = "í–¥ìƒëœ RAG ì‹œìŠ¤í…œ: ì¿¼ë¦¬ ìµœì í™” + ì¬ìˆœìœ„í™” + ì»¨í…ìŠ¤íŠ¸ ì••ì¶•"
        
    def preprocess_query(self, query: str) -> str:
        """Preprocess and optimize the query.
        
        Args:
            query: Original user query
            
        Returns:
            Optimized query
        """
        # Basic query cleaning
        query = re.sub(r'\s+', ' ', query.strip())
        
        # Add query expansion keywords (simple approach)
        expanded_terms = []
        
        # Add synonyms and related terms for common concepts
        if "AI" in query or "ì¸ê³µì§€ëŠ¥" in query:
            expanded_terms.extend(["machine learning", "ë”¥ëŸ¬ë‹", "neural network"])
        if "íŠ¸ë Œë“œ" in query or "trend" in query:
            expanded_terms.extend(["ë™í–¥", "ì „ë§", "ë¯¸ë˜"])
        if "ì—…ë¬´" in query or "work" in query:
            expanded_terms.extend(["ì§ì¥", "ë¹„ì¦ˆë‹ˆìŠ¤", "productivity"])
            
        if expanded_terms:
            expanded_query = f"{query} {' '.join(expanded_terms[:2])}"
            return expanded_query
            
        return query
    
    def retrieve_with_scores(self, query: str, k: int = 10) -> List[Tuple[Document, float]]:
        """Retrieve documents with similarity scores.
        
        Args:
            query: Search query
            k: Number of documents to retrieve (before reranking)
            
        Returns:
            List of (document, score) tuples
        """
        vector_store = self.vector_store_manager.get_vector_store()
        if vector_store is None:
            st.error("ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
            
        try:
            docs_with_scores = vector_store.similarity_search_with_score(query, k=k)
            return docs_with_scores
            
        except Exception as e:
            st.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def rerank_documents(self, query: str, docs_with_scores: List[Tuple[Document, float]], top_k: int = 5) -> List[Document]:
        """Rerank documents using TF-IDF similarity.
        
        Args:
            query: Original query
            docs_with_scores: Documents with initial scores
            top_k: Number of top documents to return after reranking
            
        Returns:
            Reranked documents
        """
        if not docs_with_scores:
            return []
            
        documents = [doc for doc, _ in docs_with_scores]
        
        # Prepare texts for TF-IDF
        texts = [doc.page_content for doc in documents]
        texts.append(query)  # Add query as the last document
        
        try:
            # Calculate TF-IDF similarity
            vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)
            tfidf_matrix = vectorizer.fit_transform(texts)
            
            # Calculate similarity between query and documents
            query_vector = tfidf_matrix[-1]  # Last vector is the query
            doc_vectors = tfidf_matrix[:-1]  # All vectors except the last one
            
            similarities = cosine_similarity(query_vector, doc_vectors).flatten()
            
            # Combine original scores with TF-IDF scores
            combined_scores = []
            for i, (doc, original_score) in enumerate(docs_with_scores):
                tfidf_score = similarities[i]
                # Weighted combination (70% TF-IDF, 30% original embedding score)
                combined_score = 0.7 * tfidf_score + 0.3 * (1 - original_score)  # Lower distance = higher score
                combined_scores.append((doc, combined_score))
            
            # Sort by combined score (descending)
            combined_scores.sort(key=lambda x: x[1], reverse=True)
            
            # Return top-k documents
            reranked_docs = [doc for doc, _ in combined_scores[:top_k]]
            return reranked_docs
            
        except Exception as e:
            st.warning(f"ì¬ìˆœìœ„í™” ì‹¤íŒ¨, ì›ë³¸ ìˆœì„œ ì‚¬ìš©: {str(e)}")
            return [doc for doc, _ in docs_with_scores[:top_k]]
    
    def compress_context(self, docs: List[Document], max_length: int = 3000) -> str:
        """Compress context by selecting most relevant sentences.
        
        Args:
            docs: List of documents
            max_length: Maximum context length
            
        Returns:
            Compressed context
        """
        if not docs:
            return ""
            
        # Combine all text
        full_context = "\n\n".join([doc.page_content for doc in docs])
        
        if len(full_context) <= max_length:
            return full_context
            
        # Split into sentences
        sentences = re.split(r'[.!?]\s+', full_context)
        
        # Simple sentence scoring based on length and content
        scored_sentences = []
        for sentence in sentences:
            if len(sentence.strip()) < 20:  # Skip very short sentences
                continue
                
            # Score based on keywords and length
            score = len(sentence) * 0.1
            if any(keyword in sentence.lower() for keyword in ['ai', 'ì¸ê³µì§€ëŠ¥', 'íŠ¸ë Œë“œ', 'ë¯¸ë˜', 'ì—…ë¬´']):
                score *= 1.5
                
            scored_sentences.append((sentence.strip(), score))
        
        # Sort by score and select top sentences
        scored_sentences.sort(key=lambda x: x[1], reverse=True)
        
        compressed_context = ""
        for sentence, _ in scored_sentences:
            if len(compressed_context) + len(sentence) <= max_length:
                compressed_context += sentence + ". "
            else:
                break
                
        return compressed_context.strip()
    
    def generate_with_reasoning(self, query: str, context: str) -> str:
        """Generate answer with explicit reasoning steps.
        
        Args:
            query: User query
            context: Retrieved and processed context
            
        Returns:
            Generated answer with reasoning
        """
        st.write("**ë‹µë³€ ìƒì„± ì¤‘ (ì¶”ë¡  ê¸°ë°˜)...**")
        answer_placeholder = st.empty()
        
        start_time = time.time()
        full_response = ""
        
        # Stream the response
        for chunk in self.llm_manager.generate_response_stream(
            prompt=query,
            context=context
        ):
            full_response += chunk
            answer_placeholder.markdown(full_response + "â–Œ")
        
        generation_time = time.time() - start_time
        answer_placeholder.markdown(full_response)
        
        st.success(f"ì¶”ë¡  ê¸°ë°˜ ë‹µë³€ ìƒì„± ì™„ë£Œ ({generation_time:.2f}ì´ˆ)")
        return full_response
    
    def query(self, question: str, k: int = 10, rerank_top_k: int = 5) -> Dict[str, Any]:
        """Process a query end-to-end with advanced techniques.
        
        Args:
            question: User question
            k: Number of documents to retrieve initially
            rerank_top_k: Number of documents after reranking
            
        Returns:
            Dictionary with results and metadata
        """
        start_time = time.time()
        
        # Step 1: Query preprocessing
        st.subheader("ğŸ”§ 1ë‹¨ê³„: ì¿¼ë¦¬ ì „ì²˜ë¦¬")
        optimized_query = self.preprocess_query(question)
        if optimized_query != question:
            st.info(f"ìµœì í™”ëœ ì¿¼ë¦¬: {optimized_query}")
        else:
            st.info("ì¿¼ë¦¬ ìµœì í™”: ë³€ê²½ì‚¬í•­ ì—†ìŒ")
        
        # Step 2: Retrieve with scores
        st.subheader("ğŸ” 2ë‹¨ê³„: ë¬¸ì„œ ê²€ìƒ‰")
        docs_with_scores = self.retrieve_with_scores(optimized_query, k=k)
        
        if not docs_with_scores:
            return {
                "question": question,
                "answer": "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "retrieved_docs": [],
                "total_time": time.time() - start_time,
                "rag_type": self.name
            }
        
        st.success(f"ì´ˆê¸° ê²€ìƒ‰: {len(docs_with_scores)}ê°œ ë¬¸ì„œ")
        
        # Step 3: Rerank documents
        st.subheader("ğŸ“Š 3ë‹¨ê³„: ë¬¸ì„œ ì¬ìˆœìœ„í™”")
        reranked_docs = self.rerank_documents(optimized_query, docs_with_scores, rerank_top_k)
        st.success(f"ì¬ìˆœìœ„í™” ì™„ë£Œ: ìƒìœ„ {len(reranked_docs)}ê°œ ë¬¸ì„œ ì„ íƒ")
        
        # Display reranked documents
        with st.expander(f"ì¬ìˆœìœ„í™”ëœ ë¬¸ì„œ ({len(reranked_docs)}ê°œ)"):
            for i, doc in enumerate(reranked_docs):
                st.write(f"**ë¬¸ì„œ {i+1}:**")
                st.write(f"ì¶œì²˜: {doc.metadata.get('source', 'Unknown')}")
                st.write(f"ë‚´ìš©: {doc.page_content[:200]}...")
                st.divider()
        
        # Step 4: Context compression
        st.subheader("ğŸ—œï¸ 4ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ì••ì¶•")
        compressed_context = self.compress_context(reranked_docs)
        compression_ratio = len(compressed_context) / sum(len(doc.page_content) for doc in reranked_docs) if reranked_docs else 0
        st.info(f"ì••ì¶•ë¥ : {compression_ratio:.2%}")
        
        # Step 5: Generate answer with reasoning
        st.subheader("ğŸ¤– 5ë‹¨ê³„: ë‹µë³€ ìƒì„±")
        answer = self.generate_with_reasoning(question, compressed_context)
        
        total_time = time.time() - start_time
        
        return {
            "question": question,
            "optimized_query": optimized_query,
            "answer": answer,
            "retrieved_docs": reranked_docs,
            "total_time": total_time,
            "rag_type": self.name,
            "metadata": {
                "initial_retrieved": len(docs_with_scores),
                "final_retrieved": len(reranked_docs),
                "compression_ratio": compression_ratio,
                "retrieval_method": "similarity_search + reranking",
                "generation_method": "reasoning-based"
            }
        }
    
    def get_system_info(self) -> Dict[str, Any]:
        """Get information about the Advanced RAG system.
        
        Returns:
            Dictionary with system information
        """
        return {
            "name": self.name,
            "description": self.description,
            "components": [
                "Query Preprocessor",
                "Vector Store (Enhanced Search)",
                "Document Reranker (TF-IDF)",
                "Context Compressor",
                "LLM (Reasoning-based Generation)"
            ],
            "features": [
                "ì¿¼ë¦¬ í™•ì¥ ë° ìµœì í™”",
                "TF-IDF ê¸°ë°˜ ë¬¸ì„œ ì¬ìˆœìœ„í™”",
                "ì»¨í…ìŠ¤íŠ¸ ì••ì¶•",
                "ì¶”ë¡  ê¸°ë°˜ ë‹µë³€ ìƒì„±"
            ],
            "advantages": [
                "í–¥ìƒëœ ê²€ìƒ‰ ì •í™•ë„",
                "íš¨ìœ¨ì ì¸ ì»¨í…ìŠ¤íŠ¸ í™œìš©",
                "ë” ì •í™•í•œ ë‹µë³€ ìƒì„±"
            ]
        } 