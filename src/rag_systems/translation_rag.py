"""Translation RAG system for translating documents from English to Korean."""

import streamlit as st
import re
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import tempfile
import os
from pathlib import Path

from ..utils.llm_manager import LLMManager
from ..utils.document_processor import DocumentProcessor
from langchain_core.messages import SystemMessage, HumanMessage


class TranslationRAG:
    """RAG system specialized for document translation."""
    
    def __init__(self, llm_manager: LLMManager):
        """Initialize the Translation RAG system.
        
        Args:
            llm_manager: LLM manager instance
        """
        self.llm_manager = llm_manager
        self.document_processor = DocumentProcessor()
        
    def split_into_paragraphs(self, text: str) -> List[str]:
        """Split text into logical paragraphs for translation.
        
        Args:
            text: Input text to split
            
        Returns:
            List of paragraphs
        """
        # Split by double newlines first (common paragraph separator)
        paragraphs = re.split(r'\n\s*\n', text.strip())
        
        # Further split very long paragraphs (over 1000 characters)
        final_paragraphs = []
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
                
            # If paragraph is too long, split by sentence groups
            if len(paragraph) > 1000:
                # Split into sentence groups of about 500-800 characters
                sentences = re.split(r'(?<=[.!?])\s+(?=[A-Z])', paragraph)
                current_chunk = ""
                
                for sentence in sentences:
                    if len(current_chunk + sentence) > 800 and current_chunk:
                        final_paragraphs.append(current_chunk.strip())
                        current_chunk = sentence
                    else:
                        current_chunk += (" " if current_chunk else "") + sentence
                
                if current_chunk.strip():
                    final_paragraphs.append(current_chunk.strip())
            else:
                final_paragraphs.append(paragraph)
        
        return final_paragraphs
    
    def translate_paragraph(self, paragraph: str, source_lang: str = "English", 
                           target_lang: str = "Korean", context: str = "") -> str:
        """Translate a paragraph with context awareness.
        
        Args:
            paragraph: Paragraph to translate
            source_lang: Source language
            target_lang: Target language
            context: Additional context for translation
            
        Returns:
            Translated paragraph
        """
        context_prompt = f"\n\nContext: {context}" if context else ""
        
        # Create explicit language mapping for better prompt clarity
        lang_map = {
            "English": "ì˜ì–´",
            "Korean": "í•œêµ­ì–´", 
            "Japanese": "ì¼ë³¸ì–´",
            "Chinese": "ì¤‘êµ­ì–´",
            "French": "í”„ë‘ìŠ¤ì–´",
            "German": "ë…ì¼ì–´",
            "Spanish": "ìŠ¤í˜ì¸ì–´",
            "Italian": "ì´íƒˆë¦¬ì•„ì–´",
            "Portuguese": "í¬ë¥´íˆ¬ê°ˆì–´",
            "Dutch": "ë„¤ëœë€ë“œì–´",
            "Russian": "ëŸ¬ì‹œì•„ì–´"
        }
        
        source_native = lang_map.get(source_lang, source_lang)
        target_native = lang_map.get(target_lang, target_lang)
        
        # Special handling for Korean translation
        korean_emphasis = ""
        if target_lang == "Korean":
            korean_emphasis = """
**ì¤‘ìš”í•œ í•œêµ­ì–´ ë²ˆì—­ ì§€ì¹¨:**
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë²ˆì—­í•˜ì„¸ìš”
- ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì„ì§€ ë§ˆì„¸ìš”
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ì¡´ëŒ“ë§ë³´ë‹¤ëŠ” í‰ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- í•œêµ­ì–´ ë§ì¶¤ë²•ê³¼ ë„ì–´ì“°ê¸°ë¥¼ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”
"""
        
        prompt = f"""You are a professional translator. Please translate the following text from {source_lang} to {target_lang}.

IMPORTANT TRANSLATION REQUIREMENTS:
- Source language: {source_lang} ({source_native})
- Target language: {target_lang} ({target_native})
- Translate ONLY to {target_lang}
- Do NOT include the original text
- Do NOT add explanations or comments
- Maintain the original meaning, tone, and style
- Ensure natural and fluent {target_lang} expression
- Keep technical terminology accurate
- Preserve formatting elements like lists, numbers, and special characters
- Maintain paragraph structure{korean_emphasis}{context_prompt}

Text to translate:
{paragraph}

Translated text in {target_lang}:"""
        
        try:
            translation = self.llm_manager.generate_response(prompt)
            return translation.strip()
        except Exception as e:
            st.error(f"ë²ˆì—­ ì˜¤ë¥˜ (ë‹¨ë½: {paragraph[:50]}...): {str(e)}")
            return f"[ë²ˆì—­ ì˜¤ë¥˜: {paragraph}]"
    
    def organize_and_format_translation(self, translated_text: str, 
                                      original_title: str = None,
                                      target_lang: str = "Korean") -> str:
        """Organize translated content and format as markdown.
        
        Args:
            translated_text: Translated content
            original_title: Original document title
            target_lang: Target language
            
        Returns:
            Markdown formatted translation
        """
        # Create language mapping for better prompt clarity
        lang_map = {
            "English": "ì˜ì–´",
            "Korean": "í•œêµ­ì–´", 
            "Japanese": "ì¼ë³¸ì–´",
            "Chinese": "ì¤‘êµ­ì–´",
            "French": "í”„ë‘ìŠ¤ì–´",
            "German": "ë…ì¼ì–´",
            "Spanish": "ìŠ¤í˜ì¸ì–´",
            "Italian": "ì´íƒˆë¦¬ì•„ì–´",
            "Portuguese": "í¬ë¥´íˆ¬ê°ˆì–´",
            "Dutch": "ë„¤ëœë€ë“œì–´",
            "Russian": "ëŸ¬ì‹œì•„ì–´"
        }
        
        target_native = lang_map.get(target_lang, target_lang)
        
        # Special handling for Korean formatting
        korean_emphasis = ""
        if target_lang == "Korean":
            korean_emphasis = """
**í•œêµ­ì–´ ì •ë¦¬ ì§€ì¹¨:**
- ëª¨ë“  ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìœ ì§€í•˜ì„¸ìš”
- í•œêµ­ì–´ ë§ì¶¤ë²•ê³¼ ë„ì–´ì“°ê¸°ë¥¼ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ì œëª©ê³¼ ì†Œì œëª©ë„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”
"""
        
        prompt = f"""Please organize and format the following {target_lang} ({target_native}) translated text into a well-structured markdown document.

IMPORTANT FORMATTING REQUIREMENTS:
- The text is already translated to {target_lang}
- Create appropriate headings (# ## ###) based on content structure
- Add proper paragraph breaks for readability
- Format lists, quotes, and code blocks appropriately
- Ensure logical flow and coherent organization
- Add a title if not present
- Maintain all original content while improving structure
- Keep all text in {target_lang}{korean_emphasis}

Original title: {original_title or 'ë¬¸ì„œ'}

{target_lang} text to organize:
{translated_text}

Please provide the organized markdown format in {target_lang}:"""
        
        try:
            organized_content = self.llm_manager.generate_response(prompt)
            return organized_content.strip()
        except Exception as e:
            st.error(f"ë‚´ìš© ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
            # Fallback: simple markdown formatting
            lines = translated_text.split('\n')
            markdown_lines = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    markdown_lines.append('')
                    continue
                    
                # Simple heuristic for headers
                if len(line) < 50 and not line.endswith('.') and not line.endswith(','):
                    markdown_lines.append(f"## {line}")
                else:
                    markdown_lines.append(line)
            
            return '\n'.join(markdown_lines)
    
    def split_into_sentences(self, text: str) -> List[str]:
        """Split text into sentences for translation.
        
        Args:
            text: Input text to split
            
        Returns:
            List of sentences
        """
        # Simple sentence splitting using regex
        # This handles common sentence endings with periods, exclamation marks, and question marks
        sentences = re.split(r'(?<=[.!?])\s+(?=[A-Z])', text.strip())
        
        # Clean up sentences and remove empty ones
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # Further split by newlines for better handling of lists and paragraphs
        final_sentences = []
        for sentence in sentences:
            if '\n' in sentence:
                # Split by newlines but keep the structure
                parts = sentence.split('\n')
                for part in parts:
                    if part.strip():
                        final_sentences.append(part.strip())
            else:
                final_sentences.append(sentence)
        
        return final_sentences
    
    def translate_sentence(self, sentence: str, source_lang: str = "English", 
                          target_lang: str = "Korean") -> str:
        """Translate a single sentence.
        
        Args:
            sentence: Sentence to translate
            source_lang: Source language
            target_lang: Target language
            
        Returns:
            Translated sentence
        """
        # Create explicit language mapping for better prompt clarity
        lang_map = {
            "English": "ì˜ì–´",
            "Korean": "í•œêµ­ì–´", 
            "Japanese": "ì¼ë³¸ì–´",
            "Chinese": "ì¤‘êµ­ì–´",
            "French": "í”„ë‘ìŠ¤ì–´",
            "German": "ë…ì¼ì–´",
            "Spanish": "ìŠ¤í˜ì¸ì–´",
            "Italian": "ì´íƒˆë¦¬ì•„ì–´",
            "Portuguese": "í¬ë¥´íˆ¬ê°ˆì–´",
            "Dutch": "ë„¤ëœë€ë“œì–´",
            "Russian": "ëŸ¬ì‹œì•„ì–´"
        }
        
        source_native = lang_map.get(source_lang, source_lang)
        target_native = lang_map.get(target_lang, target_lang)
        
        # Special handling for Korean translation
        korean_emphasis = ""
        if target_lang == "Korean":
            korean_emphasis = """
**ì¤‘ìš”í•œ í•œêµ­ì–´ ë²ˆì—­ ì§€ì¹¨:**
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë²ˆì—­í•˜ì„¸ìš”
- ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì„ì§€ ë§ˆì„¸ìš”
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ì¡´ëŒ“ë§ë³´ë‹¤ëŠ” í‰ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- í•œêµ­ì–´ ë§ì¶¤ë²•ê³¼ ë„ì–´ì“°ê¸°ë¥¼ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”
"""
        
        prompt = f"""You are a professional translator. Please translate the following text from {source_lang} to {target_lang}.

IMPORTANT TRANSLATION REQUIREMENTS:
- Source language: {source_lang} ({source_native})
- Target language: {target_lang} ({target_native})
- Translate ONLY to {target_lang}
- Do NOT include the original text
- Do NOT add explanations or comments
- Keep the original meaning and tone
- If the text contains technical terminology, maintain accuracy{korean_emphasis}

Text to translate: {sentence}

Translated text in {target_lang}:"""
        
        try:
            translation = self.llm_manager.generate_response(prompt)
            return translation.strip()
        except Exception as e:
            st.error(f"ë²ˆì—­ ì˜¤ë¥˜ (ë¬¸ì¥: {sentence[:50]}...): {str(e)}")
            return f"[ë²ˆì—­ ì˜¤ë¥˜: {sentence}]"
    
    def translate_document(self, text: str, source_lang: str = "English", 
                          target_lang: str = "Korean", 
                          use_paragraph_mode: bool = True,
                          document_title: str = None,
                          progress_callback=None) -> Dict[str, Any]:
        """Translate an entire document.
        
        Args:
            text: Document text to translate
            source_lang: Source language
            target_lang: Target language
            use_paragraph_mode: Whether to use paragraph-based translation
            document_title: Title of the document
            progress_callback: Optional callback for progress updates
            
        Returns:
            Dictionary containing translation results
        """
        if use_paragraph_mode:
            return self._translate_document_by_paragraphs(
                text, source_lang, target_lang, document_title, progress_callback
            )
        else:
            return self._translate_document_by_sentences(
                text, source_lang, target_lang, progress_callback
            )
    
    def _translate_document_by_paragraphs(self, text: str, source_lang: str, 
                                        target_lang: str, document_title: str,
                                        progress_callback=None) -> Dict[str, Any]:
        """Translate document using paragraph-based approach.
        
        Args:
            text: Document text to translate
            source_lang: Source language
            target_lang: Target language
            document_title: Title of the document
            progress_callback: Optional callback for progress updates
            
        Returns:
            Dictionary containing translation results
        """
        # Split document into paragraphs
        paragraphs = self.split_into_paragraphs(text)
        
        if not paragraphs:
            return {
                "success": False,
                "error": "ë¬¸ì„œì—ì„œ ë²ˆì—­í•  ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "original_text": text,
                "translated_text": "",
                "markdown_content": ""
            }
        
        st.info(f"ğŸ“„ ì´ {len(paragraphs)}ê°œ ë‹¨ë½ì„ ë²ˆì—­í•©ë‹ˆë‹¤...")
        
        translations = []
        translated_paragraphs = []
        
        # Create progress bar
        if progress_callback is None:
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        # Generate context for better translation
        document_context = f"ë¬¸ì„œ ì œëª©: {document_title}" if document_title else ""
        if len(text) > 500:
            # Create context from first paragraph
            first_para = paragraphs[0][:200] + "..." if len(paragraphs[0]) > 200 else paragraphs[0]
            document_context += f"\në¬¸ì„œ ê°œìš”: {first_para}"
        
        # Translate each paragraph
        for i, paragraph in enumerate(paragraphs):
            if progress_callback:
                progress_callback(i, len(paragraphs), paragraph)
            else:
                progress = (i + 1) / len(paragraphs)
                progress_bar.progress(progress)
                status_text.text(f"ë²ˆì—­ ì¤‘... ({i+1}/{len(paragraphs)}): {paragraph[:50]}...")
            
            # Skip very short paragraphs
            if len(paragraph.strip()) <= 10:
                translations.append(paragraph)
                translated_paragraphs.append({
                    "original": paragraph,
                    "translated": paragraph,
                    "skipped": True
                })
                continue
                
            translation = self.translate_paragraph(
                paragraph, source_lang, target_lang, document_context
            )
            translations.append(translation)
            translated_paragraphs.append({
                "original": paragraph,
                "translated": translation,
                "skipped": False
            })
        
        # Complete progress bar
        if progress_callback is None:
            progress_bar.progress(1.0)
            status_text.text("ë²ˆì—­ ì™„ë£Œ! ë‚´ìš©ì„ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # Combine translations
        translated_text = '\n\n'.join(translations)
        
        # Organize and format as markdown
        try:
            markdown_content = self.organize_and_format_translation(
                translated_text, document_title, target_lang
            )
        except Exception as e:
            st.warning(f"ë§ˆí¬ë‹¤ìš´ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            markdown_content = translated_text
        
        if progress_callback is None:
            status_text.text("ë²ˆì—­ ë° ì •ë¦¬ ì™„ë£Œ!")
        
        return {
            "success": True,
            "original_text": text,
            "translated_text": translated_text,
            "markdown_content": markdown_content,
            "source_language": source_lang,
            "target_language": target_lang,
            "paragraphs": paragraphs,
            "translations": translations,
            "paragraph_pairs": translated_paragraphs,
            "total_paragraphs": len(paragraphs),
            "translation_mode": "paragraph",
            "document_title": document_title,
            "timestamp": datetime.now().isoformat()
        }
    
    def _translate_document_by_sentences(self, text: str, source_lang: str, 
                                       target_lang: str, progress_callback=None) -> Dict[str, Any]:
        """Translate document using sentence-based approach (legacy).
        
        Args:
            text: Document text to translate
            source_lang: Source language
            target_lang: Target language
            progress_callback: Optional callback for progress updates
            
        Returns:
            Dictionary containing translation results
        """
        # Split document into sentences
        sentences = self.split_into_sentences(text)
        
        if not sentences:
            return {
                "success": False,
                "error": "ë¬¸ì„œì—ì„œ ë²ˆì—­í•  ë¬¸ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "original_text": text,
                "translated_text": "",
                "sentences": [],
                "translations": []
            }
        
        st.info(f"ğŸ“ ì´ {len(sentences)}ê°œ ë¬¸ì¥ì„ ë²ˆì—­í•©ë‹ˆë‹¤...")
        
        translations = []
        translated_sentences = []
        
        # Create progress bar
        if progress_callback is None:
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        # Translate each sentence
        for i, sentence in enumerate(sentences):
            if progress_callback:
                progress_callback(i, len(sentences), sentence)
            else:
                progress = (i + 1) / len(sentences)
                progress_bar.progress(progress)
                status_text.text(f"ë²ˆì—­ ì¤‘... ({i+1}/{len(sentences)}): {sentence[:50]}...")
            
            # Skip very short sentences or single characters
            if len(sentence.strip()) <= 2:
                translations.append(sentence)
                translated_sentences.append({
                    "original": sentence,
                    "translated": sentence,
                    "skipped": True
                })
                continue
                
            translation = self.translate_sentence(sentence, source_lang, target_lang)
            translations.append(translation)
            translated_sentences.append({
                "original": sentence,
                "translated": translation,
                "skipped": False
            })
        
        # Complete progress bar
        if progress_callback is None:
            progress_bar.progress(1.0)
            status_text.text("ë²ˆì—­ ì™„ë£Œ!")
        
        # Combine translations
        translated_text = '\n'.join(translations)
        
        return {
            "success": True,
            "original_text": text,
            "translated_text": translated_text,
            "source_language": source_lang,
            "target_language": target_lang,
            "sentences": sentences,
            "translations": translations,
            "sentence_pairs": translated_sentences,
            "total_sentences": len(sentences),
            "translation_mode": "sentence",
            "timestamp": datetime.now().isoformat()
        }
    
    def process_uploaded_file(self, uploaded_file) -> Optional[str]:
        """Process uploaded file and extract text.
        
        Args:
            uploaded_file: Streamlit uploaded file object
            
        Returns:
            Extracted text or None if failed
        """
        try:
            # Save uploaded file temporarily
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            # Process document
            documents = self.document_processor.load_documents([tmp_path])
            
            # Clean up temporary file
            os.unlink(tmp_path)
            
            if documents:
                # Combine all document content
                text = '\n\n'.join([doc.page_content for doc in documents])
                return text
            else:
                return None
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def export_translation_result(self, result: Dict[str, Any]) -> str:
        """Export translation result as formatted text.
        
        Args:
            result: Translation result dictionary
            
        Returns:
            Formatted text for export
        """
        if not result.get("success", False):
            return "ë²ˆì—­ ê²°ê³¼ë¥¼ ë‚´ë³´ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # Create language mapping for display
        lang_display = {
            "English": "ì˜ì–´ (English)",
            "Korean": "í•œêµ­ì–´ (Korean)", 
            "Japanese": "ì¼ë³¸ì–´ (Japanese)",
            "Chinese": "ì¤‘êµ­ì–´ (Chinese)",
            "French": "í”„ë‘ìŠ¤ì–´ (French)",
            "German": "ë…ì¼ì–´ (German)",
            "Spanish": "ìŠ¤í˜ì¸ì–´ (Spanish)",
            "Italian": "ì´íƒˆë¦¬ì•„ì–´ (Italian)",
            "Portuguese": "í¬ë¥´íˆ¬ê°ˆì–´ (Portuguese)",
            "Dutch": "ë„¤ëœë€ë“œì–´ (Dutch)",
            "Russian": "ëŸ¬ì‹œì•„ì–´ (Russian)"
        }
        
        source_lang = result.get('source_language', 'Unknown')
        target_lang = result.get('target_language', 'Unknown')
        source_display = lang_display.get(source_lang, source_lang)
        target_display = lang_display.get(target_lang, target_lang)
        translation_mode = result.get('translation_mode', 'Unknown')
        mode_display = "ë‹¨ë½ ê¸°ë°˜" if translation_mode == "paragraph" else "ë¬¸ì¥ ê¸°ë°˜"
        
        # Use markdown content if available
        if result.get("markdown_content"):
            export_text = f"""# ë¬¸ì„œ ë²ˆì—­ ê²°ê³¼

## ë²ˆì—­ ì •ë³´
- **ì›ë³¸ ì–¸ì–´:** {source_display}
- **ëŒ€ìƒ ì–¸ì–´:** {target_display}
- **ë²ˆì—­ ë°©ì‹:** {mode_display}
- **ë¬¸ì„œ ì œëª©:** {result.get('document_title', 'ì œëª© ì—†ìŒ')}
- **ë²ˆì—­ ì‹œê°„:** {result.get('timestamp', 'Unknown')}

---

{result.get('markdown_content', '')}
"""
        else:
            # Fallback to legacy format
            export_text = f"""# ë¬¸ì„œ ë²ˆì—­ ê²°ê³¼

## ë²ˆì—­ ì •ë³´
- **ì›ë³¸ ì–¸ì–´:** {source_display}
- **ëŒ€ìƒ ì–¸ì–´:** {target_display}
- **ë²ˆì—­ ë°©ì‹:** {mode_display}
- **ì´ í•­ëª© ìˆ˜:** {result.get('total_sentences', result.get('total_paragraphs', 0))}
- **ë²ˆì—­ ì‹œê°„:** {result.get('timestamp', 'Unknown')}

## ë²ˆì—­ëœ ë¬¸ì„œ

{result.get('translated_text', '')}
"""
        
        return export_text
    
    def get_translation_stats(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Get statistics about the translation.
        
        Args:
            result: Translation result dictionary
            
        Returns:
            Translation statistics
        """
        if not result.get("success", False):
            return {}
        
        translation_mode = result.get('translation_mode', 'unknown')
        
        if translation_mode == 'paragraph':
            paragraph_pairs = result.get('paragraph_pairs', [])
            total_units = len(paragraph_pairs)
            skipped_units = sum(1 for pair in paragraph_pairs if pair.get('skipped', False))
            translated_units = total_units - skipped_units
            
            stats = {
                "translation_mode": "ë‹¨ë½ ë‹¨ìœ„",
                "total_paragraphs": total_units,
                "translated_paragraphs": translated_units,
                "skipped_paragraphs": skipped_units,
            }
        else:
            sentence_pairs = result.get('sentence_pairs', [])
            total_units = len(sentence_pairs)
            skipped_units = sum(1 for pair in sentence_pairs if pair.get('skipped', False))
            translated_units = total_units - skipped_units
            
            stats = {
                "translation_mode": "ë¬¸ì¥ ë‹¨ìœ„",
                "total_sentences": total_units,
                "translated_sentences": translated_units,
                "skipped_sentences": skipped_units,
            }
        
        original_text = result.get('original_text', '')
        translated_text = result.get('translated_text', '')
        
        stats.update({
            "original_char_count": len(original_text),
            "translated_char_count": len(translated_text),
            "original_word_count": len(original_text.split()),
            "translated_word_count": len(translated_text.split()),
            "source_language": result.get('source_language', 'Unknown'),
            "target_language": result.get('target_language', 'Unknown'),
            "has_markdown": bool(result.get('markdown_content'))
        })
        
        return stats 