"""
Document Discovery UI
ë¬¸ì„œ ë°œê²¬ ë° ìƒì„¸ ê²€ìƒ‰ì„ ìœ„í•œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
"""

import streamlit as st
from typing import List, Dict, Any, Optional
import time

from src.rag_systems import document_discovery_rag as dd_rag
from src.utils.llm_manager import LLMManager
from src.utils.embeddings import EmbeddingManager
from src.graphs.document_discovery_graph import (
    create_summary_generation_graph,
    create_document_discovery_graph,
    create_detailed_search_graph
)
from src.config import MODELS_FOLDER, EMBEDDING_MODEL

class DocumentDiscoveryUI:
    """ë¬¸ì„œ ë°œê²¬ RAGë¥¼ ìœ„í•œ UI í´ë˜ìŠ¤"""

    def __init__(self):
        # LLM, Embedding Manager, Graphsë¥¼ ì´ˆê¸°í™”í•˜ê³  ìºì‹œí•©ë‹ˆë‹¤.
        self.llm_manager = self._get_llm_manager()
        self.embedding_manager = self._get_embedding_manager()
        self.graphs = self._get_graphs()

    @st.cache_resource
    def _get_llm_manager(_self) -> LLMManager:
        return LLMManager(
            st.session_state.get("selected_llm_model", "llama3.2:latest"),
            "http://localhost:11434",
            temperature=st.session_state.get("llm_temperature", 0.1)
        )

    @st.cache_resource
    def _get_embedding_manager(_self) -> EmbeddingManager:
        return EmbeddingManager(EMBEDDING_MODEL, MODELS_FOLDER)

    @st.cache_resource
    def _get_graphs(_self) -> Dict[str, Any]:
        """ì„¸ ê°€ì§€ ì£¼ìš” ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
        llm_manager = _self._get_llm_manager()
        embedding_manager = _self._get_embedding_manager()
        return {
            "summary_generation": create_summary_generation_graph(llm_manager),
            "document_discovery": create_document_discovery_graph(llm_manager),
            "detailed_search": create_detailed_search_graph(llm_manager, embedding_manager),
        }

    def render(self):
        """Document Discovery íƒ­ì˜ ì „ì²´ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
        st.header("ğŸ” ë¬¸ì„œ ë°œê²¬ ë° ìƒì„¸ ê²€ìƒ‰")
        st.markdown("""
        ì´ ê¸°ëŠ¥ì€ 2ë‹¨ê³„ë¡œ ì‘ë™í•©ë‹ˆë‹¤:
        1. **ë¬¸ì„œ ë°œê²¬**: ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë“¤ì„ ì°¾ìŠµë‹ˆë‹¤. (ì‚¬ì „ ìš”ì•½ í•„ìš”)
        2. **ìƒì„¸ ê²€ìƒ‰**: ì„ íƒëœ ë¬¸ì„œì—ì„œ êµ¬ì²´ì ì¸ ë‹µë³€ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        """)

        tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë¬¸ì„œ ìš”ì•½ ê´€ë¦¬", "ğŸ” ë¬¸ì„œ ë°œê²¬", "ğŸ“– ìƒì„¸ ê²€ìƒ‰"])
        
        with tab1:
            self._display_summary_management_tab()
        with tab2:
            self._display_document_discovery_tab()
        with tab3:
            self._display_detailed_search_tab()
    
    def _display_summary_management_tab(self):
        st.subheader("ğŸ“Š ë¬¸ì„œ ìš”ì•½ ê´€ë¦¬")
        st.markdown("ëª¨ë“  ë¬¸ì„œì˜ ìš”ì•½ì„ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ì—¬ íš¨ìœ¨ì ì¸ ê²€ìƒ‰ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.")
        
        available_docs = dd_rag.get_available_documents()
        existing_summaries = dd_rag.load_document_summaries()

        if not available_docs:
            st.warning("âš ï¸ `docs` í´ë”ì— PDF ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        st.write(f"**ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ**: {len(available_docs)}ê°œ | **ìš”ì•½ ì™„ë£Œëœ ë¬¸ì„œ**: {len(existing_summaries)}ê°œ")
        
        with st.expander("ğŸ“„ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°"):
            for doc_info in available_docs:
                filename = doc_info["filename"]
                has_summary = filename in existing_summaries
                status = "âœ… ìš”ì•½ ì™„ë£Œ" if has_summary else "â³ ìš”ì•½ í•„ìš”"
                
                col1, col2, col3 = st.columns([4, 2, 2])
                with col1:
                    st.write(f"**{filename}** ({doc_info.get('size_mb', 0):.1f}MB, {doc_info.get('pages', 0)}p)")
                with col2:
                    if st.button("ğŸ‘ï¸ ë³´ê¸°", key=f"view_{filename}", disabled=not has_summary):
                        st.session_state.selected_summary_for_view = existing_summaries[filename]
                with col3:
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{filename}", disabled=not has_summary):
                        del existing_summaries[filename]
                        dd_rag.save_document_summaries(existing_summaries)
                        st.rerun()

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“Š ëª¨ë“  ë¬¸ì„œ ìš”ì•½ ìƒì„±", type="primary"):
                self._run_summary_generation()
        with col2:
            if st.button("ğŸ—‘ï¸ ëª¨ë“  ìš”ì•½ ì‚­ì œ"):
                dd_rag.save_document_summaries({})
                st.success("ëª¨ë“  ìš”ì•½ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                time.sleep(1)
                st.rerun()
        
        if "selected_summary_for_view" in st.session_state:
            self._show_summary_detail(st.session_state.selected_summary_for_view)
            if st.button("âŒ ë‹«ê¸°", key="close_summary_view"):
                del st.session_state.selected_summary_for_view
                st.rerun()

    def _run_summary_generation(self):
        graph = self.graphs["summary_generation"]
        if not graph:
            st.error("ìš”ì•½ ìƒì„± ê·¸ë˜í”„ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        with st.spinner("ë¬¸ì„œ ìš”ì•½ ìƒì„± ì¤‘..."):
            final_state = graph.invoke({})
        
        st.success(f"âœ… ìš”ì•½ ìƒì„± ì™„ë£Œ! {final_state.get('processed_docs', 0)}ê°œ ì‹ ê·œ ë¬¸ì„œ ì²˜ë¦¬ë¨")
        time.sleep(1)
        st.rerun()

    def _display_document_discovery_tab(self):
        st.subheader("ğŸ” ë¬¸ì„œ ë°œê²¬")
        st.markdown("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë“¤ì„ ì°¾ì•„ë³´ì„¸ìš”.")
        
        summaries = dd_rag.load_document_summaries()
        if not summaries:
            st.warning("âš ï¸ ë¨¼ì € 'ë¬¸ì„œ ìš”ì•½ ê´€ë¦¬' íƒ­ì—ì„œ ë¬¸ì„œ ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return
        
        st.success(f"âœ… {len(summaries)}ê°œ ë¬¸ì„œì˜ ìš”ì•½ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        query = st.text_area("ğŸ¤” ì§ˆë¬¸:", placeholder="ì˜ˆ: 2024ë…„ AI ì •ì±…ì˜ ì£¼ìš” ë³€í™”ì ì€?", height=100, key="discovery_query")
        top_k = st.slider("ìµœëŒ€ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", 1, 10, 5, key="discovery_top_k")

        if st.button("ğŸ” ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°", type="primary"):
            if query.strip():
                self._run_document_discovery(query, top_k)
            else:
                st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if "discovery_results" in st.session_state:
            self._display_discovery_results(summaries)
    
    def _run_document_discovery(self, query: str, top_k: int):
        graph = self.graphs["document_discovery"]
        if not graph:
            st.error("ë¬¸ì„œ ë°œê²¬ ê·¸ë˜í”„ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        with st.spinner("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ëŠ” ì¤‘..."):
            inputs = {"query": query, "top_k": top_k}
            result = graph.invoke(inputs)
            st.session_state.discovery_results = result.get("relevant_docs", [])

    def _display_discovery_results(self, summaries: Dict[str, Any]):
        results = st.session_state.discovery_results
        st.markdown(f"### ğŸ“‹ ê´€ë ¨ ë¬¸ì„œ ëª©ë¡ ({len(results)}ê°œ)")
        st.markdown(f"*ê²€ìƒ‰ì–´: \"{st.session_state.discovery_query}\"*")

        if not results:
            st.warning("ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        for i, (filename, score, explanation) in enumerate(results, 1):
            with st.container(border=True):
                col1, col2, col3 = st.columns([5, 2, 2])
                with col1:
                    st.markdown(f"**{i}. {filename}** (ì ìˆ˜: {score})")
                    st.caption(explanation)
                with col2:
                    if st.button("ğŸ‘ï¸ ìš”ì•½ ë³´ê¸°", key=f"summary_{i}"):
                        if filename in summaries:
                            st.session_state.selected_summary_for_view = summaries[filename]
                with col3:
                    if st.button("ğŸ‘‰ ìƒì„¸ ê²€ìƒ‰ìœ¼ë¡œ", key=f"detail_{i}"):
                        st.session_state.selected_document_for_detail = filename
                        st.session_state.query_for_detail = st.session_state.discovery_query
                        st.info("ğŸ“– 'ìƒì„¸ ê²€ìƒ‰' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ ê²€ìƒ‰ì„ ê³„ì†í•˜ì„¸ìš”.")

        if "selected_summary_for_view" in st.session_state:
            self._show_summary_detail(st.session_state.selected_summary_for_view)
            if st.button("âŒ ë‹«ê¸°", key="close_summary_detail_view"):
                del st.session_state.selected_summary_for_view
                st.rerun()

    def _display_detailed_search_tab(self):
        st.subheader("ğŸ“– ìƒì„¸ ê²€ìƒ‰")
        st.markdown("íŠ¹ì • ë¬¸ì„œì—ì„œ êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì°¾ì•„ë³´ì„¸ìš”.")

        available_docs = dd_rag.get_available_documents()
        doc_list = [doc["filename"] for doc in available_docs]
        
        selected_filename = None
        if "selected_document_for_detail" in st.session_state:
            default_index = doc_list.index(st.session_state.selected_document_for_detail) if st.session_state.selected_document_for_detail in doc_list else 0
            selected_filename = st.selectbox("ë¬¸ì„œ ì„ íƒ", doc_list, index=default_index, key="detail_filename_select")
        else:
            selected_filename = st.selectbox("ë¬¸ì„œ ì„ íƒ", doc_list, key="detail_filename_select")

        query = st.text_area("ğŸ¤” ì§ˆë¬¸", value=st.session_state.get("query_for_detail", ""), height=100, key="detail_query")
        chunk_k = st.slider("ì°¸ê³ í•  ì²­í¬ ìˆ˜", 3, 15, 5, key="detail_chunk_k")
        
        if st.button("ğŸ” ìƒì„¸ ê²€ìƒ‰ ì‹¤í–‰", type="primary"):
            if selected_filename and query.strip():
                self._run_detailed_search(selected_filename, query, chunk_k)
            else:
                st.warning("ë¬¸ì„œì™€ ì§ˆë¬¸ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        if "detailed_search_result" in st.session_state:
            self._display_detailed_search_result()

    def _run_detailed_search(self, filename: str, query: str, top_k: int):
        graph = self.graphs["detailed_search"]
        if not graph:
            st.error("ìƒì„¸ ê²€ìƒ‰ ê·¸ë˜í”„ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        with st.spinner(f"'{filename}'ì—ì„œ ë‹µë³€ì„ ì°¾ëŠ” ì¤‘..."):
            inputs = {
                "filename": filename,
                "query": query,
                "top_k": top_k,
                "vector_store_config": {"vector_store_type": st.session_state.get("vector_store_type", "faiss")}
            }
            result = graph.invoke(inputs)
            st.session_state.detailed_search_result = result
            st.session_state.detailed_search_filename = filename

    def _display_detailed_search_result(self):
        result = st.session_state.detailed_search_result
        if result.get("error"):
            st.error(f"âŒ {result['error']}")
            return

        st.markdown(f"### ğŸ’¡ ë‹µë³€ (ì¶œì²˜: {st.session_state.detailed_search_filename})")
        st.markdown(result["answer"])
        
        with st.expander("ğŸ“ ì°¸ê³ í•œ ë¬¸ì„œ ë‚´ìš© ë³´ê¸°"):
            for chunk in result.get("relevant_chunks", []):
                st.text_area(
                    f"í˜ì´ì§€ {chunk['metadata'].get('page', 'N/A')}",
                    chunk["content"],
                    height=150,
                    disabled=True
                )

    def _show_summary_detail(self, summary_data: Dict[str, Any]):
        st.markdown(f"### ğŸ“„ {summary_data['filename']} ìš”ì•½ ìƒì„¸")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“„ í˜ì´ì§€", f"{summary_data.get('pages', 0)}ê°œ")
            st.metric("ğŸ’¾ í¬ê¸°", f"{summary_data.get('size_mb', 0):.1f}MB")
        with col2:
            st.metric("ğŸ“… ìƒì„±ì¼", summary_data.get('generated_at', 'Unknown')[:10])
            st.metric("ğŸ“ ì œëª©", (summary_data.get('title') or "ì œëª© ì—†ìŒ")[:20] + "...")
        st.markdown("#### ğŸ“‹ ìš”ì•½ ë‚´ìš©")
        st.markdown(summary_data['summary'])
        if summary_data.get('preview'):
            with st.expander("ğŸ‘€ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° (ì²« í˜ì´ì§€)"):
                st.text(summary_data['preview']) 