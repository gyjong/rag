"""
Document Discovery UI
ë¬¸ì„œ ë°œê²¬ ë° ìƒì„¸ ê²€ìƒ‰ì„ ìœ„í•œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
"""

import streamlit as st
from typing import List, Dict, Any, Optional
import time

from src.rag_systems import document_discovery_rag as dd_rag
from src.utils.llm_manager import LLMManager
from src.utils.embeddings import EmbeddingManager
from src.graphs.document_discovery_graph import (
    create_summary_generation_graph,
    create_document_discovery_graph,
    create_detailed_search_graph
)
from src.config import MODELS_FOLDER, EMBEDDING_MODEL
from src.utils.vector_store import VectorStoreManager
from src.config import langfuse_handler

class DocumentDiscoveryUI:
    """ë¬¸ì„œ ë°œê²¬ RAGë¥¼ ìœ„í•œ UI í´ë˜ìŠ¤"""

    def __init__(self):
        # LLM, Embedding Manager, Graphsë¥¼ ì´ˆê¸°í™”í•˜ê³  ìºì‹œí•©ë‹ˆë‹¤.
        self.llm_manager = self._get_llm_manager()
        self.embedding_manager = self._get_embedding_manager()
        self.graphs = self._get_graphs()

    @st.cache_resource
    def _get_llm_manager(_self) -> LLMManager:
        return LLMManager(
            st.session_state.get("selected_llm_model", "llama3.2:latest"),
            "http://localhost:11434",
            temperature=st.session_state.get("llm_temperature", 0.1)
        )

    @st.cache_resource
    def _get_embedding_manager(_self) -> EmbeddingManager:
        return EmbeddingManager(EMBEDDING_MODEL, MODELS_FOLDER)

    @st.cache_resource
    def _get_graphs(_self) -> Dict[str, Any]:
        """ì„¸ ê°€ì§€ ì£¼ìš” ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
        llm_manager = _self._get_llm_manager()
        embedding_manager = _self._get_embedding_manager()
        return {
            "summary_generation": create_summary_generation_graph(llm_manager),
            "document_discovery": create_document_discovery_graph(llm_manager),
            "detailed_search": create_detailed_search_graph(llm_manager, embedding_manager),
        }

    @staticmethod
    def display_document_discovery_tab():
        """Document Discovery íƒ­ì˜ ì „ì²´ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
        # Create an instance to access helper methods
        ui_instance = DocumentDiscoveryUI()

        st.header("ğŸ” ë¬¸ì„œ ë°œê²¬ ë° ìƒì„¸ ê²€ìƒ‰")
        st.markdown("""
        ì´ ê¸°ëŠ¥ì€ 3ë‹¨ê³„ë¡œ ì‘ë™í•©ë‹ˆë‹¤:
        1. **ë¬¸ì„œ ìš”ì•½ ê´€ë¦¬**: ê²€ìƒ‰ ëŒ€ìƒ ë¬¸ì„œë“¤ì˜ ìš”ì•½ì„ ìƒì„±/ê´€ë¦¬í•˜ì—¬ ê²€ìƒ‰ íš¨ìœ¨ì„ ë†’ì…ë‹ˆë‹¤.
        2. **ë¬¸ì„œ ë°œê²¬**: ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë“¤ì„ ìš”ì•½ ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì°¾ìŠµë‹ˆë‹¤.
        3. **ìƒì„¸ ê²€ìƒ‰**: ë°œê²¬ëœ ë¬¸ì„œë“¤ ë‚´ì—ì„œ êµ¬ì²´ì ì¸ ë‹µë³€ê³¼ ê·¼ê±°ë¥¼ ì‹¬ì¸µì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        """)

        tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë¬¸ì„œ ìš”ì•½ ê´€ë¦¬", "ğŸ” ë¬¸ì„œ ë°œê²¬", "ğŸ“– ìƒì„¸ ê²€ìƒ‰"])
        
        with tab1:
            ui_instance._display_summary_management_tab()
        with tab2:
            ui_instance._display_discovery_step_tab()
        with tab3:
            ui_instance._display_detailed_search_tab()

    def _display_summary_management_tab(self):
        st.subheader("ğŸ“Š ë¬¸ì„œ ìš”ì•½ ê´€ë¦¬")
        st.markdown("ëª¨ë“  ë¬¸ì„œì˜ ìš”ì•½ì„ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ì—¬ íš¨ìœ¨ì ì¸ ê²€ìƒ‰ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.")
        
        available_docs = dd_rag.get_available_documents()
        existing_summaries = dd_rag.load_document_summaries()

        if not available_docs:
            st.warning("âš ï¸ `docs` í´ë”ì— PDF ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        st.write(f"**ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ**: {len(available_docs)}ê°œ | **ìš”ì•½ ì™„ë£Œëœ ë¬¸ì„œ**: {len(existing_summaries)}ê°œ")
        
        with st.expander("ğŸ“„ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°"):
            for doc_info in available_docs:
                filename = doc_info["filename"]
                has_summary = filename in existing_summaries
                status = "âœ… ìš”ì•½ ì™„ë£Œ" if has_summary else "â³ ìš”ì•½ í•„ìš”"
                
                col1, col2, col3 = st.columns([4, 2, 2])
                with col1:
                    st.write(f"**{filename}** ({doc_info.get('size_mb', 0):.1f}MB, {doc_info.get('pages', 0)}p)")
                with col2:
                    if st.button("ğŸ‘ï¸ ë³´ê¸°", key=f"view_{filename}", disabled=not has_summary):
                        st.session_state.selected_summary_for_view = existing_summaries[filename]
                with col3:
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{filename}", disabled=not has_summary):
                        del existing_summaries[filename]
                        dd_rag.save_document_summaries(existing_summaries)
                        st.rerun()

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“Š ëª¨ë“  ë¬¸ì„œ ìš”ì•½ ìƒì„±", type="primary"):
                self._run_summary_generation()
        with col2:
            if st.button("ğŸ—‘ï¸ ëª¨ë“  ìš”ì•½ ì‚­ì œ"):
                dd_rag.save_document_summaries({})
                st.success("ëª¨ë“  ìš”ì•½ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                time.sleep(1)
                st.rerun()
        
        if "selected_summary_for_view" in st.session_state:
            self._show_summary_detail(st.session_state.selected_summary_for_view)
            if st.button("âŒ ë‹«ê¸°", key="close_summary_view"):
                del st.session_state.selected_summary_for_view
                st.rerun()

    def _run_summary_generation(self):
        graph = self.graphs["summary_generation"]
        if not graph:
            st.error("ìš”ì•½ ìƒì„± ê·¸ë˜í”„ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        with st.spinner("ë¬¸ì„œ ìš”ì•½ ìƒì„± ì¤‘..."):
            final_state = graph.invoke({}, config={"callbacks": [langfuse_handler]})
        
        st.success(f"âœ… ìš”ì•½ ìƒì„± ì™„ë£Œ! {final_state.get('processed_docs', 0)}ê°œ ì‹ ê·œ ë¬¸ì„œ ì²˜ë¦¬ë¨")
        time.sleep(1)
        st.rerun()

    def _display_discovery_step_tab(self):
        """Handles the UI for the document discovery step."""
        st.subheader("ğŸ” 2ë‹¨ê³„: ë¬¸ì„œ ë°œê²¬")
        
        summaries = dd_rag.load_document_summaries()
        if not summaries:
            st.warning("ë¨¼ì € 'ë¬¸ì„œ ìš”ì•½ ê´€ë¦¬' íƒ­ì—ì„œ ìµœì†Œ 1ê°œ ì´ìƒì˜ ë¬¸ì„œ ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return

        query = st.text_input("ë¶„ì„í•˜ê³  ì‹¶ì€ ì£¼ì œë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="discovery_query")

        if st.button("ğŸ” ë¬¸ì„œ ë°œê²¬ ì‹¤í–‰", key="discovery_run_button", type="primary"):
            if not query.strip():
                st.warning("ë¶„ì„í•  ì£¼ì œë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return

            graph = self.graphs["document_discovery"]
            if not graph:
                st.error("ë¬¸ì„œ ë°œê²¬ ê·¸ë˜í”„ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            with st.spinner("ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ë°œê²¬ ì¤‘..."):
                inputs = {"query": query, "top_k": 5} # top_k is fixed for discovery
                result = graph.invoke(inputs, config={"callbacks": [langfuse_handler]})
            
            if 'detailed_search_results' in st.session_state:
                del st.session_state.detailed_search_results
            st.session_state.discovered_docs = result.get("relevant_docs", [])
            st.session_state.last_discovery_query = query
        
        if 'discovered_docs' in st.session_state and st.session_state.discovered_docs:
            st.markdown("---")
            st.subheader("ğŸ¯ 3ë‹¨ê³„: ìƒì„¸ ì •ë³´ ê²€ìƒ‰")
            st.markdown("ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œ ëª©ë¡ì…ë‹ˆë‹¤. ê° ë¬¸ì„œì— ëŒ€í•´ ìƒì„¸ ê²€ìƒ‰ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            chunk_k = st.slider("ìƒì„¸ ê²€ìƒ‰ ì‹œ ì°¸ê³ í•  ì²­í¬ ìˆ˜", 3, 15, 5, key="discovery_detail_chunk_k")
            
            if 'detailed_search_results' not in st.session_state:
                st.session_state.detailed_search_results = {}

            for doc_info in st.session_state.discovered_docs:
                filename, score, reasoning = doc_info
                
                with st.container():
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.markdown(f"**- íŒŒì¼:** `{filename}` (ê´€ë ¨ì„± ì ìˆ˜: **{score}ì **)")
                        st.info(f"**ê´€ë ¨ì„± ì´ìœ :** {reasoning}")
                    
                    with col2:
                        if st.button("ğŸ” ìƒì„¸ ê²€ìƒ‰", key=f"discovery_detail_search_{filename}"):
                            self._run_detailed_search(filename, st.session_state.last_discovery_query, chunk_k)
                            st.rerun()

                    if filename in st.session_state.detailed_search_results:
                        with st.expander(f"ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼: {filename}", expanded=True):
                            result_data = st.session_state.detailed_search_results[filename]
                            self._display_single_detailed_result(result_data, filename, key_prefix="discovery_")
                    st.markdown("---")

    def _display_detailed_search_tab(self):
        st.subheader("ğŸ“– ìƒì„¸ ê²€ìƒ‰")
        st.markdown("íŠ¹ì • ë¬¸ì„œì—ì„œ êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì°¾ì•„ë³´ì„¸ìš”.")

        available_docs = dd_rag.get_available_documents()
        doc_list = [doc["filename"] for doc in available_docs]
        
        selected_filename = None
        if "selected_document_for_detail" in st.session_state:
            default_index = doc_list.index(st.session_state.selected_document_for_detail) if st.session_state.selected_document_for_detail in doc_list else 0
            selected_filename = st.selectbox("ë¬¸ì„œ ì„ íƒ", doc_list, index=default_index, key="detail_filename_select")
        else:
            selected_filename = st.selectbox("ë¬¸ì„œ ì„ íƒ", doc_list, key="detail_filename_select")

        query = st.text_area("ğŸ¤” ì§ˆë¬¸", value=st.session_state.get("query_for_detail", ""), height=100, key="detail_query")
        chunk_k = st.slider("ì°¸ê³ í•  ì²­í¬ ìˆ˜", 3, 15, 5, key="detail_chunk_k")
        
        if st.button("ğŸ” ìƒì„¸ ê²€ìƒ‰ ì‹¤í–‰", type="primary"):
            if selected_filename and query.strip():
                self._run_detailed_search(selected_filename, query, chunk_k)
            else:
                st.warning("ë¬¸ì„œì™€ ì§ˆë¬¸ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        if "detailed_search_result" in st.session_state:
            self._display_detailed_search_result()

    def _run_detailed_search(self, filename: str, query: str, top_k: int):
        graph = self.graphs["detailed_search"]
        if not graph:
            st.error("ìƒì„¸ ê²€ìƒ‰ ê·¸ë˜í”„ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        with st.spinner(f"'{filename}'ì—ì„œ ë‹µë³€ì„ ì°¾ëŠ” ì¤‘..."):
            inputs = {
                "filename": filename,
                "query": query,
                "top_k": top_k,
                "vector_store_config": {"vector_store_type": st.session_state.get("vector_store_type", "faiss")}
            }
            result = graph.invoke(inputs, config={"callbacks": [langfuse_handler]})
            
            if 'detailed_search_results' not in st.session_state:
                st.session_state.detailed_search_results = {}
            st.session_state.detailed_search_results[filename] = result
            # These are for the dedicated detail tab, can be kept for now
            st.session_state.detailed_search_result = result
            st.session_state.detailed_search_filename = filename

    def _display_detailed_search_result(self):
        result = st.session_state.detailed_search_result
        filename = st.session_state.detailed_search_filename
        if result:
            self._display_single_detailed_result(result, filename, key_prefix="detail_")

    def _display_single_detailed_result(self, result: Dict[str, Any], filename: str, key_prefix: str = ""):
        """Displays a single detailed search result."""
        if not result:
            return
            
        if result.get("error"):
            st.error(f"âŒ {result['error']}")
            return

        st.markdown(f"**ğŸ’¡ ë‹µë³€:**")
        st.markdown(result.get("answer", "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."))
        
        with st.expander("ğŸ“ ì°¸ê³ í•œ ë¬¸ì„œ ë‚´ìš© ë³´ê¸°"):
            for chunk in result.get("relevant_chunks", []):
                st.text_area(
                    f"í˜ì´ì§€ {chunk['metadata'].get('page', 'N/A')}",
                    chunk["content"],
                    height=150,
                    disabled=True,
                    key=f"{key_prefix}chunk_{filename}_{chunk['metadata'].get('page', 'N/A')}_{hash(chunk['content'])}"
                )

    def _show_summary_detail(self, summary_data: Dict[str, Any]):
        st.markdown(f"### ğŸ“„ {summary_data['filename']} ìš”ì•½ ìƒì„¸")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“„ í˜ì´ì§€", f"{summary_data.get('pages', 0)}ê°œ")
            st.metric("ğŸ’¾ í¬ê¸°", f"{summary_data.get('size_mb', 0):.1f}MB")
        with col2:
            st.metric("ğŸ“… ìƒì„±ì¼", summary_data.get('generated_at', 'Unknown')[:10])
            st.metric("ğŸ“ ì œëª©", (summary_data.get('title') or "ì œëª© ì—†ìŒ")[:20] + "...")
        st.markdown("#### ğŸ“‹ ìš”ì•½ ë‚´ìš©")
        st.markdown(summary_data['summary'])
        if summary_data.get('preview'):
            with st.expander("ğŸ‘€ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° (ì²« í˜ì´ì§€)"):
                st.text(summary_data['preview']) 