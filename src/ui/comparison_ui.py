"""UI components for RAG system comparison."""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from typing import List, Dict, Any
import time


class ComparisonUI:
    """UI components for comparing RAG systems."""
    
    @staticmethod
    def display_system_comparison(systems_info: List[Dict[str, Any]]):
        """Display comparison of RAG systems."""
        st.subheader("ğŸ” RAG ì‹œìŠ¤í…œ ë¹„êµ")
        
        # Enhanced comparison with more detailed information
        st.write("### ğŸ“Š ì‹œìŠ¤í…œ íŠ¹ì„± ë¹„êµ")
        
        for system in systems_info:
            with st.expander(f"ğŸ”§ {system['name']} - {system['description']}", expanded=True):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**ğŸ› ï¸ í•µì‹¬ êµ¬ì„± ìš”ì†Œ:**")
                    for component in system["components"]:
                        st.write(f"â€¢ {component}")
                    
                    if "retrieval_methods" in system:
                        st.write("**ğŸ” ê²€ìƒ‰ ë°©ë²•:**")
                        for method, desc in system["retrieval_methods"].items():
                            if method == "semantic":
                                st.write(f"â€¢ ğŸ§  ì˜ë¯¸ì  ê²€ìƒ‰: {desc}")
                            elif method == "keyword":
                                st.write(f"â€¢ ğŸ”¤ í‚¤ì›Œë“œ ê²€ìƒ‰: {desc}")
                            elif method == "hybrid":
                                st.write(f"â€¢ ğŸ”€ í•˜ì´ë¸Œë¦¬ë“œ: {desc}")
                
                with col2:
                    st.write("**âœ¨ ì£¼ìš” íŠ¹ì§•:**")
                    for feature in system["features"]:
                        if "BM25" in feature or "í‚¤ì›Œë“œ" in feature:
                            st.write(f"ğŸ”¤ {feature}")
                        elif "í•˜ì´ë¸Œë¦¬ë“œ" in feature or "ì¬ìˆœìœ„" in feature:
                            st.write(f"ğŸ”€ {feature}")
                        elif "ë¶„ë¥˜" in feature or "ì§ˆë¬¸" in feature:
                            st.write(f"ğŸ¯ {feature}")
                        elif "ë°˜ë³µ" in feature or "ê°œì„ " in feature:
                            st.write(f"ğŸ”„ {feature}")
                        elif "ì••ì¶•" in feature or "ìŠ¤íŠ¸ë¦¬ë°" in feature:
                            st.write(f"âš¡ {feature}")
                        else:
                            st.write(f"â€¢ {feature}")
                    
                    if "advantages" in system:
                        st.write("**ğŸ† ì£¼ìš” ì¥ì :**")
                        for advantage in system["advantages"]:
                            st.write(f"âœ… {advantage}")
        
        # Create comparison table
        st.write("### ğŸ“‹ ìš”ì•½ ë¹„êµí‘œ")
        comparison_data = []
        for system in systems_info:
            retrieval_info = ""
            if "retrieval_methods" in system:
                methods = []
                if "semantic" in system["retrieval_methods"]:
                    methods.append("ë²¡í„°")
                if "keyword" in system["retrieval_methods"]:
                    methods.append("BM25")
                if "hybrid" in system["retrieval_methods"]:
                    methods.append("í•˜ì´ë¸Œë¦¬ë“œ")
                retrieval_info = " + ".join(methods)
            
            comparison_data.append({
                "ì‹œìŠ¤í…œ": system["name"],
                "ê²€ìƒ‰ ë°©ì‹": retrieval_info or "ë²¡í„°",
                "êµ¬ì„± ìš”ì†Œ": len(system["components"]),
                "íŠ¹í™” ê¸°ëŠ¥": len(system["features"]),
                "ë³µì¡ë„": "ë†’ìŒ" if len(system["components"]) > 4 else ("ì¤‘ê°„" if len(system["components"]) > 2 else "ë‚®ìŒ")
            })
        
        df = pd.DataFrame(comparison_data)
        st.dataframe(df, use_container_width=True)
    
    @staticmethod
    def display_performance_comparison(results: List[Dict[str, Any]]):
        """Display enhanced performance comparison of RAG results."""
        if not results:
            return
            
        st.subheader("âš¡ ì„±ëŠ¥ ë¹„êµ")
        
        # Create enhanced performance metrics
        metrics_data = []
        for result in results:
            metadata = result.get("metadata", {})
            
            # Handle different metadata keys for retrieved document count
            retrieved_count = (
                metadata.get("final_retrieved") or  # Advanced RAG
                metadata.get("num_retrieved") or    # Naive RAG
                metadata.get("total_retrieved") or  # Modular RAG
                len(result.get("retrieved_docs", []))  # Fallback to counting docs
            )
            
            # Determine search methods used
            search_methods = []
            if metadata.get("retrieval_method") == "hybrid":
                search_methods.append("ë²¡í„°+ì¬ìˆœìœ„")
            elif "semantic" in str(metadata.get("retrieval_method", "")):
                search_methods.append("ë²¡í„°")
            
            if "keyword_scores" in metadata or "bm25" in str(metadata).lower():
                search_methods.append("BM25")
                
            search_method_str = " + ".join(search_methods) if search_methods else metadata.get("retrieval_method", "ë²¡í„°")
            
            # Advanced metrics
            query_type = metadata.get("query_type", "ì¼ë°˜")
            confidence = metadata.get("final_confidence", metadata.get("confidence", 0))
            iterations = metadata.get("iterations", 1)
            compression_ratio = metadata.get("compression_ratio", 0)
            
            metrics_data.append({
                "ì‹œìŠ¤í…œ": result["rag_type"],
                "ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)": round(result["total_time"], 2),
                "ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜": retrieved_count,
                "ê²€ìƒ‰ ë°©ë²•": search_method_str,
                "ì§ˆë¬¸ ìœ í˜•": query_type,
                "ì‹ ë¢°ë„": round(confidence, 2) if confidence > 0 else "N/A",
                "ë°˜ë³µ íšŸìˆ˜": iterations,
                "ì••ì¶•ë¥ ": f"{compression_ratio:.1%}" if compression_ratio > 0 else "N/A"
            })
        
        df_metrics = pd.DataFrame(metrics_data)
        
        # Display enhanced metrics table
        st.dataframe(df_metrics, use_container_width=True)
        
        # Create enhanced performance charts
        col1, col2 = st.columns(2)
        
        with col1:
            # Processing time chart with color coding
            fig_time = px.bar(
                df_metrics, 
                x="ì‹œìŠ¤í…œ", 
                y="ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)",
                title="â±ï¸ ì²˜ë¦¬ ì‹œê°„ ë¹„êµ",
                color="ê²€ìƒ‰ ë°©ë²•",
                text="ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)"
            )
            fig_time.update_traces(texttemplate='%{text}s', textposition='outside')
            fig_time.update_layout(showlegend=True)
            st.plotly_chart(fig_time, use_container_width=True)
        
        with col2:
            # Retrieved documents chart with search method info
            fig_docs = px.bar(
                df_metrics, 
                x="ì‹œìŠ¤í…œ", 
                y="ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜",
                title="ğŸ“š ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ ë¹„êµ",
                color="ê²€ìƒ‰ ë°©ë²•",
                text="ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜"
            )
            fig_docs.update_traces(texttemplate='%{text}', textposition='outside')
            fig_docs.update_layout(showlegend=True)
            st.plotly_chart(fig_docs, use_container_width=True)
        
        # Additional performance insights
        st.write("### ğŸ¯ ì„±ëŠ¥ ì¸ì‚¬ì´íŠ¸")
        
        # Performance analysis
        insights = []
        
        # Find best performing systems
        fastest_system = min(results, key=lambda x: x["total_time"])
        most_docs_system = max(results, key=lambda x: len(x.get("retrieved_docs", [])))
        
        insights.append(f"âš¡ **ìµœê³  ì†ë„**: {fastest_system['rag_type']} ({fastest_system['total_time']:.2f}ì´ˆ)")
        insights.append(f"ğŸ“š **ìµœë‹¤ ê²€ìƒ‰**: {most_docs_system['rag_type']} ({len(most_docs_system.get('retrieved_docs', []))}ê°œ ë¬¸ì„œ)")
        
        # Check for advanced features
        for result in results:
            metadata = result.get("metadata", {})
            if metadata.get("final_confidence", 0) > 0.8:
                insights.append(f"ğŸ¯ **ê³ ì‹ ë¢°ë„**: {result['rag_type']} (ì‹ ë¢°ë„ {metadata.get('final_confidence', 0):.2f})")
            if metadata.get("iterations", 1) > 1:
                insights.append(f"ğŸ”„ **ë°˜ë³µ ê°œì„ **: {result['rag_type']} ({metadata.get('iterations')}íšŒ ë°˜ë³µ)")
            if metadata.get("compression_ratio", 0) > 0:
                insights.append(f"ğŸ“¦ **ì»¨í…ìŠ¤íŠ¸ ì••ì¶•**: {result['rag_type']} ({metadata.get('compression_ratio'):.1%} ì••ì¶•)")
        
        for insight in insights:
            st.write(insight)
    
    @staticmethod
    def display_answer_comparison(results: List[Dict[str, Any]]):
        """Display enhanced side-by-side answer comparison."""
        if not results:
            return
            
        st.subheader("ğŸ“ ë‹µë³€ ë¹„êµ")
        
        # Create tabs for each system
        if len(results) <= 3:
            tabs = st.tabs([f"{result['rag_type']}" for result in results])
            
            for tab, result in zip(tabs, results):
                with tab:
                    metadata = result.get("metadata", {})
                    
                    # Show enhanced header with key metrics
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result['total_time']:.2f}ì´ˆ")
                    with col2:
                        if metadata.get("final_confidence", 0) > 0:
                            st.metric("ì‹ ë¢°ë„", f"{metadata.get('final_confidence', 0):.2f}")
                        elif metadata.get("confidence", 0) > 0:
                            st.metric("ì‹ ë¢°ë„", f"{metadata.get('confidence', 0):.2f}")
                    with col3:
                        doc_count = (
                            metadata.get("final_retrieved") or 
                            metadata.get("total_retrieved") or 
                            len(result.get("retrieved_docs", []))
                        )
                        st.metric("ê²€ìƒ‰ ë¬¸ì„œ", f"{doc_count}ê°œ")
                    
                    st.write("**ì§ˆë¬¸:**")
                    st.write(result["question"])
                    
                    # Show query analysis for Modular RAG
                    if "query_type" in metadata:
                        st.info(f"ğŸ¯ ì§ˆë¬¸ ìœ í˜•: {metadata['query_type']}")
                    if "processing_path" in metadata:
                        st.info(f"ğŸ›¤ï¸ ì²˜ë¦¬ ê²½ë¡œ: {metadata['processing_path']}")
                    if "expansion_terms" in metadata and metadata["expansion_terms"]:
                        st.info(f"ğŸ” í™•ì¥ ìš©ì–´: {', '.join(metadata['expansion_terms'])}")
                    
                    st.write("**ë‹µë³€:**")
                    st.write(result["answer"])
                    
                    # Enhanced metadata display
                    with st.expander("ğŸ“Š ìƒì„¸ ë©”íƒ€ë°ì´í„°"):
                        for key, value in metadata.items():
                            if key == "retrieval_method":
                                st.write(f"ğŸ” ê²€ìƒ‰ ë°©ë²•: {value}")
                            elif key == "query_type":
                                st.write(f"ğŸ¯ ì§ˆë¬¸ ìœ í˜•: {value}")
                            elif key == "iterations":
                                st.write(f"ğŸ”„ ë°˜ë³µ íšŸìˆ˜: {value}")
                            elif key == "compression_ratio":
                                st.write(f"ğŸ“¦ ì••ì¶•ë¥ : {value:.1%}")
                            elif key == "rerank_scores" and isinstance(value, list):
                                st.write(f"ğŸ“ˆ ì¬ìˆœìœ„ ì ìˆ˜: {[f'{s:.3f}' for s in value[:3]]}")
                            elif key == "keyword_scores" and isinstance(value, list):
                                st.write(f"ğŸ”¤ í‚¤ì›Œë“œ ì ìˆ˜: {[f'{s:.3f}' for s in value[:3]]}")
                            elif isinstance(value, (int, float, str)) and len(str(value)) < 100:
                                st.write(f"â€¢ {key}: {value}")
                    
                    if result.get("retrieved_docs"):
                        with st.expander(f"ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ({len(result['retrieved_docs'])}ê°œ)"):
                            for i, doc in enumerate(result["retrieved_docs"][:5]):  # Show top 5
                                st.write(f"**ë¬¸ì„œ {i+1}:**")
                                st.write(f"ğŸ“‚ ì¶œì²˜: {doc.metadata.get('source', 'Unknown')}")
                                if "score" in doc.metadata:
                                    st.write(f"ğŸ“Š ì ìˆ˜: {doc.metadata['score']:.3f}")
                                st.write(f"ğŸ“„ ë‚´ìš©: {doc.page_content[:200]}...")
                                st.divider()
        else:
            # For more than 3 systems, use selectbox
            selected_system = st.selectbox(
                "ë¹„êµí•  ì‹œìŠ¤í…œ ì„ íƒ:",
                [result["rag_type"] for result in results]
            )
            
            selected_result = next(r for r in results if r["rag_type"] == selected_system)
            
            st.write("**ì§ˆë¬¸:**")
            st.write(selected_result["question"])
            
            st.write("**ë‹µë³€:**")
            st.write(selected_result["answer"])
            
            st.write("**ë©”íƒ€ë°ì´í„°:**")
            metadata = selected_result.get("metadata", {})
            for key, value in metadata.items():
                if isinstance(value, (int, float, str)):
                    st.write(f"â€¢ {key}: {value}")
    
    @staticmethod
    def create_processing_flow_diagram(rag_type: str):
        """Create an enhanced processing flow diagram for the RAG system."""
        st.subheader(f"ğŸ”„ {rag_type} ì²˜ë¦¬ íë¦„")
        
        if rag_type == "Naive RAG":
            flow_steps = [
                "ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸",
                "ğŸ§  ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰",
                "ğŸ“š ë¬¸ì„œ ê²€ìƒ‰",
                "ğŸ¤– LLM ë‹µë³€ ìƒì„±",
                "âœ… ìµœì¢… ë‹µë³€"
            ]
            description = "ë‹¨ìˆœí•˜ê³  ë¹ ë¥¸ ê²€ìƒ‰ â†’ ìƒì„± íŒŒì´í”„ë¼ì¸"
            
        elif rag_type == "Advanced RAG":
            flow_steps = [
                "ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸",
                "ğŸ”§ ì¿¼ë¦¬ ì „ì²˜ë¦¬ & ìµœì í™”",
                "ğŸ§  ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰",
                "ğŸ”€ í•˜ì´ë¸Œë¦¬ë“œ ì¬ìˆœìœ„í™”<br/>(TF-IDF + ë²¡í„°)",
                "ğŸ“¦ ì»¨í…ìŠ¤íŠ¸ ì••ì¶•",
                "ğŸ¤– ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±",
                "âœ… ìµœì¢… ë‹µë³€"
            ]
            description = "Enhanced Search: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + ì••ì¶• + ìŠ¤íŠ¸ë¦¬ë°"
            
        elif rag_type == "Modular RAG":
            flow_steps = [
                "ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸",
                "ğŸ¯ ì¿¼ë¦¬ ë¶„ë¥˜ & í™•ì¥<br/>(7ê°€ì§€ ìœ í˜•)",
                "ğŸ›¤ï¸ ë¼ìš°íŒ… ê²°ì •<br/>(ì²˜ë¦¬ ê²½ë¡œ ì„ íƒ)",
                "ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰<br/>(ë²¡í„° + BM25)",
                "ğŸ”§ í•„í„°ë§ & ë‹¤ì–‘ì„±",
                "ğŸ¤– ìœ í˜•ë³„ ë§ì¶¤ ìƒì„±",
                "ğŸ“Š ì‹ ë¢°ë„ í‰ê°€",
                "ğŸ”„ ë°˜ë³µ ì œì–´<br/>(ì‹ ë¢°ë„ < 0.7ì‹œ ì¬ì‹œë„)",
                "âœ… ìµœì¢… ë‹µë³€"
            ]
            description = "ëª¨ë“ˆí˜• ì•„í‚¤í…ì²˜: ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì í™” + ë°˜ë³µì  ê°œì„ "
            
        else:
            flow_steps = ["ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸", "ğŸ”§ ì²˜ë¦¬", "âœ… ìµœì¢… ë‹µë³€"]
            description = "ê¸°ë³¸ ì²˜ë¦¬ íë¦„"
        
        st.info(f"**íŠ¹ì§•**: {description}")
        
        # Create an enhanced flow diagram
        num_cols = min(len(flow_steps), 4)  # Max 4 columns per row
        rows = [flow_steps[i:i+num_cols] for i in range(0, len(flow_steps), num_cols)]
        
        for row_idx, row in enumerate(rows):
            cols = st.columns(len(row))
            for i, (col, step) in enumerate(zip(cols, row)):
                with col:
                    step_num = row_idx * num_cols + i + 1
                    
                    # Use different colors for different types of steps
                    if "ì§ˆë¬¸" in step:
                        st.markdown(f"""
                        <div style="background-color: #e3f2fd; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;">
                        <strong>{step_num}.</strong><br/>{step}
                        </div>
                        """, unsafe_allow_html=True)
                    elif "ê²€ìƒ‰" in step or "BM25" in step:
                        st.markdown(f"""
                        <div style="background-color: #f3e5f5; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;">
                        <strong>{step_num}.</strong><br/>{step}
                        </div>
                        """, unsafe_allow_html=True)
                    elif "ìƒì„±" in step or "ë‹µë³€" in step:
                        st.markdown(f"""
                        <div style="background-color: #e8f5e8; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;">
                        <strong>{step_num}.</strong><br/>{step}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div style="background-color: #fff3e0; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;">
                        <strong>{step_num}.</strong><br/>{step}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Add arrow except for last step
                    if step_num < len(flow_steps):
                        if i == len(row) - 1 and row_idx < len(rows) - 1:
                            # End of row, point down
                            st.markdown("<div style='text-align: center; font-size: 20px;'>â¬‡ï¸</div>", unsafe_allow_html=True)
                        elif i < len(row) - 1:
                            # Within row, point right
                            st.markdown("<div style='text-align: center; font-size: 20px;'>â¡ï¸</div>", unsafe_allow_html=True)
    
    @staticmethod
    def display_detailed_metrics(result: Dict[str, Any]):
        """Display enhanced detailed metrics for a single result."""
        st.subheader(f"ğŸ“Š {result['rag_type']} ìƒì„¸ ë©”íŠ¸ë¦­")
        
        metadata = result.get("metadata", {})
        
        # Enhanced basic metrics
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("â±ï¸ ì²˜ë¦¬ ì‹œê°„", f"{result['total_time']:.2f}ì´ˆ")
        
        with col2:
            retrieved_count = (
                metadata.get("final_retrieved") or  
                metadata.get("num_retrieved") or    
                metadata.get("total_retrieved") or  
                len(result.get("retrieved_docs", []))
            )
            st.metric("ğŸ“š ê²€ìƒ‰ ë¬¸ì„œ", f"{retrieved_count}ê°œ")
        
        with col3:
            if "confidence" in metadata or "final_confidence" in metadata:
                confidence = metadata.get("final_confidence", metadata.get("confidence", 0))
                st.metric("ğŸ¯ ì‹ ë¢°ë„", f"{confidence:.2f}")
        
        with col4:
            if "iterations" in metadata:
                st.metric("ğŸ”„ ë°˜ë³µ íšŸìˆ˜", f"{metadata['iterations']}íšŒ")
            elif "compression_ratio" in metadata:
                st.metric("ğŸ“¦ ì••ì¶•ë¥ ", f"{metadata['compression_ratio']:.1%}")
        
        with col5:
            if "query_type" in metadata:
                st.metric("ğŸ¯ ì§ˆë¬¸ ìœ í˜•", metadata["query_type"])
        
        # Advanced metrics section
        if metadata:
            st.write("### ğŸ” ê³ ê¸‰ ë©”íŠ¸ë¦­")
            
            # Create metrics categories
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ğŸ”§ ì²˜ë¦¬ ì •ë³´:**")
                if "retrieval_method" in metadata:
                    st.write(f"â€¢ ê²€ìƒ‰ ë°©ë²•: {metadata['retrieval_method']}")
                if "processing_path" in metadata:
                    st.write(f"â€¢ ì²˜ë¦¬ ê²½ë¡œ: {metadata['processing_path']}")
                if "expansion_terms" in metadata and metadata["expansion_terms"]:
                    st.write(f"â€¢ í™•ì¥ ìš©ì–´: {', '.join(metadata['expansion_terms'][:5])}")
                if "generation_method" in metadata:
                    st.write(f"â€¢ ìƒì„± ë°©ë²•: {metadata['generation_method']}")
            
            with col2:
                st.write("**ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:**")
                if "rerank_scores" in metadata and isinstance(metadata["rerank_scores"], list):
                    avg_rerank = sum(metadata["rerank_scores"]) / len(metadata["rerank_scores"])
                    st.write(f"â€¢ í‰ê·  ì¬ìˆœìœ„ ì ìˆ˜: {avg_rerank:.3f}")
                if "keyword_scores" in metadata and isinstance(metadata["keyword_scores"], list):
                    avg_keyword = sum(metadata["keyword_scores"]) / len(metadata["keyword_scores"])
                    st.write(f"â€¢ í‰ê·  í‚¤ì›Œë“œ ì ìˆ˜: {avg_keyword:.3f}")
                if "context_length" in metadata:
                    st.write(f"â€¢ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {metadata['context_length']} í† í°")
        
        # Visualization of search results if available
        if "rerank_scores" in metadata or "keyword_scores" in metadata:
            st.write("### ğŸ“ˆ ê²€ìƒ‰ ì ìˆ˜ ë¶„í¬")
            
            score_data = []
            if "rerank_scores" in metadata:
                for i, score in enumerate(metadata["rerank_scores"][:10]):
                    score_data.append({"ë¬¸ì„œ": f"Doc {i+1}", "ì¬ìˆœìœ„ ì ìˆ˜": score, "ìœ í˜•": "ì¬ìˆœìœ„"})
            
            if "keyword_scores" in metadata:
                for i, score in enumerate(metadata["keyword_scores"][:10]):
                    if i < len(score_data):
                        score_data[i]["í‚¤ì›Œë“œ ì ìˆ˜"] = score
                    else:
                        score_data.append({"ë¬¸ì„œ": f"Doc {i+1}", "í‚¤ì›Œë“œ ì ìˆ˜": score, "ìœ í˜•": "í‚¤ì›Œë“œ"})
            
            if score_data:
                df_scores = pd.DataFrame(score_data)
                
                if "ì¬ìˆœìœ„ ì ìˆ˜" in df_scores.columns and "í‚¤ì›Œë“œ ì ìˆ˜" in df_scores.columns:
                    # Dual score visualization
                    fig = go.Figure()
                    fig.add_trace(go.Bar(
                        name='ì¬ìˆœìœ„ ì ìˆ˜',
                        x=df_scores['ë¬¸ì„œ'],
                        y=df_scores['ì¬ìˆœìœ„ ì ìˆ˜'],
                        yaxis='y'
                    ))
                    fig.add_trace(go.Bar(
                        name='í‚¤ì›Œë“œ ì ìˆ˜',
                        x=df_scores['ë¬¸ì„œ'],
                        y=df_scores['í‚¤ì›Œë“œ ì ìˆ˜'],
                        yaxis='y2'
                    ))
                    
                    fig.update_layout(
                        xaxis=dict(title='ë¬¸ì„œ'),
                        yaxis=dict(title='ì¬ìˆœìœ„ ì ìˆ˜', side='left'),
                        yaxis2=dict(title='í‚¤ì›Œë“œ ì ìˆ˜', side='right', overlaying='y'),
                        title='ë¬¸ì„œë³„ ê²€ìƒ‰ ì ìˆ˜ ë¹„êµ'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    # Single score type
                    score_col = "ì¬ìˆœìœ„ ì ìˆ˜" if "ì¬ìˆœìœ„ ì ìˆ˜" in df_scores.columns else "í‚¤ì›Œë“œ ì ìˆ˜"
                    fig = px.bar(df_scores, x="ë¬¸ì„œ", y=score_col, title=f"ë¬¸ì„œë³„ {score_col}")
                    st.plotly_chart(fig, use_container_width=True)
    
    @staticmethod
    def create_summary_report(results: List[Dict[str, Any]]):
        """Create an enhanced summary report of all results."""
        if not results:
            return
            
        st.subheader("ğŸ“‹ ì‹¤í—˜ ìš”ì•½ ë³´ê³ ì„œ")
        
        # Enhanced summary statistics
        total_systems = len(results)
        avg_time = sum(r["total_time"] for r in results) / total_systems
        total_docs = sum(len(r.get("retrieved_docs", [])) for r in results)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ", f"{total_systems}ê°œ")
        with col2:
            st.metric("â±ï¸ í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{avg_time:.2f}ì´ˆ")
        with col3:
            st.metric("ğŸ“š ì´ ê²€ìƒ‰ ë¬¸ì„œ", f"{total_docs}ê°œ")
        with col4:
            avg_docs = total_docs / total_systems if total_systems > 0 else 0
            st.metric("ğŸ“„ í‰ê·  ë¬¸ì„œìˆ˜", f"{avg_docs:.1f}ê°œ")
        
        # Enhanced performance analysis
        st.write("### ğŸ† ì„±ëŠ¥ ë¶„ì„")
        
        fastest_system = min(results, key=lambda x: x["total_time"])
        most_docs_system = max(results, key=lambda x: len(x.get("retrieved_docs", [])))
        
        # Advanced analysis
        analysis_results = []
        
        for result in results:
            metadata = result.get("metadata", {})
            analysis = {
                "ì‹œìŠ¤í…œ": result["rag_type"],
                "ì†ë„": "ğŸš€ ë¹ ë¦„" if result["total_time"] < avg_time else "ğŸ¢ ëŠë¦¼",
                "ê²€ìƒ‰ëŸ‰": "ğŸ“š ë§ìŒ" if len(result.get("retrieved_docs", [])) > avg_docs else "ğŸ“„ ì ìŒ",
                "íŠ¹ìˆ˜ê¸°ëŠ¥": []
            }
            
            # Check for special features
            if metadata.get("final_confidence", 0) > 0.7:
                analysis["íŠ¹ìˆ˜ê¸°ëŠ¥"].append("ğŸ¯ ê³ ì‹ ë¢°ë„")
            if metadata.get("iterations", 1) > 1:
                analysis["íŠ¹ìˆ˜ê¸°ëŠ¥"].append("ğŸ”„ ë°˜ë³µê°œì„ ")
            if metadata.get("compression_ratio", 0) > 0:
                analysis["íŠ¹ìˆ˜ê¸°ëŠ¥"].append("ğŸ“¦ ì••ì¶•")
            if "bm25" in str(metadata).lower() or "keyword" in str(metadata).lower():
                analysis["íŠ¹ìˆ˜ê¸°ëŠ¥"].append("ğŸ”¤ í‚¤ì›Œë“œê²€ìƒ‰")
            if metadata.get("query_type") != "general":
                analysis["íŠ¹ìˆ˜ê¸°ëŠ¥"].append("ğŸ¯ ì§ˆë¬¸ë¶„ë¥˜")
            
            analysis_results.append(analysis)
        
        # Display analysis
        for analysis in analysis_results:
            feature_text = " ".join(analysis["íŠ¹ìˆ˜ê¸°ëŠ¥"]) if analysis["íŠ¹ìˆ˜ê¸°ëŠ¥"] else "ê¸°ë³¸"
            st.write(f"**{analysis['ì‹œìŠ¤í…œ']}**: {analysis['ì†ë„']} | {analysis['ê²€ìƒ‰ëŸ‰']} | {feature_text}")
        
        # System recommendations
        st.write("### ğŸ’¡ ì‹œìŠ¤í…œ ì„ íƒ ê°€ì´ë“œ")
        
        recommendations = []
        
        if fastest_system["rag_type"] == "Naive RAG":
            recommendations.append("âš¡ **ë¹ ë¥¸ ì‘ë‹µì´ ìµœìš°ì„ **ì¸ ê²½ìš° â†’ Naive RAG")
        
        # Check for Advanced RAG features
        for result in results:
            if "Advanced" in result["rag_type"]:
                metadata = result.get("metadata", {})
                if metadata.get("compression_ratio", 0) > 0:
                    recommendations.append("ğŸ“¦ **ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì˜ ê· í˜•**ì´ í•„ìš”í•œ ê²½ìš° â†’ Advanced RAG")
                break
        
        # Check for Modular RAG features
        for result in results:
            if "Modular" in result["rag_type"]:
                metadata = result.get("metadata", {})
                if metadata.get("iterations", 1) > 1:
                    recommendations.append("ğŸ”„ **ë³µì¡í•œ ì§ˆë¬¸ê³¼ ë†’ì€ ì •í™•ì„±**ì´ í•„ìš”í•œ ê²½ìš° â†’ Modular RAG")
                if metadata.get("query_type") != "general":
                    recommendations.append("ğŸ¯ **ë‹¤ì–‘í•œ ì§ˆë¬¸ ìœ í˜•**ì„ ë‹¤ë£¨ëŠ” ê²½ìš° â†’ Modular RAG")
                break
        
        # Check for hybrid search
        hybrid_systems = [r for r in results if "hybrid" in str(r.get("metadata", {})).lower()]
        if hybrid_systems:
            recommendations.append("ğŸ” **ì˜ë¯¸ì  + í‚¤ì›Œë“œ ê²€ìƒ‰**ì´ ëª¨ë‘ í•„ìš”í•œ ê²½ìš° â†’ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ")
        
        for rec in recommendations:
            st.write(rec)
        
        # Performance summary table
        st.write("### ğŸ“Š ì¢…í•© ì„±ëŠ¥í‘œ")
        summary_data = []
        for result in results:
            metadata = result.get("metadata", {})
            summary_data.append({
                "ì‹œìŠ¤í…œ": result["rag_type"],
                "ì²˜ë¦¬ì‹œê°„": f"{result['total_time']:.2f}s",
                "ê²€ìƒ‰ë¬¸ì„œ": len(result.get("retrieved_docs", [])),
                "ì‹ ë¢°ë„": f"{metadata.get('final_confidence', metadata.get('confidence', 0)):.2f}",
                "íŠ¹ì§•": ", ".join([
                    "í•˜ì´ë¸Œë¦¬ë“œ" if "hybrid" in str(metadata).lower() else "",
                    "ë°˜ë³µ" if metadata.get("iterations", 1) > 1 else "",
                    "ì••ì¶•" if metadata.get("compression_ratio", 0) > 0 else "",
                    "ë¶„ë¥˜" if metadata.get("query_type", "general") != "general" else ""
                ]).strip(", ") or "ê¸°ë³¸"
            })
        
        df_summary = pd.DataFrame(summary_data)
        st.dataframe(df_summary, use_container_width=True) 