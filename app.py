"""Main Streamlit application for RAG systems comparison."""

import streamlit as st
import os
from pathlib import Path
import base64
import pandas as pd
from datetime import datetime
import json
from typing import Optional

# Disable ChromaDB telemetry at app startup to prevent telemetry errors
os.environ["ANONYMIZED_TELEMETRY"] = "False"
os.environ["CHROMA_TELEMETRY"] = "False"
os.environ["CHROMA_SERVER_NOFILE"] = "1"

# Import our modules
from src.config import *
from src.utils.document_processor import DocumentProcessor
from src.utils.embeddings import EmbeddingManager
from src.utils.vector_store import VectorStoreManager
from src.utils.llm_manager import LLMManager
from src.utils.font_utils import apply_custom_css
from src.rag_systems.naive_rag import NaiveRAG
from src.rag_systems.advanced_rag import AdvancedRAG
from src.rag_systems.modular_rag import ModularRAG
from src.ui.comparison_ui import ComparisonUI
from src.ui.about_ui import AboutUI


def load_custom_font():
    """Load custom font if available."""
    return apply_custom_css()


def get_or_create_vector_store_manager() -> Optional[VectorStoreManager]:
    """Get or create vector store manager with lazy loading.
    
    Returns:
        VectorStoreManager instance or None if creation fails
    """
    if "vector_store_manager" not in st.session_state:
        try:
            # Initialize embeddings lazily
            embedding_manager = EmbeddingManager(EMBEDDING_MODEL, MODELS_FOLDER)
            embeddings = embedding_manager.get_embeddings()
            
            # Initialize vector store manager
            st.session_state.vector_store_manager = VectorStoreManager(
                embeddings=embeddings,
                vector_store_type=st.session_state.get("vector_store_type", "faiss"),
                collection_name="rag_documents"
            )
            st.session_state.embedding_manager = embedding_manager
            
        except Exception as e:
            st.error(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return None
    
    return st.session_state.get("vector_store_manager")


def initialize_session_state():
    """Initialize session state variables."""
    if "documents_loaded" not in st.session_state:
        st.session_state.documents_loaded = False
    if "vector_store_created" not in st.session_state:
        st.session_state.vector_store_created = False
    if "rag_systems" not in st.session_state:
        st.session_state.rag_systems = {}
    if "experiment_results" not in st.session_state:
        st.session_state.experiment_results = []
    if "documents" not in st.session_state:
        st.session_state.documents = []
    if "document_chunks" not in st.session_state:
        st.session_state.document_chunks = []
    # vector_store_managerëŠ” ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì²˜ë¦¬ (í•„ìš”í•  ë•Œë§Œ ìƒì„±)


def setup_page():
    """Setup page configuration."""
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Apply custom font globally first
    font_loaded = apply_custom_css()
    
    # Display title with custom styling
    if font_loaded:
        st.markdown('<h1 class="main-title">ğŸ¤– RAG Systems Comparison Tool</h1>', unsafe_allow_html=True)
        st.markdown('<p class="subtitle">ë‹¨ê³„ë³„ Naive RAG, Advanced RAG, Modular RAG ë¹„êµ ì‹¤í—˜ ì• í”Œë¦¬ì¼€ì´ì…˜</p>', unsafe_allow_html=True)
    else:
        st.title("ğŸ¤– RAG Systems Comparison Tool")
        st.subheader("ë‹¨ê³„ë³„ Naive RAG, Advanced RAG, Modular RAG ë¹„êµ ì‹¤í—˜ ì• í”Œë¦¬ì¼€ì´ì…˜")


def setup_sidebar():
    """Setup sidebar with system information."""
    st.sidebar.title("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # Model Selection
    st.sidebar.subheader("ğŸ¤– ëª¨ë¸ ì„ íƒ")
    selected_model_name = st.sidebar.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ:",
        options=list(AVAILABLE_LLM_MODELS.keys()),
        index=list(AVAILABLE_LLM_MODELS.values()).index(DEFAULT_LLM_MODEL) if DEFAULT_LLM_MODEL in AVAILABLE_LLM_MODELS.values() else 0
    )
    selected_model = AVAILABLE_LLM_MODELS[selected_model_name]
    
    # LLM Temperature
    st.sidebar.subheader("ğŸ”¥ LLM Temperature")
    temperature = st.sidebar.slider(
        "Temperature (ì°½ì˜ì„±)", min_value=0.0, max_value=1.0, value=st.session_state.get("llm_temperature", 0.1), step=0.05
    )
    st.session_state.llm_temperature = temperature
    st.sidebar.write(f"í˜„ì¬ ê°’: {temperature}")
    
    # Vector Store Type
    st.sidebar.subheader("ğŸ—„ï¸ ë²¡í„° ìŠ¤í† ì–´ íƒ€ì…")
    vector_store_type = st.sidebar.radio(
        "Vector Store ì—”ì§„ ì„ íƒ:",
        options=["faiss", "chroma"],
        index=["faiss", "chroma"].index(st.session_state.get("vector_store_type", "faiss"))
    )
    st.session_state.vector_store_type = vector_store_type
    st.sidebar.write(f"í˜„ì¬ ì„ íƒ: {vector_store_type}")
    
    # Chunk Size
    st.sidebar.subheader("ğŸ”ª ì²­í¬ í¬ê¸° (Chunk Size)")
    chunk_size = st.sidebar.slider(
        "ì²­í¬ í¬ê¸°:", min_value=256, max_value=4096, value=st.session_state.get("chunk_size", CHUNK_SIZE), step=64
    )
    st.session_state.chunk_size = chunk_size
    st.sidebar.write(f"í˜„ì¬ ê°’: {chunk_size}")
    
    # Chunk Overlap
    st.sidebar.subheader("ğŸ”— ì²­í¬ ì˜¤ë²„ë© (Chunk Overlap)")
    chunk_overlap = st.sidebar.slider(
        "ì˜¤ë²„ë©:", min_value=0, max_value=1024, value=st.session_state.get("chunk_overlap", CHUNK_OVERLAP), step=16
    )
    st.session_state.chunk_overlap = chunk_overlap
    st.sidebar.write(f"í˜„ì¬ ê°’: {chunk_overlap}")
    
    # Top-K (ê²€ìƒ‰ ìˆ˜)
    st.sidebar.subheader("ğŸ” ê²€ìƒ‰ ìˆ˜ (Top-K)")
    top_k = st.sidebar.slider(
        "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜:", min_value=1, max_value=30, value=st.session_state.get("top_k", DEFAULT_K), step=1
    )
    st.session_state.top_k = top_k
    st.sidebar.write(f"í˜„ì¬ ê°’: {top_k}")
    
    # Store selected model in session state
    if "selected_llm_model" not in st.session_state:
        st.session_state.selected_llm_model = selected_model
    elif st.session_state.selected_llm_model != selected_model:
        st.session_state.selected_llm_model = selected_model
        # Clear cached LLM when model changes
        if "llm_manager" in st.session_state:
            del st.session_state.llm_manager
    
    # LLM Status
    st.sidebar.subheader("ğŸ§  LLM ìƒíƒœ")
    llm_manager = LLMManager(st.session_state.selected_llm_model, OLLAMA_BASE_URL, temperature=st.session_state.llm_temperature)
    llm_info = llm_manager.get_model_info()
    
    if llm_info["connection_status"]:
        st.sidebar.success("âœ… Ollama ì„œë²„ ì—°ê²°ë¨")
        if llm_info["model_available"]:
            st.sidebar.success(f"âœ… ëª¨ë¸ '{st.session_state.selected_llm_model}' ì‚¬ìš© ê°€ëŠ¥")
        else:
            st.sidebar.error(f"âŒ ëª¨ë¸ '{st.session_state.selected_llm_model}' ì—†ìŒ")
            if st.sidebar.button("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"):
                with st.spinner("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                    if llm_manager.pull_model():
                        st.sidebar.success("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                        st.rerun()
                    else:
                        st.sidebar.error("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
    else:
        st.sidebar.error("âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
        st.sidebar.code(f"ollama serve")
    
    # Document Status
    st.sidebar.subheader("ğŸ“š ë¬¸ì„œ ìƒíƒœ")
    if st.session_state.documents_loaded:
        st.sidebar.success(f"âœ… {len(st.session_state.documents)}ê°œ ë¬¸ì„œ ë¡œë”©ë¨")
        st.sidebar.success(f"âœ… {len(st.session_state.document_chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
    else:
        st.sidebar.warning("âš ï¸ ë¬¸ì„œê°€ ë¡œë”©ë˜ì§€ ì•ŠìŒ")
    
    # Vector Store Status
    if st.session_state.vector_store_created:
        st.sidebar.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„±ë¨")
    else:
        st.sidebar.warning("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ ë¯¸ìƒì„±")
    
    # Configuration
    st.sidebar.subheader("ğŸ”§ ì„¤ì •")
    st.sidebar.write(f"**ì„ë² ë”© ëª¨ë¸:** {EMBEDDING_MODEL}")
    st.sidebar.write(f"**ì²­í¬ í¬ê¸°:** {chunk_size}")
    st.sidebar.write(f"**ì²­í¬ ì˜¤ë²„ë©:** {chunk_overlap}")
    st.sidebar.write(f"**ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜:** {top_k}")


def load_documents_tab():
    """Enhanced document loading tab with JSON functionality."""
    st.header("ğŸ“š ë¬¸ì„œ ë¡œë”© ë° ì „ì²˜ë¦¬")
    
    # Create JSON output folder if it doesn't exist
    JSON_OUTPUT_FOLDER.mkdir(exist_ok=True)
    
    # Data source selection
    st.subheader("ğŸ¯ ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“– ìƒˆ PDF ë¡œë”©", "ğŸ“„ JSON ë¡œë”©", "ğŸ—‚ï¸ JSON ê´€ë¦¬"])
    
    with tab1:
        st.write("### ğŸ“ PDF íŒŒì¼ì—ì„œ ìƒˆë¡œ ë¡œë”©")
        
        # Document folder info
        st.info(f"ğŸ“‚ ë¬¸ì„œ í´ë”: {DOCS_FOLDER}")
        
        if not DOCS_FOLDER.exists():
            st.error(f"ë¬¸ì„œ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {DOCS_FOLDER}")
            return
        
        # List available documents
        pdf_files = list(DOCS_FOLDER.glob("*.pdf"))
        st.write(f"ğŸ“š **ì‚¬ìš© ê°€ëŠ¥í•œ PDF íŒŒì¼ ({len(pdf_files)}ê°œ):**")
        
        if pdf_files:
            # Display PDF files with details and selection
            pdf_data = []
            for pdf_file in pdf_files:
                file_size = pdf_file.stat().st_size / (1024 * 1024)  # MB
                pdf_data.append({
                    "íŒŒì¼ëª…": pdf_file.name,
                    "í¬ê¸° (MB)": f"{file_size:.1f}",
                    "ìˆ˜ì •ì¼": datetime.fromtimestamp(pdf_file.stat().st_mtime).strftime("%Y-%m-%d %H:%M")
                })
            
            df_pdfs = pd.DataFrame(pdf_data)
            st.dataframe(df_pdfs, use_container_width=True)
            
            # File selection
            st.write("### ğŸ¯ ë¡œë”©í•  íŒŒì¼ ì„ íƒ")
            
            # Select all option
            select_all = st.checkbox("ğŸ“‚ ëª¨ë“  íŒŒì¼ ì„ íƒ", value=True)
            
            # Individual file selection
            if select_all:
                selected_files = [f.name for f in pdf_files]
            else:
                selected_files = st.multiselect(
                    "ë¡œë”©í•  PDF íŒŒì¼ ì„ íƒ:",
                    options=[f.name for f in pdf_files],
                    default=[]
                )
            
            # Display selected files info
            if selected_files:
                st.write(f"**ì„ íƒëœ íŒŒì¼:** {len(selected_files)}ê°œ")
                selected_size = 0
                for file_name in selected_files:
                    file_path = DOCS_FOLDER / file_name
                    selected_size += file_path.stat().st_size / (1024 * 1024)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ“„ ì„ íƒëœ íŒŒì¼ ìˆ˜", len(selected_files))
                with col2:
                    st.metric("ğŸ“Š ì´ í¬ê¸°", f"{selected_size:.1f} MB")
                with col3:
                    st.metric("ğŸ“ˆ ì „ì²´ ëŒ€ë¹„", f"{len(selected_files)/len(pdf_files)*100:.0f}%")
                
                # Show selected files list
                with st.expander("ğŸ“‹ ì„ íƒëœ íŒŒì¼ ëª©ë¡"):
                    for file_name in selected_files:
                        st.write(f"â€¢ {file_name}")
            else:
                st.warning("âš ï¸ ë¡œë”©í•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            
            # JSON save options (only show if files are selected)
            if selected_files:
                st.write("### âš™ï¸ ì²˜ë¦¬ ì˜µì…˜")
                
                # Generate default filenames based on selected files
                if len(selected_files) == 1:
                    # Single file
                    file_base = selected_files[0].replace('.pdf', '')
                    default_docs_name = f"documents_{file_base}_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
                    default_chunks_name = f"chunks_{file_base}_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
                else:
                    # Multiple files
                    default_docs_name = f"documents_{len(selected_files)}files_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
                    default_chunks_name = f"chunks_{len(selected_files)}files_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
                
                col1, col2 = st.columns(2)
                
                with col1:
                    save_docs_json = st.checkbox("ğŸ“„ ì›ë³¸ ë¬¸ì„œë¥¼ JSONìœ¼ë¡œ ì €ì¥", value=True)
                    if save_docs_json:
                        docs_json_name = st.text_input(
                            "ì›ë³¸ JSON íŒŒì¼ëª…:", 
                            value=default_docs_name
                        )
                
                with col2:
                    save_chunks_json = st.checkbox("ğŸ§© ì²­í¬ë¥¼ JSONìœ¼ë¡œ ì €ì¥", value=True)
                    if save_chunks_json:
                        chunks_json_name = st.text_input(
                            "ì²­í¬ JSON íŒŒì¼ëª…:", 
                            value=default_chunks_name
                        )
            
            # Load documents button
            load_disabled = not selected_files if 'selected_files' in locals() else True
            
            if st.button("ğŸš€ PDF ë¬¸ì„œ ë¡œë”© ì‹œì‘", type="primary", disabled=load_disabled):
                if not selected_files:
                    st.warning("âš ï¸ ë¡œë”©í•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    return
                
                # Initialize document processor
                doc_processor = DocumentProcessor(st.session_state.chunk_size, st.session_state.chunk_overlap)
                
                # Create temporary folder with selected files only
                selected_file_paths = [DOCS_FOLDER / file_name for file_name in selected_files]
                
                # Load only selected documents
                st.write(f"ğŸ“– **{len(selected_files)}ê°œ íŒŒì¼ ë¡œë”© ì‹œì‘**")
                
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                documents = []
                loaded_count = 0
                
                for i, file_path in enumerate(selected_file_paths):
                    try:
                        status_text.text(f"ğŸ“„ ë¡œë”© ì¤‘: {file_path.name} ({i+1}/{len(selected_files)})")
                        file_docs = doc_processor.load_documents_from_file(file_path)
                        documents.extend(file_docs)
                        loaded_count += 1
                        
                        # Update progress
                        progress = (i + 1) / len(selected_files)
                        progress_bar.progress(progress)
                        
                        st.write(f"âœ… {file_path.name} ë¡œë”© ì™„ë£Œ ({len(file_docs)}ê°œ í˜ì´ì§€)")
                        
                    except Exception as e:
                        st.error(f"âŒ {file_path.name} ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                        continue
                
                # Clear progress indicators
                progress_bar.empty()
                status_text.empty()
                
                st.write(f"ğŸ“Š **ë¡œë”© ì™„ë£Œ: {loaded_count}/{len(selected_files)}ê°œ íŒŒì¼**")
                
                if documents:
                    st.session_state.documents = documents
                    
                    # Save documents to JSON if requested
                    if save_docs_json:
                        docs_json_path = JSON_OUTPUT_FOLDER / docs_json_name
                        doc_processor.save_documents_to_json(documents, docs_json_path)
                    
                    # Display document statistics
                    stats = doc_processor.get_document_stats(documents)
                    
                    st.write("### ğŸ“Š ë¡œë”© ê²°ê³¼ í†µê³„")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ“„ ì´ í˜ì´ì§€ ìˆ˜", stats["total_documents"])
                    with col2:
                        st.metric("ğŸ“ ì´ ë¬¸ì ìˆ˜", f"{stats['total_characters']:,}")
                    with col3:
                        st.metric("ğŸ“ í‰ê·  ë¬¸ì/í˜ì´ì§€", f"{stats['average_chars_per_doc']:,.0f}")
                    with col4:
                        st.metric("ğŸ“ ë¡œë”©ëœ íŒŒì¼", len(selected_files))
                    
                    # Display loaded files details
                    st.write("### ğŸ“‹ ë¡œë”©ëœ íŒŒì¼ ìƒì„¸")
                    loaded_files_data = []
                    for file_name in selected_files:
                        file_docs = [doc for doc in documents if doc.metadata.get('source') == file_name]
                        if file_docs:
                            file_chars = sum(len(doc.page_content) for doc in file_docs)
                            loaded_files_data.append({
                                "íŒŒì¼ëª…": file_name,
                                "í˜ì´ì§€ ìˆ˜": len(file_docs),
                                "ë¬¸ì ìˆ˜": f"{file_chars:,}",
                                "í‰ê·  ë¬¸ì/í˜ì´ì§€": f"{file_chars/len(file_docs):,.0f}" if file_docs else "0"
                            })
                    
                    if loaded_files_data:
                        df_loaded = pd.DataFrame(loaded_files_data)
                        st.dataframe(df_loaded, use_container_width=True)
                    
                    # Split documents
                    with st.spinner("ğŸ§© ë¬¸ì„œ ì²­í¬ ë¶„í•  ì¤‘..."):
                        chunks = doc_processor.split_documents(documents)
                    
                    st.session_state.document_chunks = chunks
                    st.session_state.documents_loaded = True
                    
                    # Save chunks to JSON if requested
                    if save_chunks_json:
                        chunks_json_path = JSON_OUTPUT_FOLDER / chunks_json_name
                        doc_processor.save_chunks_to_json(chunks, chunks_json_path)
                    
                    # Display chunk statistics
                    st.write("### ğŸ§© ì²­í¬ ë¶„í•  ê²°ê³¼")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ§© ì´ ì²­í¬ ìˆ˜", len(chunks))
                    with col2:
                        avg_chunk_size = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)
                        st.metric("ğŸ“ í‰ê·  ì²­í¬ í¬ê¸°", f"{avg_chunk_size:.0f}")
                    with col3:
                        chunks_per_file = len(chunks) / len(selected_files)
                        st.metric("ğŸ“Š íŒŒì¼ë‹¹ ì²­í¬", f"{chunks_per_file:.1f}")
                    with col4:
                        st.metric("âš™ï¸ ì²­í¬ ì„¤ì •", f"{st.session_state.chunk_size}/{st.session_state.chunk_overlap}")
                    
                    st.success(f"âœ… {len(selected_files)}ê°œ íŒŒì¼ì˜ ë¬¸ì„œ ë¡œë”© ë° ì „ì²˜ë¦¬ ì™„ë£Œ! ({len(chunks)}ê°œ ì²­í¬ ìƒì„±)")
                else:
                    st.error("âŒ ë¬¸ì„œ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ğŸ“­ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab2:
        st.write("### ğŸ“„ ê¸°ì¡´ JSON íŒŒì¼ì—ì„œ ë¡œë”©")
        
        # List available JSON files
        json_files = list(JSON_OUTPUT_FOLDER.glob("*.json"))
        
        if json_files:
            st.write(f"ğŸ“ **ì‚¬ìš© ê°€ëŠ¥í•œ JSON íŒŒì¼ ({len(json_files)}ê°œ):**")
            
            # JSON file selection
            selected_json = st.selectbox(
                "ë¡œë”©í•  JSON íŒŒì¼ ì„ íƒ:",
                options=[f.name for f in json_files],
                key="json_file_selector"
            )
            
            if selected_json:
                json_path = JSON_OUTPUT_FOLDER / selected_json
                doc_processor = DocumentProcessor(st.session_state.chunk_size, st.session_state.chunk_overlap)
                
                # Get JSON file info
                json_info = doc_processor.get_json_info(json_path)
                if json_info:
                    st.write("### ğŸ“‹ JSON íŒŒì¼ ì •ë³´")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ğŸ“ íŒŒì¼ í¬ê¸°", f"{json_info['file_size_mb']:.1f} MB")
                    with col2:
                        st.metric("ğŸ“„ ë°ì´í„° ìœ í˜•", json_info['data_type'])
                    with col3:
                        st.metric("ğŸ“Š í•­ëª© ìˆ˜", json_info['total_items'])
                    
                    # Additional info
                    with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
                        st.write(f"**ìƒì„± ì‹œê°„:** {json_info['created_at']}")
                        st.write(f"**ì´ ë¬¸ì ìˆ˜:** {json_info['total_characters']:,}")
                        if json_info['chunk_config']:
                            st.write(f"**ì²­í¬ ì„¤ì •:** {json_info['chunk_config']}")
                        st.write("**ìƒ˜í”Œ ë‚´ìš©:**")
                        st.text(json_info['sample_content'])
                
                # Load JSON button
                if st.button("ğŸ“¥ JSON íŒŒì¼ ë¡œë”©", type="primary"):
                    try:
                        if json_info['data_type'] == 'documents':
                            # Load documents and split into chunks
                            documents = doc_processor.load_documents_from_json(json_path)
                            if documents:
                                st.session_state.documents = documents
                                
                                # Split documents
                                chunks = doc_processor.split_documents(documents)
                                st.session_state.document_chunks = chunks
                                st.session_state.documents_loaded = True
                                
                                st.success(f"âœ… {len(documents)}ê°œ ë¬¸ì„œë¥¼ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¡œë”©í–ˆìŠµë‹ˆë‹¤!")
                        
                        elif json_info['data_type'] == 'chunks':
                            # Load chunks directly
                            chunks = doc_processor.load_chunks_from_json(json_path)
                            if chunks:
                                st.session_state.document_chunks = chunks
                                st.session_state.documents_loaded = True
                                
                                st.success(f"âœ… {len(chunks)}ê°œ ì²­í¬ë¥¼ ì§ì ‘ ë¡œë”©í–ˆìŠµë‹ˆë‹¤!")
                    
                    except Exception as e:
                        st.error(f"âŒ JSON ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        else:
            st.info("ğŸ“­ ì €ì¥ëœ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ë¡œë”©í•˜ì—¬ JSONìœ¼ë¡œ ì €ì¥í•´ì£¼ì„¸ìš”.")
    
    with tab3:
        st.write("### ğŸ—‚ï¸ JSON íŒŒì¼ ê´€ë¦¬")
        
        json_files = list(JSON_OUTPUT_FOLDER.glob("*.json"))
        
        if json_files:
            st.write(f"ğŸ“ **JSON íŒŒì¼ ëª©ë¡ ({len(json_files)}ê°œ):**")
            
            # Create detailed JSON file list
            json_data = []
            doc_processor = DocumentProcessor(st.session_state.chunk_size, st.session_state.chunk_overlap)
            
            for json_file in json_files:
                json_info = doc_processor.get_json_info(json_file)
                if json_info:
                    json_data.append({
                        "íŒŒì¼ëª…": json_file.name,
                        "ìœ í˜•": json_info['data_type'],
                        "í•­ëª© ìˆ˜": json_info['total_items'],
                        "í¬ê¸° (MB)": json_info['file_size_mb'],
                        "ìƒì„±ì¼": json_info['created_at'][:10]  # Date only
                    })
            
            if json_data:
                df_json = pd.DataFrame(json_data)
                st.dataframe(df_json, use_container_width=True)
                
                # JSON file operations
                st.write("### ğŸ”§ íŒŒì¼ ì‘ì—…")
                selected_files = st.multiselect(
                    "ì‘ì—…í•  íŒŒì¼ ì„ íƒ:",
                    options=[f.name for f in json_files]
                )
                
                if selected_files:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if st.button("ğŸ‘ï¸ ì„ íƒ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°"):
                            for file_name in selected_files:
                                file_path = JSON_OUTPUT_FOLDER / file_name
                                json_info = doc_processor.get_json_info(file_path)
                                if json_info:
                                    with st.expander(f"ğŸ“„ {file_name}"):
                                        st.write(f"**ìœ í˜•:** {json_info['data_type']}")
                                        st.write(f"**í•­ëª© ìˆ˜:** {json_info['total_items']}")
                                        st.write(f"**ìƒ˜í”Œ ë‚´ìš©:**")
                                        st.text(json_info['sample_content'])
                    
                    with col2:
                        if st.button("ğŸ—‘ï¸ ì„ íƒ íŒŒì¼ ì‚­ì œ", type="secondary"):
                            for file_name in selected_files:
                                file_path = JSON_OUTPUT_FOLDER / file_name
                                try:
                                    file_path.unlink()
                                    st.success(f"âœ… {file_name} ì‚­ì œ ì™„ë£Œ")
                                except Exception as e:
                                    st.error(f"âŒ {file_name} ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
                            st.rerun()
        else:
            st.info("ğŸ“­ ê´€ë¦¬í•  JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # Display loaded documents info
    if st.session_state.documents_loaded:
        st.markdown("---")
        st.subheader("ğŸ“‹ í˜„ì¬ ë¡œë”©ëœ ë°ì´í„°")
        
        if st.session_state.document_chunks:
            chunks = st.session_state.document_chunks
            
            # Display summary
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ğŸ§© ì´ ì²­í¬", len(chunks))
            with col2:
                avg_size = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)
                st.metric("ğŸ“ í‰ê·  í¬ê¸°", f"{avg_size:.0f}")
            with col3:
                sources = set(chunk.metadata.get('source', 'Unknown') for chunk in chunks)
                st.metric("ğŸ“š ì†ŒìŠ¤ ìˆ˜", len(sources))
            with col4:
                total_chars = sum(len(chunk.page_content) for chunk in chunks)
                st.metric("ğŸ“ ì´ ë¬¸ì", f"{total_chars:,}")
            
            # Document chunks preview
            with st.expander("ğŸ” ì²­í¬ ë¯¸ë¦¬ë³´ê¸° ë° íƒìƒ‰"):
                # Chunk navigation
                col1, col2 = st.columns([3, 1])
                with col1:
                    chunk_index = st.slider("ì²­í¬ ì„ íƒ:", 0, len(chunks)-1, 0)
                with col2:
                    show_metadata = st.checkbox("ë©”íƒ€ë°ì´í„° í‘œì‹œ", value=False)
                
                chunk = chunks[chunk_index]
                
                # Display chunk info
                st.write(f"### ğŸ“„ ì²­í¬ {chunk_index + 1}/{len(chunks)}")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write(f"**ğŸ“‚ ì¶œì²˜:** {chunk.metadata.get('source', 'Unknown')}")
                with col2:
                    st.write(f"**ğŸ“ í¬ê¸°:** {len(chunk.page_content)} ë¬¸ì")
                with col3:
                    st.write(f"**ğŸ“„ í˜ì´ì§€:** {chunk.metadata.get('page_number', 'N/A')}")
                
                if show_metadata:
                    with st.expander("ğŸ·ï¸ ì „ì²´ ë©”íƒ€ë°ì´í„°"):
                        st.json(chunk.metadata)
                
                # Display content
                st.write("**ğŸ“– ë‚´ìš©:**")
                st.text_area(
                    label="ì²­í¬ ë‚´ìš©",
                    value=chunk.page_content,
                    height=300,
                    disabled=True,
                    label_visibility="hidden",
                    key=f"chunk_content_{chunk_index}"
                )


def create_vector_store_tab():
    """Enhanced vector store tab with creation/loading/management functionality."""
    st.header("ğŸ” ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ê´€ë¦¬")
    
    # Create vector stores output folder if it doesn't exist
    from src.config import VECTOR_STORES_FOLDER
    VECTOR_STORES_FOLDER.mkdir(exist_ok=True)
    
    # Vector store source selection
    st.subheader("ğŸ¯ ë²¡í„° ìŠ¤í† ì–´ ì†ŒìŠ¤ ì„ íƒ")
    
    tab1, tab2, tab3 = st.tabs(["ğŸš€ ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±", "ğŸ“¥ ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©", "ğŸ—‚ï¸ ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬"])
    
    with tab1:
        st.write("### ğŸ” í˜„ì¬ ë¡œë”©ëœ ë¬¸ì„œì—ì„œ ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±")
        
        if not st.session_state.documents_loaded:
            st.warning("âš ï¸ ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë”©í•´ì£¼ì„¸ìš”.")
            st.info("**ğŸ“š ë¬¸ì„œ ë¡œë”©** íƒ­ì—ì„œ PDFë¥¼ ë¡œë”©í•˜ê±°ë‚˜ JSONì—ì„œ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”.")
        else:
            # Display current document info
            chunks = st.session_state.document_chunks
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ğŸ§© ì´ ì²­í¬", len(chunks))
            with col2:
                avg_size = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)
                st.metric("ğŸ“ í‰ê·  í¬ê¸°", f"{avg_size:.0f}")
            with col3:
                sources = set(chunk.metadata.get('source', 'Unknown') for chunk in chunks)
                st.metric("ğŸ“š ì†ŒìŠ¤ ìˆ˜", len(sources))
            with col4:
                total_chars = sum(len(chunk.page_content) for chunk in chunks)
                st.metric("ğŸ“ ì´ ë¬¸ì", f"{total_chars:,}")
            
            st.info(f"ğŸ¤– ì„ë² ë”© ëª¨ë¸: {EMBEDDING_MODEL}")
            
            # Vector store creation options
            st.write("### âš™ï¸ ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •")
            
            col1, col2 = st.columns(2)
            with col1:
                # Vector store type (from sidebar setting)
                vector_store_type = st.session_state.get("vector_store_type", "chroma")
                st.write(f"**ë²¡í„° ìŠ¤í† ì–´ íƒ€ì…:** {vector_store_type.upper()}")
                st.write(f"**ì»¬ë ‰ì…˜ ì´ë¦„:** {COLLECTION_NAME}")
                
            with col2:
                # Save options
                save_vector_store = st.checkbox("ğŸ’¾ ë²¡í„° ìŠ¤í† ì–´ ì €ì¥", value=True)
                if save_vector_store:
                    store_name = st.text_input(
                        "ë²¡í„° ìŠ¤í† ì–´ ì´ë¦„:", 
                        value=f"vectorstore_{vector_store_type}_{datetime.now().strftime('%Y%m%d_%H%M')}"
                    )
            
            # Create vector store button
            if st.button("ğŸš€ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹œì‘", type="primary"):
                try:
                    # Initialize embedding manager with models folder
                    embedding_manager = EmbeddingManager(EMBEDDING_MODEL, MODELS_FOLDER)
                    embeddings = embedding_manager.get_embeddings()
                    
                    # Display embedding model info
                    embed_info = embedding_manager.get_model_info()
                    with st.expander("ğŸ¤– ì„ë² ë”© ëª¨ë¸ ì •ë³´"):
                        for key, value in embed_info.items():
                            st.write(f"â€¢ **{key}**: {value}")
                    
                    # Create vector store manager
                    vector_store_manager = VectorStoreManager(
                        embeddings, 
                        vector_store_type=vector_store_type,
                        collection_name=COLLECTION_NAME
                    )
                    
                    # Create vector store
                    vector_store = vector_store_manager.create_vector_store(chunks)
                    
                    # Store in session state
                    st.session_state.vector_store_manager = vector_store_manager
                    st.session_state.embedding_manager = embedding_manager
                    st.session_state.vector_store_created = True
                    
                    # Display collection stats
                    stats = vector_store_manager.get_collection_stats()
                    st.write("### ğŸ“Š ë²¡í„° ìŠ¤í† ì–´ í†µê³„")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ğŸ“„ ë¬¸ì„œ ìˆ˜", stats.get("document_count", "N/A"))
                    with col2:
                        st.metric("ğŸ”§ ìƒíƒœ", stats.get("status", "N/A"))
                    with col3:
                        st.metric("ğŸš« í…”ë ˆë©”íŠ¸ë¦¬", stats.get("telemetry_status", "N/A"))
                    
                    # Save vector store if requested
                    if save_vector_store and store_name:
                        store_path = VECTOR_STORES_FOLDER / store_name
                        
                        # Prepare metadata
                        metadata = {
                            "document_count": len(chunks),
                            "total_characters": total_chars,
                            "source_count": len(sources),
                            "avg_chunk_size": avg_size,
                            "embedding_model": EMBEDDING_MODEL,
                            "chunk_size": st.session_state.get("chunk_size", CHUNK_SIZE),
                            "chunk_overlap": st.session_state.get("chunk_overlap", CHUNK_OVERLAP)
                        }
                        
                        success = vector_store_manager.save_vector_store(store_path, metadata)
                        if success:
                            st.balloons()
                    
                except Exception as e:
                    st.error(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    with tab2:
        st.write("### ğŸ“¥ ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ë¡œë”©")
        
        # Debug: Show folder path and check existence
        st.write(f"**ğŸ” ë””ë²„ê·¸ ì •ë³´:**")
        st.write(f"- ë²¡í„° ìŠ¤í† ì–´ í´ë”: `{VECTOR_STORES_FOLDER}`")
        st.write(f"- í´ë” ì¡´ì¬ ì—¬ë¶€: {VECTOR_STORES_FOLDER.exists()}")
        
        if VECTOR_STORES_FOLDER.exists():
            all_items = list(VECTOR_STORES_FOLDER.iterdir())
            st.write(f"- í´ë” ë‚´ í•­ëª© ìˆ˜: {len(all_items)}")
            for item in all_items:
                st.write(f"  - {'[DIR]' if item.is_dir() else '[FILE]'} {item.name}")
        
        # List available vector stores
        saved_stores = VectorStoreManager.list_saved_vector_stores(VECTOR_STORES_FOLDER)
        st.write(f"- **ê°ì§€ëœ ë²¡í„° ìŠ¤í† ì–´ ìˆ˜: {len(saved_stores)}**")
        
        # Debug: Show individual store info
        if VECTOR_STORES_FOLDER.exists():
            st.write("**ğŸ“‹ ê°œë³„ ìŠ¤í† ì–´ ë¶„ì„:**")
            for item in VECTOR_STORES_FOLDER.iterdir():
                if item.is_dir():
                    metadata_path = item / "metadata.json"
                    st.write(f"  - **{item.name}**:")
                    st.write(f"    - metadata.json ì¡´ì¬: {metadata_path.exists()}")
                    if metadata_path.exists():
                        try:
                            import json
                            with open(metadata_path, 'r', encoding='utf-8') as f:
                                metadata = json.load(f)
                            st.write(f"    - JSON íŒŒì‹±: âœ… ì„±ê³µ")
                            st.write(f"    - ë¬¸ì„œ ìˆ˜: {metadata.get('document_count', 'N/A')}")
                            st.write(f"    - íƒ€ì…: {metadata.get('vector_store_type', 'N/A')}")
                        except Exception as e:
                            st.write(f"    - JSON íŒŒì‹±: âŒ ì‹¤íŒ¨ - {str(e)}")
        
        if saved_stores:
            st.write(f"ğŸ“ **ì‚¬ìš© ê°€ëŠ¥í•œ ë²¡í„° ìŠ¤í† ì–´ ({len(saved_stores)}ê°œ):**")
            
            # Vector store selection
            store_options = [f"{store['store_name']} ({store.get('vector_store_type', 'unknown').upper()})" for store in saved_stores]
            selected_store_idx = st.selectbox(
                "ë¡œë”©í•  ë²¡í„° ìŠ¤í† ì–´ ì„ íƒ:",
                options=range(len(store_options)),
                format_func=lambda x: store_options[x],
                key="vector_store_selector"
            )
            
            if selected_store_idx is not None:
                selected_store = saved_stores[selected_store_idx]
                store_path = Path(selected_store["store_path"])
                
                # Display vector store info
                st.write("### ğŸ“‹ ë²¡í„° ìŠ¤í† ì–´ ì •ë³´")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ“ íŒŒì¼ í¬ê¸°", f"{selected_store.get('file_size_mb', 0):.1f} MB")
                with col2:
                    st.metric("ğŸ”§ íƒ€ì…", selected_store.get('vector_store_type', 'unknown').upper())
                with col3:
                    st.metric("ğŸ“„ ë¬¸ì„œ ìˆ˜", selected_store.get('document_count', 'N/A'))
                
                # Additional info
                with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
                    st.write(f"**ìƒì„± ì‹œê°„:** {selected_store.get('created_at', 'N/A')[:19]}")
                    st.write(f"**ì»¬ë ‰ì…˜ ì´ë¦„:** {selected_store.get('collection_name', 'N/A')}")
                    st.write(f"**ì„ë² ë”© ëª¨ë¸:** {selected_store.get('embedding_model', 'N/A')}")
                    if selected_store.get('total_characters'):
                        st.write(f"**ì´ ë¬¸ì ìˆ˜:** {selected_store['total_characters']:,}")
                    if selected_store.get('avg_chunk_size'):
                        st.write(f"**í‰ê·  ì²­í¬ í¬ê¸°:** {selected_store['avg_chunk_size']:.0f}")
                    if selected_store.get('chunk_size'):
                        st.write(f"**ì²­í¬ ì„¤ì •:** {selected_store['chunk_size']}/{selected_store.get('chunk_overlap', 0)}")
            
                # Load vector store button
                if st.button("ğŸ“¥ ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©", type="primary"):
                    try:
                        # Initialize embedding manager
                        embedding_manager = EmbeddingManager(EMBEDDING_MODEL, MODELS_FOLDER)
                        embeddings = embedding_manager.get_embeddings()
                        
                        # Create vector store manager and load
                        vector_store_manager = VectorStoreManager(
                            embeddings,
                            vector_store_type=selected_store.get('vector_store_type', 'chroma'),
                            collection_name=selected_store.get('collection_name', COLLECTION_NAME)
                        )
                        
                        success = vector_store_manager.load_vector_store(store_path)
                        if success:
                            # Store in session state
                            st.session_state.vector_store_manager = vector_store_manager
                            st.session_state.embedding_manager = embedding_manager
                            st.session_state.vector_store_created = True
                            
                            # Show loaded stats
                            stats = vector_store_manager.get_collection_stats()
                            st.write("### âœ… ë¡œë”© ì™„ë£Œ")
                            for key, value in stats.items():
                                st.write(f"â€¢ **{key}**: {value}")
                            
                            st.balloons()
                    
                    except Exception as e:
                        st.error(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        else:
            st.info("ğŸ“­ ì €ì¥ëœ ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒˆ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            
            # Manual path option as fallback
            st.write("**ğŸ”§ ìˆ˜ë™ ë¡œë”© (ê³ ê¸‰ ì‚¬ìš©ììš©):**")
            manual_path = st.text_input(
                "ë²¡í„° ìŠ¤í† ì–´ í´ë” ê²½ë¡œë¥¼ ì§ì ‘ ì…ë ¥:",
                placeholder="ì˜ˆ: /Users/kenny/GitHub/rag/vector_stores/vectorstore_chroma_20250628_1832"
            )
            
            if manual_path and st.button("ğŸ” ìˆ˜ë™ ê²½ë¡œì—ì„œ ë¡œë”©"):
                manual_store_path = Path(manual_path)
                if manual_store_path.exists() and manual_store_path.is_dir():
                    metadata_path = manual_store_path / "metadata.json"
                    if metadata_path.exists():
                        try:
                            # Load metadata
                            with open(metadata_path, 'r', encoding='utf-8') as f:
                                metadata = json.load(f)
                            
                            st.success(f"âœ… ë©”íƒ€ë°ì´í„° ë°œê²¬: {metadata.get('vector_store_type', 'unknown')} íƒ€ì…")
                            
                            # Initialize and load
                            embedding_manager = EmbeddingManager(EMBEDDING_MODEL, MODELS_FOLDER)
                            embeddings = embedding_manager.get_embeddings()
                            
                            vector_store_manager = VectorStoreManager(
                                embeddings,
                                vector_store_type=metadata.get('vector_store_type', 'chroma'),
                                collection_name=metadata.get('collection_name', COLLECTION_NAME)
                            )
                            
                            success = vector_store_manager.load_vector_store(manual_store_path)
                            if success:
                                st.session_state.vector_store_manager = vector_store_manager
                                st.session_state.embedding_manager = embedding_manager
                                st.session_state.vector_store_created = True
                                st.balloons()
                                
                        except Exception as e:
                            st.error(f"âŒ ìˆ˜ë™ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                    else:
                        st.error("âŒ metadata.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.error("âŒ ì§€ì •ëœ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    with tab3:
        st.write("### ğŸ—‚ï¸ ë²¡í„° ìŠ¤í† ì–´ íŒŒì¼ ê´€ë¦¬")
        
        saved_stores = VectorStoreManager.list_saved_vector_stores(VECTOR_STORES_FOLDER)
        
        if saved_stores:
            st.write(f"ğŸ“ **ë²¡í„° ìŠ¤í† ì–´ ëª©ë¡ ({len(saved_stores)}ê°œ):**")
            
            # Create detailed vector store list
            store_data = []
            for store in saved_stores:
                store_data.append({
                    "ì´ë¦„": store['store_name'],
                    "íƒ€ì…": store.get('vector_store_type', 'unknown').upper(),
                    "ë¬¸ì„œ ìˆ˜": store.get('document_count', 'N/A'),
                    "í¬ê¸° (MB)": store.get('file_size_mb', 0),
                    "ìƒì„±ì¼": store.get('created_at', 'N/A')[:10]  # Date only
                })
            
            if store_data:
                df_stores = pd.DataFrame(store_data)
                st.dataframe(df_stores, use_container_width=True)
                
                # Vector store operations
                st.write("### ğŸ”§ íŒŒì¼ ì‘ì—…")
                selected_stores = st.multiselect(
                    "ì‘ì—…í•  ë²¡í„° ìŠ¤í† ì–´ ì„ íƒ:",
                    options=[store['store_name'] for store in saved_stores]
                )
                
                if selected_stores:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if st.button("ğŸ‘ï¸ ì„ íƒ ìŠ¤í† ì–´ ë¯¸ë¦¬ë³´ê¸°"):
                            for store_name in selected_stores:
                                # Find store info
                                store_info = next((s for s in saved_stores if s['store_name'] == store_name), None)
                                if store_info:
                                    with st.expander(f"ğŸ” {store_name}"):
                                        st.write(f"**íƒ€ì…:** {store_info.get('vector_store_type', 'unknown').upper()}")
                                        st.write(f"**ë¬¸ì„œ ìˆ˜:** {store_info.get('document_count', 'N/A')}")
                                        st.write(f"**ì»¬ë ‰ì…˜:** {store_info.get('collection_name', 'N/A')}")
                                        st.write(f"**ì„ë² ë”© ëª¨ë¸:** {store_info.get('embedding_model', 'N/A')}")
                                        st.write(f"**í¬ê¸°:** {store_info.get('file_size_mb', 0):.1f} MB")
                    
                    with col2:
                        if st.button("ğŸ—‘ï¸ ì„ íƒ ìŠ¤í† ì–´ ì‚­ì œ", type="secondary"):
                            for store_name in selected_stores:
                                store_path = VECTOR_STORES_FOLDER / store_name
                                success = VectorStoreManager.delete_vector_store(store_path)
                                if success:
                                    st.success(f"âœ… {store_name} ì‚­ì œ ì™„ë£Œ")
                                else:
                                    st.error(f"âŒ {store_name} ì‚­ì œ ì‹¤íŒ¨")
                            st.rerun()
        else:
            st.info("ğŸ“­ ê´€ë¦¬í•  ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # Test search functionality (if vector store is loaded)
    if st.session_state.vector_store_created:
        st.markdown("---")
        st.subheader("ğŸ” ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            test_query = st.text_input("í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: AI íŠ¸ë Œë“œ")
        with col2:
            test_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜:", 1, 10, st.session_state.get("top_k", DEFAULT_K))
        
        if test_query and st.button("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"):
            vector_store_manager = st.session_state.vector_store_manager
            try:
                docs_with_score = vector_store_manager.similarity_search_with_score(test_query, k=test_k)
                
                st.write(f"### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ({len(docs_with_score)}ê°œ)")
                
                for i, (doc, score) in enumerate(docs_with_score):
                    with st.expander(f"ğŸ“„ ë¬¸ì„œ {i+1}: {doc.metadata.get('source', 'Unknown')} (ì ìˆ˜: {score:.3f})"):
                        st.write(f"**ìœ ì‚¬ë„ ì ìˆ˜:** {score:.4f}")
                        st.write(f"**ì¶œì²˜:** {doc.metadata.get('source', 'Unknown')}")
                        st.write(f"**í˜ì´ì§€:** {doc.metadata.get('page_number', 'N/A')}")
                        st.write("**ë‚´ìš©:**")
                        content_preview = doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content
                        st.text(content_preview)
                        
            except Exception as e:
                st.error(f"âŒ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        
        # Current vector store status
        with st.expander("ğŸ“Š í˜„ì¬ ë²¡í„° ìŠ¤í† ì–´ ìƒíƒœ"):
            vector_store_manager = st.session_state.vector_store_manager
            stats = vector_store_manager.get_collection_stats()
            for key, value in stats.items():
                st.write(f"â€¢ **{key}**: {value}")


def rag_experiment_tab():
    """RAG experiment tab with various systems."""
    st.header("ğŸ§ª RAG ì‹œìŠ¤í…œ ì‹¤í—˜")
    
    # First check if we have a vector store manager with actual vector store
    vector_store_manager = st.session_state.get("vector_store_manager")
    vector_store = None
    
    if vector_store_manager:
        try:
            vector_store = vector_store_manager.get_vector_store()
        except Exception as e:
            st.warning(f"âš ï¸ ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            vector_store = None
    
    # If no vector store exists, try to create manager (but don't force it)
    if vector_store is None:
        st.warning("ğŸ“‹ ë²¡í„° ìŠ¤í† ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.info("**ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:**")
        st.markdown("""
        1. **ğŸ“š ë¬¸ì„œ ë¡œë”©** íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•œ í›„ **ğŸ” ë²¡í„° ìŠ¤í† ì–´** íƒ­ì—ì„œ ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        2. **ğŸ” ë²¡í„° ìŠ¤í† ì–´** íƒ­ì—ì„œ ê¸°ì¡´ì— ì €ì¥ëœ ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©
        """)
        return
    
    # Display vector store info
    st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ì¤€ë¹„ ì™„ë£Œ!")
    
    # Show current vector store status
    with st.expander("ğŸ“Š í˜„ì¬ ë²¡í„° ìŠ¤í† ì–´ ì •ë³´"):
        try:
            # Get sample documents to check vector store
            sample_docs = vector_store.similarity_search("test", k=1)
            if sample_docs:
                st.info(f"ğŸ“„ ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: ì¶”ì • {len(sample_docs)} ê°œ ì´ìƒ")
                st.write(f"**ìƒ˜í”Œ ë¬¸ì„œ ì¶œì²˜:** {sample_docs[0].metadata.get('source', 'Unknown')}")
            else:
                st.warning("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"âš ï¸ ë²¡í„° ìŠ¤í† ì–´ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
    
    # Initialize RAG systems if not already done
    if not st.session_state.rag_systems:
        selected_model = st.session_state.get("selected_llm_model", DEFAULT_LLM_MODEL)
        llm_temperature = st.session_state.get("llm_temperature", 0.1)
        llm_manager = LLMManager(selected_model, OLLAMA_BASE_URL, temperature=llm_temperature)
        
        st.session_state.rag_systems = {
            "Naive RAG": NaiveRAG(vector_store_manager, llm_manager),
            "Advanced RAG": AdvancedRAG(vector_store_manager, llm_manager),
            "Modular RAG": ModularRAG(vector_store_manager, llm_manager)
        }
    
    # System selection
    st.subheader("ğŸ¯ ì‹¤í—˜ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    with col1:
        selected_systems = st.multiselect(
            "í…ŒìŠ¤íŠ¸í•  RAG ì‹œìŠ¤í…œ ì„ íƒ:",
            list(st.session_state.rag_systems.keys()),
            default=list(st.session_state.rag_systems.keys())
        )
    
    with col2:
        retrieval_k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (k):", 1, 15, st.session_state.top_k)
    
    # Sample queries - ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ìš© ë‹¤ì–‘í•œ ìœ í˜•
    st.write("**ìƒ˜í”Œ ì§ˆë¬¸ (ì§ˆë¬¸ ìœ í˜•ë³„):**")
    sample_queries = [
        "2025ë…„ AI íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",                    # factual
        "ì§ì¥ì—ì„œ AIë¥¼ ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆë‚˜ìš”?",            # procedural
        "ì™œ AIê°€ ì—…ë¬´ ìƒì‚°ì„±ì— ì¤‘ìš”í•œê°€ìš”?",                # causal
        "AI ê¸°ìˆ ì€ ì–¸ì œë¶€í„° ë°œì „í•˜ê¸° ì‹œì‘í–ˆë‚˜ìš”?",          # temporal
        "ìƒì„±í˜• AIì™€ ê¸°ì¡´ AIì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",        # comparative
        "AI ì‹œì¥ ê·œëª¨ëŠ” ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",                   # quantitative
        "ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",                     # general
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì€?",                # procedural
        "AI ê°œë°œì—ëŠ” ì–´ë–¤ ë¹„ìš©ì´ ë“œë‚˜ìš”?",                 # quantitative
        "ë”¥ëŸ¬ë‹ì´ ì£¼ëª©ë°›ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"              # causal
    ]
    
    # Display categorized sample questions
    st.write("**ğŸ·ï¸ ì§ˆë¬¸ ìœ í˜• ì˜ˆì‹œ:**")
    st.markdown("""
    - **ì‚¬ì‹¤í˜•(factual)**: "ë¬´ì—‡", "ì–´ë–¤" â†’ ì •í™•í•œ ì •ë³´ ìœ„ì£¼
    - **ë°©ë²•í˜•(procedural)**: "ì–´ë–»ê²Œ", "ë°©ë²•" â†’ ë‹¨ê³„ë³„ ì„¤ëª…  
    - **ì›ì¸í˜•(causal)**: "ì™œ", "ì´ìœ " â†’ ë…¼ë¦¬ì  ë¶„ì„
    - **ì‹œê°„í˜•(temporal)**: "ì–¸ì œ", "ì‹œì " â†’ ì‹œê°„ìˆœ ì •ë¦¬
    - **ë¹„êµí˜•(comparative)**: "ì°¨ì´", "ë¹„êµ" â†’ ë¹„êµ ë¶„ì„
    - **ìˆ˜ì¹˜í˜•(quantitative)**: "ì–¼ë§ˆ", "ê·œëª¨" â†’ ë°ì´í„° ê¸°ë°˜
    - **ì¼ë°˜í˜•(general)**: ê¸°íƒ€ â†’ ì¢…í•©ì  ì„¤ëª…
    """)
    
    st.write("**ğŸ“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ëª©ë¡:**")
    
    # Sample query types for reference
    query_types = ["factual", "procedural", "causal", "temporal", "comparative", "quantitative", "general", "procedural", "quantitative", "causal"]
    
    cols = st.columns(2)
    for i, sample_query in enumerate(sample_queries):
        col = cols[i % 2]
        query_type = query_types[i] if i < len(query_types) else "general"
        type_emoji = {
            "factual": "ğŸ¯", "procedural": "ğŸ“‹", "causal": "ğŸ¤”", 
            "temporal": "â°", "comparative": "âš–ï¸", "quantitative": "ğŸ“Š", "general": "ğŸ“–"
        }
        emoji = type_emoji.get(query_type, "ğŸ“")
        
        if col.button(f"{emoji} {sample_query}", key=f"sample_{i}", help=f"ì§ˆë¬¸ ìœ í˜•: {query_type}"):
            st.session_state.text_area_value = sample_query
            st.rerun()
    
    # Query input - ìƒ˜í”Œ ì§ˆë¬¸ ì„ íƒ ì‹œ í•´ë‹¹ ì§ˆë¬¸ì´ ì…ë ¥ì°½ì— í‘œì‹œë¨
    query = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        value=st.session_state.get("text_area_value", ""),
        placeholder="ì˜ˆ: 2025ë…„ AI íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        height=100,
        key="query_input"
    )
    
    # Run experiment
    if query and selected_systems and st.button("ğŸš€ ì‹¤í—˜ ì‹¤í–‰", type="primary"):
        results = []
        
        for system_name in selected_systems:
            st.write(f"## {system_name} ì‹¤í–‰ ì¤‘...")
            
            rag_system = st.session_state.rag_systems[system_name]
            
            try:
                if system_name == "Advanced RAG":
                    result = rag_system.query(query, k=retrieval_k*2, rerank_top_k=retrieval_k)
                elif system_name == "Modular RAG":
                    result = rag_system.query(query, max_iterations=2)
                else:
                    result = rag_system.query(query, k=retrieval_k)
                
                results.append(result)
                
                # Display individual result
                st.write(f"**ë‹µë³€:** {result['answer']}")
                st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {result['total_time']:.2f}ì´ˆ")
                
            except Exception as e:
                st.error(f"{system_name} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
                import traceback
                st.error(f"ìƒì„¸ ì˜¤ë¥˜ ì •ë³´: {traceback.format_exc()}")
                continue
            
            st.divider()
        
        # Store results
        if results:
            st.session_state.experiment_results = results
            st.success("âœ… ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")


def comparison_tab():
    """Comparison and analysis tab."""
    st.header("ğŸ“Š ê²°ê³¼ ë¹„êµ ë° ë¶„ì„")
    
    if not st.session_state.experiment_results:
        st.warning("ë¨¼ì € RAG ì‹¤í—˜ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    results = st.session_state.experiment_results
    
    # System information comparison
    if st.session_state.rag_systems:
        systems_info = []
        for system_name, rag_system in st.session_state.rag_systems.items():
            systems_info.append(rag_system.get_system_info())
        
        ComparisonUI.display_system_comparison(systems_info)
        st.divider()
    
    # Performance comparison
    ComparisonUI.display_performance_comparison(results)
    st.divider()
    
    # Answer comparison
    ComparisonUI.display_answer_comparison(results)
    st.divider()
    
    # Detailed metrics for each system
    for result in results:
        ComparisonUI.display_detailed_metrics(result)
        ComparisonUI.create_processing_flow_diagram(result["rag_type"])
        st.divider()
    
    # Summary report
    ComparisonUI.create_summary_report(results)


def about_tab():
    """About and documentation tab."""
    AboutUI.display_about_page()


def main():
    """Main application function."""
    # Apply custom font globally first (before any other UI elements)
    apply_custom_css()
    
    # Setup
    setup_page()
    initialize_session_state()
    setup_sidebar()
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“š ë¬¸ì„œ ë¡œë”©",
        "ğŸ” ë²¡í„° ìŠ¤í† ì–´",
        "ğŸ§ª RAG ì‹¤í—˜",
        "ğŸ“Š ê²°ê³¼ ë¹„êµ",
        "â„¹ï¸ ì†Œê°œ"
    ])
    
    with tab1:
        load_documents_tab()
    
    with tab2:
        create_vector_store_tab()
    
    with tab3:
        rag_experiment_tab()
    
    with tab4:
        comparison_tab()
    
    with tab5:
        about_tab()


if __name__ == "__main__":
    main()