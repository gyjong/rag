"""Main Streamlit application for RAG systems comparison."""

import streamlit as st
import os
from pathlib import Path
import base64

# Import our modules
from src.config import *
from src.utils.document_processor import DocumentProcessor
from src.utils.embeddings import EmbeddingManager
from src.utils.vector_store import VectorStoreManager
from src.utils.llm_manager import LLMManager
from src.utils.font_utils import apply_custom_css
from src.rag_systems.naive_rag import NaiveRAG
from src.rag_systems.advanced_rag import AdvancedRAG
from src.rag_systems.modular_rag import ModularRAG
from src.ui.comparison_ui import ComparisonUI


def load_custom_font():
    """Load custom font if available."""
    return apply_custom_css()


def initialize_session_state():
    """Initialize session state variables."""
    if "documents_loaded" not in st.session_state:
        st.session_state.documents_loaded = False
    if "vector_store_created" not in st.session_state:
        st.session_state.vector_store_created = False
    if "rag_systems" not in st.session_state:
        st.session_state.rag_systems = {}
    if "experiment_results" not in st.session_state:
        st.session_state.experiment_results = []
    if "documents" not in st.session_state:
        st.session_state.documents = []
    if "document_chunks" not in st.session_state:
        st.session_state.document_chunks = []


def setup_page():
    """Setup page configuration."""
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Apply custom font globally first
    font_loaded = apply_custom_css()
    
    # Display title with custom styling
    if font_loaded:
        st.markdown('<h1 class="main-title">ğŸ¤– RAG Systems Comparison Tool</h1>', unsafe_allow_html=True)
        st.markdown('<p class="subtitle">ë‹¨ê³„ë³„ Naive RAG, Advanced RAG, Modular RAG ë¹„êµ ì‹¤í—˜ ì• í”Œë¦¬ì¼€ì´ì…˜</p>', unsafe_allow_html=True)
    else:
        st.title("ğŸ¤– RAG Systems Comparison Tool")
        st.subheader("ë‹¨ê³„ë³„ Naive RAG, Advanced RAG, Modular RAG ë¹„êµ ì‹¤í—˜ ì• í”Œë¦¬ì¼€ì´ì…˜")


def setup_sidebar():
    """Setup sidebar with system information."""
    st.sidebar.title("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # Model Selection
    st.sidebar.subheader("ğŸ¤– ëª¨ë¸ ì„ íƒ")
    selected_model_name = st.sidebar.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ:",
        options=list(AVAILABLE_LLM_MODELS.keys()),
        index=list(AVAILABLE_LLM_MODELS.values()).index(DEFAULT_LLM_MODEL) if DEFAULT_LLM_MODEL in AVAILABLE_LLM_MODELS.values() else 0
    )
    selected_model = AVAILABLE_LLM_MODELS[selected_model_name]
    
    # LLM Temperature
    st.sidebar.subheader("ğŸ”¥ LLM Temperature")
    temperature = st.sidebar.slider(
        "Temperature (ì°½ì˜ì„±)", min_value=0.0, max_value=1.0, value=st.session_state.get("llm_temperature", 0.1), step=0.05
    )
    st.session_state.llm_temperature = temperature
    st.sidebar.write(f"í˜„ì¬ ê°’: {temperature}")
    
    # Vector Store Type
    st.sidebar.subheader("ğŸ—„ï¸ ë²¡í„° ìŠ¤í† ì–´ íƒ€ì…")
    vector_store_type = st.sidebar.radio(
        "Vector Store ì—”ì§„ ì„ íƒ:",
        options=["faiss", "chroma"],
        index=["faiss", "chroma"].index(st.session_state.get("vector_store_type", "faiss"))
    )
    st.session_state.vector_store_type = vector_store_type
    st.sidebar.write(f"í˜„ì¬ ì„ íƒ: {vector_store_type}")
    
    # Chunk Size
    st.sidebar.subheader("ğŸ”ª ì²­í¬ í¬ê¸° (Chunk Size)")
    chunk_size = st.sidebar.slider(
        "ì²­í¬ í¬ê¸°:", min_value=256, max_value=4096, value=st.session_state.get("chunk_size", CHUNK_SIZE), step=64
    )
    st.session_state.chunk_size = chunk_size
    st.sidebar.write(f"í˜„ì¬ ê°’: {chunk_size}")
    
    # Chunk Overlap
    st.sidebar.subheader("ğŸ”— ì²­í¬ ì˜¤ë²„ë© (Chunk Overlap)")
    chunk_overlap = st.sidebar.slider(
        "ì˜¤ë²„ë©:", min_value=0, max_value=1024, value=st.session_state.get("chunk_overlap", CHUNK_OVERLAP), step=16
    )
    st.session_state.chunk_overlap = chunk_overlap
    st.sidebar.write(f"í˜„ì¬ ê°’: {chunk_overlap}")
    
    # Top-K (ê²€ìƒ‰ ìˆ˜)
    st.sidebar.subheader("ğŸ” ê²€ìƒ‰ ìˆ˜ (Top-K)")
    top_k = st.sidebar.slider(
        "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜:", min_value=1, max_value=30, value=st.session_state.get("top_k", DEFAULT_K), step=1
    )
    st.session_state.top_k = top_k
    st.sidebar.write(f"í˜„ì¬ ê°’: {top_k}")
    
    # Store selected model in session state
    if "selected_llm_model" not in st.session_state:
        st.session_state.selected_llm_model = selected_model
    elif st.session_state.selected_llm_model != selected_model:
        st.session_state.selected_llm_model = selected_model
        # Clear cached LLM when model changes
        if "llm_manager" in st.session_state:
            del st.session_state.llm_manager
    
    # LLM Status
    st.sidebar.subheader("ğŸ§  LLM ìƒíƒœ")
    llm_manager = LLMManager(st.session_state.selected_llm_model, OLLAMA_BASE_URL, temperature=st.session_state.llm_temperature)
    llm_info = llm_manager.get_model_info()
    
    if llm_info["connection_status"]:
        st.sidebar.success("âœ… Ollama ì„œë²„ ì—°ê²°ë¨")
        if llm_info["model_available"]:
            st.sidebar.success(f"âœ… ëª¨ë¸ '{st.session_state.selected_llm_model}' ì‚¬ìš© ê°€ëŠ¥")
        else:
            st.sidebar.error(f"âŒ ëª¨ë¸ '{st.session_state.selected_llm_model}' ì—†ìŒ")
            if st.sidebar.button("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"):
                with st.spinner("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                    if llm_manager.pull_model():
                        st.sidebar.success("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                        st.rerun()
                    else:
                        st.sidebar.error("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
    else:
        st.sidebar.error("âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
        st.sidebar.code(f"ollama serve")
    
    # Document Status
    st.sidebar.subheader("ğŸ“š ë¬¸ì„œ ìƒíƒœ")
    if st.session_state.documents_loaded:
        st.sidebar.success(f"âœ… {len(st.session_state.documents)}ê°œ ë¬¸ì„œ ë¡œë”©ë¨")
        st.sidebar.success(f"âœ… {len(st.session_state.document_chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
    else:
        st.sidebar.warning("âš ï¸ ë¬¸ì„œê°€ ë¡œë”©ë˜ì§€ ì•ŠìŒ")
    
    # Vector Store Status
    if st.session_state.vector_store_created:
        st.sidebar.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„±ë¨")
    else:
        st.sidebar.warning("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ ë¯¸ìƒì„±")
    
    # Configuration
    st.sidebar.subheader("ğŸ”§ ì„¤ì •")
    st.sidebar.write(f"**ì„ë² ë”© ëª¨ë¸:** {EMBEDDING_MODEL}")
    st.sidebar.write(f"**ì²­í¬ í¬ê¸°:** {chunk_size}")
    st.sidebar.write(f"**ì²­í¬ ì˜¤ë²„ë©:** {chunk_overlap}")
    st.sidebar.write(f"**ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜:** {top_k}")


def load_documents_tab():
    """Document loading tab."""
    st.header("ğŸ“š ë¬¸ì„œ ë¡œë”© ë° ì „ì²˜ë¦¬")
    
    # Document folder info
    st.info(f"ë¬¸ì„œ í´ë”: {DOCS_FOLDER}")
    
    if not DOCS_FOLDER.exists():
        st.error(f"ë¬¸ì„œ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {DOCS_FOLDER}")
        return
    
    # List available documents
    pdf_files = list(DOCS_FOLDER.glob("*.pdf"))
    st.write(f"ì‚¬ìš© ê°€ëŠ¥í•œ PDF íŒŒì¼ ({len(pdf_files)}ê°œ):")
    for pdf_file in pdf_files:
        file_size = pdf_file.stat().st_size / (1024 * 1024)  # MB
        st.write(f"â€¢ {pdf_file.name} ({file_size:.1f} MB)")
    
    # Load documents button
    if st.button("ğŸ“– ë¬¸ì„œ ë¡œë”© ì‹œì‘", type="primary"):
        if not pdf_files:
            st.warning("PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # Initialize document processor
        doc_processor = DocumentProcessor(st.session_state.chunk_size, st.session_state.chunk_overlap)
        
        # Load documents
        documents = doc_processor.load_documents_from_folder(DOCS_FOLDER)
        
        if documents:
            st.session_state.documents = documents
            
            # Display document statistics
            stats = doc_processor.get_document_stats(documents)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ë¬¸ì„œ ìˆ˜", stats["total_documents"])
            with col2:
                st.metric("ì´ ë¬¸ì ìˆ˜", f"{stats['total_characters']:,}")
            with col3:
                st.metric("í‰ê·  ë¬¸ì/ë¬¸ì„œ", f"{stats['average_chars_per_doc']:,.0f}")
            
            # Split documents
            chunks = doc_processor.split_documents(documents)
            st.session_state.document_chunks = chunks
            st.session_state.documents_loaded = True
            
            st.success("âœ… ë¬¸ì„œ ë¡œë”© ë° ì „ì²˜ë¦¬ ì™„ë£Œ!")
        else:
            st.error("ë¬¸ì„œ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # Display loaded documents info
    if st.session_state.documents_loaded:
        st.subheader("ğŸ“‹ ë¡œë”©ëœ ë¬¸ì„œ ì •ë³´")
        
        # Document chunks preview
        with st.expander("ë¬¸ì„œ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°"):
            if st.session_state.document_chunks:
                chunk = st.session_state.document_chunks[0]
                st.write(f"**ì²« ë²ˆì§¸ ì²­í¬ (ID: {chunk.metadata.get('chunk_id', 'N/A')}):**")
                st.write(f"**ì¶œì²˜:** {chunk.metadata.get('source', 'Unknown')}")
                st.write(f"**í¬ê¸°:** {len(chunk.page_content)} ë¬¸ì")
                st.write(f"**ë‚´ìš©:**")
                st.write(chunk.page_content[:500] + "..." if len(chunk.page_content) > 500 else chunk.page_content)


def create_vector_store_tab():
    """Vector store creation tab."""
    st.header("ğŸ” ë²¡í„° ìŠ¤í† ì–´ ìƒì„±")
    
    if not st.session_state.documents_loaded:
        st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë”©í•´ì£¼ì„¸ìš”.")
        return
    
    st.info(f"ì„ë² ë”© ëª¨ë¸: {EMBEDDING_MODEL}")
    
    # Create vector store button
    if st.button("ğŸš€ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±", type="primary"):
        try:
            # Initialize embedding manager with models folder
            embedding_manager = EmbeddingManager(EMBEDDING_MODEL, MODELS_FOLDER)
            embeddings = embedding_manager.get_embeddings()
            
            # Display embedding model info
            embed_info = embedding_manager.get_model_info()
            st.write("**ì„ë² ë”© ëª¨ë¸ ì •ë³´:**")
            for key, value in embed_info.items():
                st.write(f"â€¢ {key}: {value}")
            
            # Create vector store (use selected type)
            vector_store_type = st.session_state.get("vector_store_type", "faiss")
            vector_store_manager = VectorStoreManager(embeddings, vector_store_type)
            vector_store = vector_store_manager.create_vector_store(st.session_state.document_chunks)
            
            # Store in session state
            st.session_state.vector_store_manager = vector_store_manager
            st.session_state.embedding_manager = embedding_manager
            st.session_state.vector_store_created = True
            
            # Display collection stats
            stats = vector_store_manager.get_collection_stats()
            st.write("**ë²¡í„° ìŠ¤í† ì–´ í†µê³„:**")
            for key, value in stats.items():
                st.write(f"â€¢ {key}: {value}")
            
            st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
            
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    # Test search functionality
    if st.session_state.vector_store_created:
        st.subheader("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        test_query = st.text_input("í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: AI íŠ¸ë Œë“œ")
        
        if test_query and st.button("ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"):
            vector_store_manager = st.session_state.vector_store_manager
            try:
                docs = vector_store_manager.similarity_search(test_query, k=st.session_state.top_k)
                st.write(f"**ê²€ìƒ‰ ê²°ê³¼ ({len(docs)}ê°œ):**")
                
                for i, doc in enumerate(docs):
                    with st.expander(f"ë¬¸ì„œ {i+1}: {doc.metadata.get('source', 'Unknown')}"):
                        st.write(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                        
            except Exception as e:
                st.error(f"ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")


def rag_experiment_tab():
    """RAG experiment tab."""
    st.header("ğŸ§ª RAG ì‹œìŠ¤í…œ ì‹¤í—˜")
    
    if not st.session_state.vector_store_created:
        st.warning("ë¨¼ì € ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # Initialize RAG systems if not already done
    if not st.session_state.rag_systems:
        vector_store_manager = st.session_state.vector_store_manager
        selected_model = st.session_state.get("selected_llm_model", DEFAULT_LLM_MODEL)
        llm_temperature = st.session_state.get("llm_temperature", 0.1)
        llm_manager = LLMManager(selected_model, OLLAMA_BASE_URL, temperature=llm_temperature)
        
        st.session_state.rag_systems = {
            "Naive RAG": NaiveRAG(vector_store_manager, llm_manager),
            "Advanced RAG": AdvancedRAG(vector_store_manager, llm_manager),
            "Modular RAG": ModularRAG(vector_store_manager, llm_manager)
        }
    
    # System selection
    st.subheader("ğŸ¯ ì‹¤í—˜ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    with col1:
        selected_systems = st.multiselect(
            "í…ŒìŠ¤íŠ¸í•  RAG ì‹œìŠ¤í…œ ì„ íƒ:",
            list(st.session_state.rag_systems.keys()),
            default=list(st.session_state.rag_systems.keys())
        )
    
    with col2:
        retrieval_k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (k):", 1, 15, st.session_state.top_k)
    
    # Sample queries - ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ìš© ë‹¤ì–‘í•œ ìœ í˜•
    st.write("**ìƒ˜í”Œ ì§ˆë¬¸ (ì§ˆë¬¸ ìœ í˜•ë³„):**")
    sample_queries = [
        "2025ë…„ AI íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",                    # factual
        "ì§ì¥ì—ì„œ AIë¥¼ ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆë‚˜ìš”?",            # procedural
        "ì™œ AIê°€ ì—…ë¬´ ìƒì‚°ì„±ì— ì¤‘ìš”í•œê°€ìš”?",                # causal
        "AI ê¸°ìˆ ì€ ì–¸ì œë¶€í„° ë°œì „í•˜ê¸° ì‹œì‘í–ˆë‚˜ìš”?",          # temporal
        "ìƒì„±í˜• AIì™€ ê¸°ì¡´ AIì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",        # comparative
        "AI ì‹œì¥ ê·œëª¨ëŠ” ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",                   # quantitative
        "ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",                     # general
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì€?",                # procedural
        "AI ê°œë°œì—ëŠ” ì–´ë–¤ ë¹„ìš©ì´ ë“œë‚˜ìš”?",                 # quantitative
        "ë”¥ëŸ¬ë‹ì´ ì£¼ëª©ë°›ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"              # causal
    ]
    
    # Display categorized sample questions
    st.write("**ğŸ·ï¸ ì§ˆë¬¸ ìœ í˜• ì˜ˆì‹œ:**")
    st.markdown("""
    - **ì‚¬ì‹¤í˜•(factual)**: "ë¬´ì—‡", "ì–´ë–¤" â†’ ì •í™•í•œ ì •ë³´ ìœ„ì£¼
    - **ë°©ë²•í˜•(procedural)**: "ì–´ë–»ê²Œ", "ë°©ë²•" â†’ ë‹¨ê³„ë³„ ì„¤ëª…  
    - **ì›ì¸í˜•(causal)**: "ì™œ", "ì´ìœ " â†’ ë…¼ë¦¬ì  ë¶„ì„
    - **ì‹œê°„í˜•(temporal)**: "ì–¸ì œ", "ì‹œì " â†’ ì‹œê°„ìˆœ ì •ë¦¬
    - **ë¹„êµí˜•(comparative)**: "ì°¨ì´", "ë¹„êµ" â†’ ë¹„êµ ë¶„ì„
    - **ìˆ˜ì¹˜í˜•(quantitative)**: "ì–¼ë§ˆ", "ê·œëª¨" â†’ ë°ì´í„° ê¸°ë°˜
    - **ì¼ë°˜í˜•(general)**: ê¸°íƒ€ â†’ ì¢…í•©ì  ì„¤ëª…
    """)
    
    st.write("**ğŸ“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ëª©ë¡:**")
    
    # Sample query types for reference
    query_types = ["factual", "procedural", "causal", "temporal", "comparative", "quantitative", "general", "procedural", "quantitative", "causal"]
    
    cols = st.columns(2)
    for i, sample_query in enumerate(sample_queries):
        col = cols[i % 2]
        query_type = query_types[i] if i < len(query_types) else "general"
        type_emoji = {
            "factual": "ğŸ¯", "procedural": "ğŸ“‹", "causal": "ğŸ¤”", 
            "temporal": "â°", "comparative": "âš–ï¸", "quantitative": "ğŸ“Š", "general": "ğŸ“–"
        }
        emoji = type_emoji.get(query_type, "ğŸ“")
        
        if col.button(f"{emoji} {sample_query}", key=f"sample_{i}", help=f"ì§ˆë¬¸ ìœ í˜•: {query_type}"):
            st.session_state.text_area_value = sample_query
            st.rerun()
    
    # Query input - ìƒ˜í”Œ ì§ˆë¬¸ ì„ íƒ ì‹œ í•´ë‹¹ ì§ˆë¬¸ì´ ì…ë ¥ì°½ì— í‘œì‹œë¨
    query = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        value=st.session_state.get("text_area_value", ""),
        placeholder="ì˜ˆ: 2025ë…„ AI íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        height=100,
        key="query_input"
    )
    
    # Run experiment
    if query and selected_systems and st.button("ğŸš€ ì‹¤í—˜ ì‹¤í–‰", type="primary"):
        results = []
        
        for system_name in selected_systems:
            st.write(f"## {system_name} ì‹¤í–‰ ì¤‘...")
            
            rag_system = st.session_state.rag_systems[system_name]
            
            try:
                if system_name == "Advanced RAG":
                    result = rag_system.query(query, k=retrieval_k*2, rerank_top_k=retrieval_k)
                elif system_name == "Modular RAG":
                    result = rag_system.query(query, max_iterations=2)
                else:
                    result = rag_system.query(query, k=retrieval_k)
                
                results.append(result)
                
                # Display individual result
                st.write(f"**ë‹µë³€:** {result['answer']}")
                st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {result['total_time']:.2f}ì´ˆ")
                
            except Exception as e:
                st.error(f"{system_name} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
                continue
            
            st.divider()
        
        # Store results
        if results:
            st.session_state.experiment_results = results
            st.success("âœ… ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")


def comparison_tab():
    """Comparison and analysis tab."""
    st.header("ğŸ“Š ê²°ê³¼ ë¹„êµ ë° ë¶„ì„")
    
    if not st.session_state.experiment_results:
        st.warning("ë¨¼ì € RAG ì‹¤í—˜ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    results = st.session_state.experiment_results
    
    # System information comparison
    if st.session_state.rag_systems:
        systems_info = []
        for system_name, rag_system in st.session_state.rag_systems.items():
            systems_info.append(rag_system.get_system_info())
        
        ComparisonUI.display_system_comparison(systems_info)
        st.divider()
    
    # Performance comparison
    ComparisonUI.display_performance_comparison(results)
    st.divider()
    
    # Answer comparison
    ComparisonUI.display_answer_comparison(results)
    st.divider()
    
    # Detailed metrics for each system
    for result in results:
        ComparisonUI.display_detailed_metrics(result)
        ComparisonUI.create_processing_flow_diagram(result["rag_type"])
        st.divider()
    
    # Summary report
    ComparisonUI.create_summary_report(results)


def about_tab():
    """About and documentation tab."""
    st.header("â„¹ï¸ RAG ì‹œìŠ¤í…œ ì†Œê°œ")
    
    st.markdown("""
    ## ğŸ¯ ì• í”Œë¦¬ì¼€ì´ì…˜ ëª©ì 
    
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì„¸ ê°€ì§€ ì£¼ìš” RAG (Retrieval-Augmented Generation) íŒ¨ëŸ¬ë‹¤ì„ì„ ë¹„êµí•˜ê³  ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤:
    
    ### 1. ğŸ“š Naive RAG
    - **íŠ¹ì§•**: ê°€ì¥ ê¸°ë³¸ì ì¸ RAG êµ¬í˜„
    - **êµ¬ì„±**: ë‹¨ìˆœ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ + ì§ì ‘ ìƒì„±
    - **ì¥ì **: ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„, ê°„ë‹¨í•œ êµ¬ì¡°
    - **ë‹¨ì **: ì œí•œëœ ê²€ìƒ‰ í’ˆì§ˆ, ì»¨í…ìŠ¤íŠ¸ ìµœì í™” ì—†ìŒ
    
    ### 2. ğŸ”§ Advanced RAG
    - **íŠ¹ì§•**: í–¥ìƒëœ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ ê¸°ë²• ì ìš©
    - **êµ¬ì„±**: ì¿¼ë¦¬ ìµœì í™” + ë¬¸ì„œ ì¬ìˆœìœ„í™” + ì»¨í…ìŠ¤íŠ¸ ì••ì¶•
    - **ì¥ì **: ë†’ì€ ê²€ìƒ‰ ì •í™•ë„, íš¨ìœ¨ì ì¸ ì»¨í…ìŠ¤íŠ¸ í™œìš©
    - **ë‹¨ì **: ë³µì¡í•œ êµ¬ì¡°, ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦° ì²˜ë¦¬
    
    ### 3. ğŸ§© Modular RAG
    - **íŠ¹ì§•**: ìœ ì—°í•œ ëª¨ë“ˆ ê¸°ë°˜ ì•„í‚¤í…ì²˜
    - **êµ¬ì„±**: ë…ë¦½ì  ëª¨ë“ˆë“¤ì˜ ì¡°í•©, ë°˜ë³µì  ê°œì„ 
    - **ì¥ì **: ë†’ì€ í™•ì¥ì„±, ìƒí™©ë³„ ìµœì í™”, íˆ¬ëª…í•œ ì²˜ë¦¬ ê³¼ì •
    - **ë‹¨ì **: ë³µì¡í•œ ì„¤ê³„, ë§ì€ ê³„ì‚° ë¦¬ì†ŒìŠ¤ í•„ìš”
    
    ## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ
    
    - **Frontend**: Streamlit
    - **LLM**: Ollama (Gemma 3 Models)
    - **Embeddings**: HuggingFace Multilingual E5
    - **Vector Store**: ChromaDB
    - **Framework**: LangChain, LangGraph
    - **Package Management**: pip/uv
    
    ## ğŸ“– ì‚¬ìš© ë°©ë²•
    
    1. **ë¬¸ì„œ ë¡œë”©**: PDF ë¬¸ì„œë“¤ì„ ë¡œë”©í•˜ê³  ì²­í¬ë¡œ ë¶„í• 
    2. **ë²¡í„° ìŠ¤í† ì–´ ìƒì„±**: ë¬¸ì„œ ì„ë² ë”© ìƒì„± ë° ì¸ë±ì‹±
    3. **RAG ì‹¤í—˜**: ë‹¤ì–‘í•œ RAG ì‹œìŠ¤í…œìœ¼ë¡œ ì§ˆë¬¸ ë‹µë³€ í…ŒìŠ¤íŠ¸
    4. **ê²°ê³¼ ë¹„êµ**: ì„±ëŠ¥, ì •í™•ë„, ì²˜ë¦¬ ì‹œê°„ ë“±ì„ ë¹„êµ ë¶„ì„
    
    ## ğŸ¨ UI íŠ¹ì§•
    
    - ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© í‘œì‹œ
    - ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
    - ì‹œê°ì  ë¹„êµ ì°¨íŠ¸
    - ìƒì„¸í•œ ì²˜ë¦¬ ê³¼ì • ë¡œê·¸
    - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€
    """)
    
    # Display system requirements
    st.subheader("âš™ï¸ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­")
    
    col1, col2 = st.columns(2)
    with col1:
        st.write("**í•„ìˆ˜ ìš”êµ¬ì‚¬í•­:**")
        st.write("â€¢ Python 3.11+")
        st.write("â€¢ Ollama ì„¤ì¹˜ ë° ì‹¤í–‰")
        st.write("â€¢ 4GB+ RAM")
        st.write("â€¢ 2GB+ ë””ìŠ¤í¬ ê³µê°„")
    
    with col2:
        st.write("**ê¶Œì¥ ì‚¬ì–‘:**")
        st.write("â€¢ 8GB+ RAM")
        st.write("â€¢ GPU ì§€ì› (ì„ íƒì‚¬í•­)")
        st.write("â€¢ SSD ì €ì¥ì¥ì¹˜")
        st.write("â€¢ ì•ˆì •ì ì¸ ì¸í„°ë„· ì—°ê²°")


def main():
    """Main application function."""
    # Apply custom font globally first (before any other UI elements)
    apply_custom_css()
    
    # Setup
    setup_page()
    initialize_session_state()
    setup_sidebar()
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“š ë¬¸ì„œ ë¡œë”©",
        "ğŸ” ë²¡í„° ìŠ¤í† ì–´",
        "ğŸ§ª RAG ì‹¤í—˜",
        "ğŸ“Š ê²°ê³¼ ë¹„êµ",
        "â„¹ï¸ ì†Œê°œ"
    ])
    
    with tab1:
        load_documents_tab()
    
    with tab2:
        create_vector_store_tab()
    
    with tab3:
        rag_experiment_tab()
    
    with tab4:
        comparison_tab()
    
    with tab5:
        about_tab()


if __name__ == "__main__":
    main()