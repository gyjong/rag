"""Main Streamlit application for RAG systems comparison."""

import streamlit as st
import os
from pathlib import Path
import base64

# Import our modules
from src.config import *
from src.utils.document_processor import DocumentProcessor
from src.utils.embeddings import EmbeddingManager
from src.utils.vector_store import VectorStoreManager
from src.utils.llm_manager import LLMManager
from src.utils.font_utils import apply_custom_css
from src.rag_systems.naive_rag import NaiveRAG
from src.rag_systems.advanced_rag import AdvancedRAG
from src.rag_systems.modular_rag import ModularRAG
from src.ui.comparison_ui import ComparisonUI


def load_custom_font():
    """Load custom font if available."""
    return apply_custom_css()


def initialize_session_state():
    """Initialize session state variables."""
    if "documents_loaded" not in st.session_state:
        st.session_state.documents_loaded = False
    if "vector_store_created" not in st.session_state:
        st.session_state.vector_store_created = False
    if "rag_systems" not in st.session_state:
        st.session_state.rag_systems = {}
    if "experiment_results" not in st.session_state:
        st.session_state.experiment_results = []
    if "documents" not in st.session_state:
        st.session_state.documents = []
    if "document_chunks" not in st.session_state:
        st.session_state.document_chunks = []


def setup_page():
    """Setup page configuration."""
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Apply custom font globally first
    font_loaded = apply_custom_css()
    
    # Display title with custom styling
    if font_loaded:
        st.markdown('<h1 class="main-title">ğŸ¤– RAG Systems Comparison Tool</h1>', unsafe_allow_html=True)
        st.markdown('<p class="subtitle">ë‹¨ê³„ë³„ Naive RAG, Advanced RAG, Modular RAG ë¹„êµ ì‹¤í—˜ ì• í”Œë¦¬ì¼€ì´ì…˜</p>', unsafe_allow_html=True)
    else:
        st.title("ğŸ¤– RAG Systems Comparison Tool")
        st.subheader("ë‹¨ê³„ë³„ Naive RAG, Advanced RAG, Modular RAG ë¹„êµ ì‹¤í—˜ ì• í”Œë¦¬ì¼€ì´ì…˜")


def setup_sidebar():
    """Setup sidebar with system information."""
    st.sidebar.title("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # Model Selection
    st.sidebar.subheader("ğŸ¤– ëª¨ë¸ ì„ íƒ")
    selected_model_name = st.sidebar.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ:",
        options=list(AVAILABLE_LLM_MODELS.keys()),
        index=list(AVAILABLE_LLM_MODELS.values()).index(DEFAULT_LLM_MODEL) if DEFAULT_LLM_MODEL in AVAILABLE_LLM_MODELS.values() else 0
    )
    selected_model = AVAILABLE_LLM_MODELS[selected_model_name]
    
    # LLM Temperature
    st.sidebar.subheader("ğŸ”¥ LLM Temperature")
    temperature = st.sidebar.slider(
        "Temperature (ì°½ì˜ì„±)", min_value=0.0, max_value=1.0, value=st.session_state.get("llm_temperature", 0.1), step=0.05
    )
    st.session_state.llm_temperature = temperature
    st.sidebar.write(f"í˜„ì¬ ê°’: {temperature}")
    
    # Vector Store Type
    st.sidebar.subheader("ğŸ—„ï¸ ë²¡í„° ìŠ¤í† ì–´ íƒ€ì…")
    vector_store_type = st.sidebar.radio(
        "Vector Store ì—”ì§„ ì„ íƒ:",
        options=["faiss", "chroma"],
        index=["faiss", "chroma"].index(st.session_state.get("vector_store_type", "faiss"))
    )
    st.session_state.vector_store_type = vector_store_type
    st.sidebar.write(f"í˜„ì¬ ì„ íƒ: {vector_store_type}")
    
    # Chunk Size
    st.sidebar.subheader("ğŸ”ª ì²­í¬ í¬ê¸° (Chunk Size)")
    chunk_size = st.sidebar.slider(
        "ì²­í¬ í¬ê¸°:", min_value=256, max_value=4096, value=st.session_state.get("chunk_size", CHUNK_SIZE), step=64
    )
    st.session_state.chunk_size = chunk_size
    st.sidebar.write(f"í˜„ì¬ ê°’: {chunk_size}")
    
    # Chunk Overlap
    st.sidebar.subheader("ğŸ”— ì²­í¬ ì˜¤ë²„ë© (Chunk Overlap)")
    chunk_overlap = st.sidebar.slider(
        "ì˜¤ë²„ë©:", min_value=0, max_value=1024, value=st.session_state.get("chunk_overlap", CHUNK_OVERLAP), step=16
    )
    st.session_state.chunk_overlap = chunk_overlap
    st.sidebar.write(f"í˜„ì¬ ê°’: {chunk_overlap}")
    
    # Top-K (ê²€ìƒ‰ ìˆ˜)
    st.sidebar.subheader("ğŸ” ê²€ìƒ‰ ìˆ˜ (Top-K)")
    top_k = st.sidebar.slider(
        "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜:", min_value=1, max_value=30, value=st.session_state.get("top_k", DEFAULT_K), step=1
    )
    st.session_state.top_k = top_k
    st.sidebar.write(f"í˜„ì¬ ê°’: {top_k}")
    
    # Store selected model in session state
    if "selected_llm_model" not in st.session_state:
        st.session_state.selected_llm_model = selected_model
    elif st.session_state.selected_llm_model != selected_model:
        st.session_state.selected_llm_model = selected_model
        # Clear cached LLM when model changes
        if "llm_manager" in st.session_state:
            del st.session_state.llm_manager
    
    # LLM Status
    st.sidebar.subheader("ğŸ§  LLM ìƒíƒœ")
    llm_manager = LLMManager(st.session_state.selected_llm_model, OLLAMA_BASE_URL, temperature=st.session_state.llm_temperature)
    llm_info = llm_manager.get_model_info()
    
    if llm_info["connection_status"]:
        st.sidebar.success("âœ… Ollama ì„œë²„ ì—°ê²°ë¨")
        if llm_info["model_available"]:
            st.sidebar.success(f"âœ… ëª¨ë¸ '{st.session_state.selected_llm_model}' ì‚¬ìš© ê°€ëŠ¥")
        else:
            st.sidebar.error(f"âŒ ëª¨ë¸ '{st.session_state.selected_llm_model}' ì—†ìŒ")
            if st.sidebar.button("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"):
                with st.spinner("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                    if llm_manager.pull_model():
                        st.sidebar.success("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                        st.rerun()
                    else:
                        st.sidebar.error("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
    else:
        st.sidebar.error("âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
        st.sidebar.code(f"ollama serve")
    
    # Document Status
    st.sidebar.subheader("ğŸ“š ë¬¸ì„œ ìƒíƒœ")
    if st.session_state.documents_loaded:
        st.sidebar.success(f"âœ… {len(st.session_state.documents)}ê°œ ë¬¸ì„œ ë¡œë”©ë¨")
        st.sidebar.success(f"âœ… {len(st.session_state.document_chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
    else:
        st.sidebar.warning("âš ï¸ ë¬¸ì„œê°€ ë¡œë”©ë˜ì§€ ì•ŠìŒ")
    
    # Vector Store Status
    if st.session_state.vector_store_created:
        st.sidebar.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„±ë¨")
    else:
        st.sidebar.warning("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ ë¯¸ìƒì„±")
    
    # Configuration
    st.sidebar.subheader("ğŸ”§ ì„¤ì •")
    st.sidebar.write(f"**ì„ë² ë”© ëª¨ë¸:** {EMBEDDING_MODEL}")
    st.sidebar.write(f"**ì²­í¬ í¬ê¸°:** {chunk_size}")
    st.sidebar.write(f"**ì²­í¬ ì˜¤ë²„ë©:** {chunk_overlap}")
    st.sidebar.write(f"**ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜:** {top_k}")


def load_documents_tab():
    """Document loading tab."""
    st.header("ğŸ“š ë¬¸ì„œ ë¡œë”© ë° ì „ì²˜ë¦¬")
    
    # Document folder info
    st.info(f"ë¬¸ì„œ í´ë”: {DOCS_FOLDER}")
    
    if not DOCS_FOLDER.exists():
        st.error(f"ë¬¸ì„œ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {DOCS_FOLDER}")
        return
    
    # List available documents
    pdf_files = list(DOCS_FOLDER.glob("*.pdf"))
    st.write(f"ì‚¬ìš© ê°€ëŠ¥í•œ PDF íŒŒì¼ ({len(pdf_files)}ê°œ):")
    for pdf_file in pdf_files:
        file_size = pdf_file.stat().st_size / (1024 * 1024)  # MB
        st.write(f"â€¢ {pdf_file.name} ({file_size:.1f} MB)")
    
    # Load documents button
    if st.button("ğŸ“– ë¬¸ì„œ ë¡œë”© ì‹œì‘", type="primary"):
        if not pdf_files:
            st.warning("PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # Initialize document processor
        doc_processor = DocumentProcessor(st.session_state.chunk_size, st.session_state.chunk_overlap)
        
        # Load documents
        documents = doc_processor.load_documents_from_folder(DOCS_FOLDER)
        
        if documents:
            st.session_state.documents = documents
            
            # Display document statistics
            stats = doc_processor.get_document_stats(documents)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ë¬¸ì„œ ìˆ˜", stats["total_documents"])
            with col2:
                st.metric("ì´ ë¬¸ì ìˆ˜", f"{stats['total_characters']:,}")
            with col3:
                st.metric("í‰ê·  ë¬¸ì/ë¬¸ì„œ", f"{stats['average_chars_per_doc']:,.0f}")
            
            # Split documents
            chunks = doc_processor.split_documents(documents)
            st.session_state.document_chunks = chunks
            st.session_state.documents_loaded = True
            
            st.success("âœ… ë¬¸ì„œ ë¡œë”© ë° ì „ì²˜ë¦¬ ì™„ë£Œ!")
        else:
            st.error("ë¬¸ì„œ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # Display loaded documents info
    if st.session_state.documents_loaded:
        st.subheader("ğŸ“‹ ë¡œë”©ëœ ë¬¸ì„œ ì •ë³´")
        
        # Document chunks preview
        with st.expander("ë¬¸ì„œ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°"):
            if st.session_state.document_chunks:
                chunk = st.session_state.document_chunks[0]
                st.write(f"**ì²« ë²ˆì§¸ ì²­í¬ (ID: {chunk.metadata.get('chunk_id', 'N/A')}):**")
                st.write(f"**ì¶œì²˜:** {chunk.metadata.get('source', 'Unknown')}")
                st.write(f"**í¬ê¸°:** {len(chunk.page_content)} ë¬¸ì")
                st.write(f"**ë‚´ìš©:**")
                st.write(chunk.page_content[:500] + "..." if len(chunk.page_content) > 500 else chunk.page_content)


def create_vector_store_tab():
    """Vector store creation tab."""
    st.header("ğŸ” ë²¡í„° ìŠ¤í† ì–´ ìƒì„±")
    
    if not st.session_state.documents_loaded:
        st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë”©í•´ì£¼ì„¸ìš”.")
        return
    
    st.info(f"ì„ë² ë”© ëª¨ë¸: {EMBEDDING_MODEL}")
    
    # Create vector store button
    if st.button("ğŸš€ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±", type="primary"):
        try:
            # Initialize embedding manager with models folder
            embedding_manager = EmbeddingManager(EMBEDDING_MODEL, MODELS_FOLDER)
            embeddings = embedding_manager.get_embeddings()
            
            # Display embedding model info
            embed_info = embedding_manager.get_model_info()
            st.write("**ì„ë² ë”© ëª¨ë¸ ì •ë³´:**")
            for key, value in embed_info.items():
                st.write(f"â€¢ {key}: {value}")
            
            # Create vector store (use selected type)
            vector_store_type = st.session_state.get("vector_store_type", "faiss")
            vector_store_manager = VectorStoreManager(embeddings, vector_store_type)
            vector_store = vector_store_manager.create_vector_store(st.session_state.document_chunks)
            
            # Store in session state
            st.session_state.vector_store_manager = vector_store_manager
            st.session_state.embedding_manager = embedding_manager
            st.session_state.vector_store_created = True
            
            # Display collection stats
            stats = vector_store_manager.get_collection_stats()
            st.write("**ë²¡í„° ìŠ¤í† ì–´ í†µê³„:**")
            for key, value in stats.items():
                st.write(f"â€¢ {key}: {value}")
            
            st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
            
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    # Test search functionality
    if st.session_state.vector_store_created:
        st.subheader("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        test_query = st.text_input("í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: AI íŠ¸ë Œë“œ")
        
        if test_query and st.button("ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"):
            vector_store_manager = st.session_state.vector_store_manager
            try:
                docs = vector_store_manager.similarity_search(test_query, k=st.session_state.top_k)
                st.write(f"**ê²€ìƒ‰ ê²°ê³¼ ({len(docs)}ê°œ):**")
                
                for i, doc in enumerate(docs):
                    with st.expander(f"ë¬¸ì„œ {i+1}: {doc.metadata.get('source', 'Unknown')}"):
                        st.write(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                        
            except Exception as e:
                st.error(f"ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")


def rag_experiment_tab():
    """RAG experiment tab."""
    st.header("ğŸ§ª RAG ì‹œìŠ¤í…œ ì‹¤í—˜")
    
    if not st.session_state.vector_store_created:
        st.warning("ë¨¼ì € ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # Initialize RAG systems if not already done
    if not st.session_state.rag_systems:
        vector_store_manager = st.session_state.vector_store_manager
        selected_model = st.session_state.get("selected_llm_model", DEFAULT_LLM_MODEL)
        llm_temperature = st.session_state.get("llm_temperature", 0.1)
        llm_manager = LLMManager(selected_model, OLLAMA_BASE_URL, temperature=llm_temperature)
        
        st.session_state.rag_systems = {
            "Naive RAG": NaiveRAG(vector_store_manager, llm_manager),
            "Advanced RAG": AdvancedRAG(vector_store_manager, llm_manager),
            "Modular RAG": ModularRAG(vector_store_manager, llm_manager)
        }
    
    # System selection
    st.subheader("ğŸ¯ ì‹¤í—˜ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    with col1:
        selected_systems = st.multiselect(
            "í…ŒìŠ¤íŠ¸í•  RAG ì‹œìŠ¤í…œ ì„ íƒ:",
            list(st.session_state.rag_systems.keys()),
            default=list(st.session_state.rag_systems.keys())
        )
    
    with col2:
        retrieval_k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (k):", 1, 15, st.session_state.top_k)
    
    # Sample queries - ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ìš© ë‹¤ì–‘í•œ ìœ í˜•
    st.write("**ìƒ˜í”Œ ì§ˆë¬¸ (ì§ˆë¬¸ ìœ í˜•ë³„):**")
    sample_queries = [
        "2025ë…„ AI íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",                    # factual
        "ì§ì¥ì—ì„œ AIë¥¼ ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆë‚˜ìš”?",            # procedural
        "ì™œ AIê°€ ì—…ë¬´ ìƒì‚°ì„±ì— ì¤‘ìš”í•œê°€ìš”?",                # causal
        "AI ê¸°ìˆ ì€ ì–¸ì œë¶€í„° ë°œì „í•˜ê¸° ì‹œì‘í–ˆë‚˜ìš”?",          # temporal
        "ìƒì„±í˜• AIì™€ ê¸°ì¡´ AIì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",        # comparative
        "AI ì‹œì¥ ê·œëª¨ëŠ” ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",                   # quantitative
        "ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",                     # general
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì€?",                # procedural
        "AI ê°œë°œì—ëŠ” ì–´ë–¤ ë¹„ìš©ì´ ë“œë‚˜ìš”?",                 # quantitative
        "ë”¥ëŸ¬ë‹ì´ ì£¼ëª©ë°›ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"              # causal
    ]
    
    # Display categorized sample questions
    st.write("**ğŸ·ï¸ ì§ˆë¬¸ ìœ í˜• ì˜ˆì‹œ:**")
    st.markdown("""
    - **ì‚¬ì‹¤í˜•(factual)**: "ë¬´ì—‡", "ì–´ë–¤" â†’ ì •í™•í•œ ì •ë³´ ìœ„ì£¼
    - **ë°©ë²•í˜•(procedural)**: "ì–´ë–»ê²Œ", "ë°©ë²•" â†’ ë‹¨ê³„ë³„ ì„¤ëª…  
    - **ì›ì¸í˜•(causal)**: "ì™œ", "ì´ìœ " â†’ ë…¼ë¦¬ì  ë¶„ì„
    - **ì‹œê°„í˜•(temporal)**: "ì–¸ì œ", "ì‹œì " â†’ ì‹œê°„ìˆœ ì •ë¦¬
    - **ë¹„êµí˜•(comparative)**: "ì°¨ì´", "ë¹„êµ" â†’ ë¹„êµ ë¶„ì„
    - **ìˆ˜ì¹˜í˜•(quantitative)**: "ì–¼ë§ˆ", "ê·œëª¨" â†’ ë°ì´í„° ê¸°ë°˜
    - **ì¼ë°˜í˜•(general)**: ê¸°íƒ€ â†’ ì¢…í•©ì  ì„¤ëª…
    """)
    
    st.write("**ğŸ“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ëª©ë¡:**")
    
    # Sample query types for reference
    query_types = ["factual", "procedural", "causal", "temporal", "comparative", "quantitative", "general", "procedural", "quantitative", "causal"]
    
    cols = st.columns(2)
    for i, sample_query in enumerate(sample_queries):
        col = cols[i % 2]
        query_type = query_types[i] if i < len(query_types) else "general"
        type_emoji = {
            "factual": "ğŸ¯", "procedural": "ğŸ“‹", "causal": "ğŸ¤”", 
            "temporal": "â°", "comparative": "âš–ï¸", "quantitative": "ğŸ“Š", "general": "ğŸ“–"
        }
        emoji = type_emoji.get(query_type, "ğŸ“")
        
        if col.button(f"{emoji} {sample_query}", key=f"sample_{i}", help=f"ì§ˆë¬¸ ìœ í˜•: {query_type}"):
            st.session_state.text_area_value = sample_query
            st.rerun()
    
    # Query input - ìƒ˜í”Œ ì§ˆë¬¸ ì„ íƒ ì‹œ í•´ë‹¹ ì§ˆë¬¸ì´ ì…ë ¥ì°½ì— í‘œì‹œë¨
    query = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        value=st.session_state.get("text_area_value", ""),
        placeholder="ì˜ˆ: 2025ë…„ AI íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        height=100,
        key="query_input"
    )
    
    # Run experiment
    if query and selected_systems and st.button("ğŸš€ ì‹¤í—˜ ì‹¤í–‰", type="primary"):
        results = []
        
        for system_name in selected_systems:
            st.write(f"## {system_name} ì‹¤í–‰ ì¤‘...")
            
            rag_system = st.session_state.rag_systems[system_name]
            
            try:
                if system_name == "Advanced RAG":
                    result = rag_system.query(query, k=retrieval_k*2, rerank_top_k=retrieval_k)
                elif system_name == "Modular RAG":
                    result = rag_system.query(query, max_iterations=2)
                else:
                    result = rag_system.query(query, k=retrieval_k)
                
                results.append(result)
                
                # Display individual result
                st.write(f"**ë‹µë³€:** {result['answer']}")
                st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {result['total_time']:.2f}ì´ˆ")
                
            except Exception as e:
                st.error(f"{system_name} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
                continue
            
            st.divider()
        
        # Store results
        if results:
            st.session_state.experiment_results = results
            st.success("âœ… ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")


def comparison_tab():
    """Comparison and analysis tab."""
    st.header("ğŸ“Š ê²°ê³¼ ë¹„êµ ë° ë¶„ì„")
    
    if not st.session_state.experiment_results:
        st.warning("ë¨¼ì € RAG ì‹¤í—˜ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    results = st.session_state.experiment_results
    
    # System information comparison
    if st.session_state.rag_systems:
        systems_info = []
        for system_name, rag_system in st.session_state.rag_systems.items():
            systems_info.append(rag_system.get_system_info())
        
        ComparisonUI.display_system_comparison(systems_info)
        st.divider()
    
    # Performance comparison
    ComparisonUI.display_performance_comparison(results)
    st.divider()
    
    # Answer comparison
    ComparisonUI.display_answer_comparison(results)
    st.divider()
    
    # Detailed metrics for each system
    for result in results:
        ComparisonUI.display_detailed_metrics(result)
        ComparisonUI.create_processing_flow_diagram(result["rag_type"])
        st.divider()
    
    # Summary report
    ComparisonUI.create_summary_report(results)


def about_tab():
    """About and documentation tab."""
    st.header("â„¹ï¸ RAG ì‹œìŠ¤í…œ ì†Œê°œ")
    
    st.markdown("""
    ## ğŸ¯ ì• í”Œë¦¬ì¼€ì´ì…˜ ëª©ì 
    
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ **ìµœì‹  RAG ê¸°ìˆ ì„ í™œìš©í•œ** ì„¸ ê°€ì§€ ì°¨ë³„í™”ëœ RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ 
    ì§ì ‘ ë¹„êµí•˜ê³  ì‹¤í—˜í•  ìˆ˜ ìˆëŠ” **ì¢…í•© ë²¤ì¹˜ë§ˆí‚¹ í”Œë«í¼**ì…ë‹ˆë‹¤.
    """)
    
    # Create detailed system comparison
    with st.expander("ğŸ“š **Naive RAG** - ê¸°ë³¸í˜• ì‹œìŠ¤í…œ", expanded=True):
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown("""
            ### ğŸ”§ **êµ¬ì„±**
            - **ê²€ìƒ‰**: ë‹¨ìˆœ ë²¡í„° ìœ ì‚¬ë„ (Dense Retrieval)
            - **ìƒì„±**: ì§ì ‘ LLM í˜¸ì¶œ
            - **ìµœì í™”**: ì—†ìŒ
            
            ### âœ¨ **íŠ¹ì§•**
            - âš¡ **ì´ˆê³ ì† ì²˜ë¦¬**: ìµœì†Œí•œì˜ ì˜¤ë²„í—¤ë“œ
            - ğŸ¯ **ë‹¨ìˆœí•¨**: ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°
            - ğŸ“¦ **ê²½ëŸ‰í™”**: ìµœì†Œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©
            """)
        with col2:
            st.info("**âš¡ ì†ë„ ìš°ì„ **\n\në¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì´ë‚˜ \nì‹¤ì‹œê°„ ì‘ë‹µì´ í•„ìš”í•œ \ní™˜ê²½ì— ìµœì í™”")
    
    with st.expander("ğŸ”§ **Advanced RAG** - Enhanced Search ì‹œìŠ¤í…œ", expanded=True):
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown("""
            ### ğŸ”§ **Enhanced Search êµ¬ì„±**
            - **1ë‹¨ê³„**: ğŸ” ì¿¼ë¦¬ ì „ì²˜ë¦¬ & ìµœì í™”
            - **2ë‹¨ê³„**: ğŸ§  ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (í™•ì¥ ë²”ìœ„)
            - **3ë‹¨ê³„**: ğŸ”€ **í•˜ì´ë¸Œë¦¬ë“œ ì¬ìˆœìœ„í™”**
              - TF-IDF ì ìˆ˜ (70%) + ë²¡í„° ìœ ì‚¬ë„ (30%)
            - **4ë‹¨ê³„**: ğŸ“¦ **ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ì••ì¶•**
              - í‚¤ì›Œë“œ ê¸°ë°˜ ì¤‘ìš”ë„ ìŠ¤ì½”ì–´ë§
              - ë™ì  ê¸¸ì´ ì¡°ì ˆ
            - **5ë‹¨ê³„**: ğŸ¤– **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±**
            
            ### âœ¨ **í•µì‹¬ í˜ì‹ **
            - ğŸ”€ **í•˜ì´ë¸Œë¦¬ë“œ ì¬ìˆœìœ„í™”**: ì˜ë¯¸ì  + í†µê³„ì  ê²€ìƒ‰ ê²°í•©
            - ğŸ“¦ **ì§€ëŠ¥í˜• ì••ì¶•**: ì¤‘ìš” ì •ë³´ ë³´ì¡´í•˜ë©° í† í° íš¨ìœ¨í™”
            - âš¡ **ìŠ¤íŠ¸ë¦¬ë°**: ì‹¤ì‹œê°„ ë‹µë³€ ìƒì„± ë° í‘œì‹œ
            """)
        with col2:
            st.success("**ğŸ“¦ ê· í˜• ìµœì í™”**\n\nì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì˜ \nì™„ë²½í•œ ë°¸ëŸ°ìŠ¤ë¥¼ \nì¶”êµ¬í•˜ëŠ” ì‹œìŠ¤í…œ")
    
    with st.expander("ğŸ§© **Modular RAG** - ì§€ëŠ¥í˜• ëª¨ë“ˆëŸ¬ ì‹œìŠ¤í…œ", expanded=True):
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown("""
            ### ğŸ§  **Pre-Retrieval Modules**
            - **ğŸ¯ Query Classification**: 7ê°€ì§€ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
              - factual(ì‚¬ì‹¤í˜•), procedural(ë°©ë²•í˜•), causal(ì›ì¸í˜•)
              - temporal(ì‹œê°„í˜•), comparative(ë¹„êµí˜•), quantitative(ìˆ˜ì¹˜í˜•), general(ì¼ë°˜í˜•)
            - **ğŸ” Query Expansion**: í‚¤ì›Œë“œ ë§¤í•‘ ê¸°ë°˜ í™•ì¥
            
            ### ğŸ” **Retrieval Modules**
            - **ğŸ§  Semantic Retrieval**: Dense ë²¡í„° ê²€ìƒ‰
            - **ğŸ”¤ BM25 Keyword Retrieval**: Sparse í‚¤ì›Œë“œ ê²€ìƒ‰
              - ë…ë¦½ì ì¸ BM25 êµ¬í˜„ (k1=1.5, b=0.75)
              - í•œêµ­ì–´ í† í¬ë‚˜ì´ì§• ì§€ì›
            
            ### ğŸ”§ **Post-Retrieval Modules**
            - **ğŸ“Š Relevance Filtering**: ê´€ë ¨ë„ ê¸°ë°˜ í•„í„°ë§
            - **ğŸ² Diversity Module**: ì¤‘ë³µ ì œê±° ë° ë‹¤ì–‘ì„± ë³´ì¥
            
            ### ğŸ¤– **Generation Modules**
            - **ğŸ¯ Type-Specific Generation**: ì§ˆë¬¸ ìœ í˜•ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸
            - **ğŸ“Š Confidence Estimation**: ë‹µë³€ ì‹ ë¢°ë„ í‰ê°€
            
            ### ğŸ”„ **Orchestration Modules**
            - **ğŸ›¤ï¸ Routing**: ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì  ì²˜ë¦¬ ê²½ë¡œ ì„ íƒ
            - **ğŸ”„ Iteration Control**: ì‹ ë¢°ë„ ê¸°ë°˜ ë°˜ë³µ ê°œì„  (< 0.7ì‹œ ì¬ì‹œë„)
            """)
        with col2:
            st.warning("**ğŸ¯ ì •ë°€ ìµœì í™”**\n\në³µì¡í•œ ì§ˆë¬¸ê³¼ \në†’ì€ ì •í™•ì„±ì´ \nìš”êµ¬ë˜ëŠ” ê³ ê¸‰ ìš©ë„")
    
    st.markdown("---")
    
    # Technical innovations section
    st.markdown("""
    ## ğŸš€ **ê¸°ìˆ ì  í˜ì‹ ì‚¬í•­**
    
    ### ğŸ”€ **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Advanced & Modular)**
    - **Dense + Sparse ê²°í•©**: ì˜ë¯¸ì  ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ë§¤ì¹­ì˜ ì‹œë„ˆì§€
    - **ë™ì  ê°€ì¤‘ì¹˜**: TF-IDF 70% + ë²¡í„° ìœ ì‚¬ë„ 30% ìµœì  ë¹„ìœ¨
    - **BM25 ì™„ì „ êµ¬í˜„**: ì™¸ë¶€ ì˜ì¡´ì„± ì—†ëŠ” ìˆœìˆ˜ Python êµ¬í˜„
    
    ### ğŸ¯ **ì§€ëŠ¥í˜• ì§ˆë¬¸ ë¶„ë¥˜ (Modular)**
    - **7ê°€ì§€ ì§ˆë¬¸ ìœ í˜•**: ì„¸ë°€í•œ ì˜ë„ íŒŒì•… ë° ë§ì¶¤ ì²˜ë¦¬
    - **ë™ì  ì‹ ë¢°ë„ ê³„ì‚°**: ë§¤ì¹­ í‚¤ì›Œë“œ íŒ¨í„´ ë¶„ì„
    - **ì‹œê°í™” ì§€ì›**: ë¶„ë¥˜ ê³¼ì •ì˜ íˆ¬ëª…í•œ í‘œì‹œ
    
    ### ğŸ“¦ **ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ (Advanced)**
    - **í‚¤ì›Œë“œ ê¸°ë°˜ ì••ì¶•**: ì¤‘ìš” ë¬¸ì¥ ìë™ ì¶”ì¶œ
    - **ë™ì  ê¸¸ì´ ì¡°ì ˆ**: ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¥¸ ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ìµœì í™”
    - **í† í° íš¨ìœ¨ì„±**: ìµœëŒ€ 50% ì••ì¶•ë¥ ë¡œ ë¹„ìš© ì ˆê°
    
    ### ğŸ”„ **ë°˜ë³µì  ê°œì„  (Modular)**
    - **ì‹ ë¢°ë„ ì„ê³„ê°’**: 0.7 ë¯¸ë§Œì‹œ ìë™ ì¬ì‹œë„
    - **ë§¤ê°œë³€ìˆ˜ ì¡°ì •**: ê²€ìƒ‰ ë²”ìœ„ ë™ì  í™•ëŒ€ (k â†’ k+2)
    - **ìµœëŒ€ ë°˜ë³µ ì œí•œ**: ë¬´í•œ ë£¨í”„ ë°©ì§€
    """)
    
    st.markdown("---")
    
    # Enhanced tech stack
    st.markdown("""
    ## ğŸ› ï¸ **ê³ ê¸‰ ê¸°ìˆ  ìŠ¤íƒ**
    
    ### ğŸ§  **AI/ML ì½”ì–´**
    - **LLM**: Ollama Gemma 3 (1B~27B, QAT ìµœì í™”)
    - **Embeddings**: Multilingual E5-Large-Instruct (ë‹¤êµ­ì–´ ì§€ì›)
    - **ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜**: 
      - Dense Retrieval (FAISS/ChromaDB)
      - BM25 Sparse Retrieval (ìˆœìˆ˜ êµ¬í˜„)
      - TF-IDF í†µê³„ ë¶„ì„
    
    ### ğŸ”§ **í”„ë ˆì„ì›Œí¬ & ë„êµ¬**
    - **Frontend**: Streamlit (ì‹¤ì‹œê°„ UI)
    - **Backend**: LangChain + ì»¤ìŠ¤í…€ ëª¨ë“ˆ
    - **ë²¡í„° DB**: ChromaDB (ì˜êµ¬ ì €ì¥)
    - **ì‹œê°í™”**: Plotly (ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸)
    - **í°íŠ¸**: Paperlogy (ì»¤ìŠ¤í…€ ë””ìì¸)
    
    ### ğŸ“Š **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**
    - **ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­**: ì²˜ë¦¬ ì‹œê°„, ê²€ìƒ‰ ì ìˆ˜, ì‹ ë¢°ë„
    - **ìƒì„¸ ë¶„ì„**: ê²€ìƒ‰ ì ìˆ˜ ë¶„í¬, ì••ì¶•ë¥ , ë°˜ë³µ íšŸìˆ˜
    - **ë¹„êµ ì‹œê°í™”**: ì‹œìŠ¤í…œë³„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹
    """)
    
    st.markdown("---")
    
    # Usage guide
    st.markdown("""
    ## ğŸ“– **ë‹¨ê³„ë³„ ì‚¬ìš© ê°€ì´ë“œ**
    
    ### ğŸ¯ **ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì  ì‹œìŠ¤í…œ ì„ íƒ**
    """)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info("""
        **âš¡ Naive RAG**
        
        âœ… **ì í•©í•œ ê²½ìš°:**
        - ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
        - ì‹¤ì‹œê°„ ì‘ë‹µ í•„ìš”
        - ë‹¨ìˆœí•œ ì •ë³´ ì¡°íšŒ
        - ë¦¬ì†ŒìŠ¤ ì œì•½ í™˜ê²½
        
        ğŸ“ **ì˜ˆì‹œ ì§ˆë¬¸:**
        - "AIë€ ë¬´ì—‡ì¸ê°€ìš”?"
        - "í˜„ì¬ íŠ¸ë Œë“œëŠ”?"
        """)
    
    with col2:
        st.success("""
        **ğŸ“¦ Advanced RAG**
        
        âœ… **ì í•©í•œ ê²½ìš°:**
        - ì •í™•ì„±ê³¼ ì†ë„ ê· í˜•
        - ì¤‘ê¸‰ ë³µì¡ë„ ì§ˆë¬¸
        - íš¨ìœ¨ì  í† í° ì‚¬ìš©
        - ë¹„ìš© ìµœì í™” í•„ìš”
        
        ğŸ“ **ì˜ˆì‹œ ì§ˆë¬¸:**
        - "AIê°€ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?"
        - "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ?"
        """)
    
    with col3:
        st.warning("""
        **ğŸ¯ Modular RAG**
        
        âœ… **ì í•©í•œ ê²½ìš°:**
        - ë³µì¡í•œ ë¶„ì„ ì§ˆë¬¸
        - ìµœê³  ì •í™•ë„ ìš”êµ¬
        - ë‹¤ì–‘í•œ ì§ˆë¬¸ ìœ í˜•
        - ìƒì„¸í•œ í”„ë¡œì„¸ìŠ¤ ì¶”ì 
        
        ğŸ“ **ì˜ˆì‹œ ì§ˆë¬¸:**
        - "AI ë„ì… ì „ëµì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        - "2025ë…„ê³¼ 2024ë…„ AI íŠ¸ë Œë“œë¥¼ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”"
        """)
    
    st.markdown("""
    ### ğŸš€ **ì‹¤í—˜ ì§„í–‰ ë‹¨ê³„**
    
    1. **ğŸ“š ë¬¸ì„œ ë¡œë”©** â†’ PDF ë¬¸ì„œ ìë™ íŒŒì‹± ë° ì²­í¬ ë¶„í• 
    2. **ğŸ” ë²¡í„° ìŠ¤í† ì–´** â†’ ì„ë² ë”© ìƒì„± ë° ì¸ë±ìŠ¤ êµ¬ì¶•  
    3. **ğŸ§ª RAG ì‹¤í—˜** â†’ ì‹œìŠ¤í…œë³„ ì§ˆë¬¸ ì²˜ë¦¬ ë° ë‹µë³€ ìƒì„±
    4. **ğŸ“Š ê²°ê³¼ ë¹„êµ** â†’ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¶„ì„ ë° ì‹œê°í™”
    
    ### ğŸ¨ **ê³ ê¸‰ UI ê¸°ëŠ¥**
    
    - **ğŸ¯ ì§ˆë¬¸ ìœ í˜• ê°€ì´ë“œ**: 10ê°€ì§€ ìƒ˜í”Œ ì§ˆë¬¸ (ìœ í˜•ë³„ ë¶„ë¥˜)
    - **ğŸ“Š ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­**: ì²˜ë¦¬ ì‹œê°„, ì‹ ë¢°ë„, ê²€ìƒ‰ ì ìˆ˜
    - **ğŸ” ìƒì„¸ ë¶„ì„**: ê²€ìƒ‰ ê³¼ì • ì‹œê°í™”, ì ìˆ˜ ë¶„í¬ ì°¨íŠ¸
    - **âš¡ ìŠ¤íŠ¸ë¦¬ë°**: Advanced RAG ì‹¤ì‹œê°„ ë‹µë³€ ìƒì„±
    - **ğŸ”„ í”„ë¡œì„¸ìŠ¤ ì¶”ì **: Modular RAG ëª¨ë“ˆë³„ ì²˜ë¦¬ ê³¼ì •
    """)
    
    st.markdown("---")
    
    # System requirements
    st.subheader("âš™ï¸ **ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­**")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        ### ğŸ“‹ **í•„ìˆ˜ ìš”êµ¬ì‚¬í•­**
        - **Python**: 3.11+ (Poetry ê¶Œì¥)
        - **Ollama**: ì„¤ì¹˜ ë° ì‹¤í–‰ ì¤‘
        - **RAM**: 4GB+ (BM25 ì¸ë±ì‹±ìš©)
        - **Storage**: 2GB+ (ëª¨ë¸ ë° ë²¡í„° ì €ì¥)
        - **Models**: Gemma 3 ë‹¤ìš´ë¡œë“œ í•„ìš”
        
        ### ğŸš€ **ê¶Œì¥ ì‚¬ì–‘ (ê³ ì„±ëŠ¥)**
        - **RAM**: 8GB+ (ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬)
        - **GPU**: CUDA ì§€ì› (ì„ íƒì‚¬í•­)
        - **SSD**: ë¹ ë¥¸ ë²¡í„° ê²€ìƒ‰
        - **Network**: ì•ˆì •ì  ì—°ê²° (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ)
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ”§ **ì„¤ì¹˜ ëª…ë ¹ì–´**
        ```bash
        # Ollama ì„¤ì¹˜ (macOS)
        brew install ollama
        
        # Gemma 3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        ollama pull gemma3:4b-it-qat
        ollama pull gemma3:12b-it-qat
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
        poetry install
        poetry run streamlit run app.py
        ```
        
        ### ğŸ“Š **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**
        - **Naive RAG**: ~1-2ì´ˆ (ê²½ëŸ‰)
        - **Advanced RAG**: ~3-5ì´ˆ (ê· í˜•)  
        - **Modular RAG**: ~5-8ì´ˆ (ì •ë°€)
        
        *Gemma 3 4B ëª¨ë¸ ê¸°ì¤€
        """)
    
    st.markdown("---")
    
    # Footer
    st.markdown("""
    ## ğŸ‰ **ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê°€ì¹˜**
    
    ğŸ“š **êµìœ¡ì  ê°€ì¹˜**: RAG ê¸°ìˆ ì˜ ë°œì „ ê³¼ì •ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì²´í—˜  
    ğŸ”¬ **ì—°êµ¬ ë„êµ¬**: ë‹¤ì–‘í•œ RAG ì ‘ê·¼ë²•ì˜ ì„±ëŠ¥ ë¹„êµ ë¶„ì„  
    âš¡ **ì‹¤ìš©ì„±**: ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ í™˜ê²½ì—ì„œì˜ RAG ì‹œìŠ¤í…œ ì„ íƒ ê°€ì´ë“œ  
    ğŸš€ **í˜ì‹ ì„±**: ìµœì‹  RAG ê¸°ìˆ ë“¤ì˜ ì‹¤ì œ êµ¬í˜„ ë° ë²¤ì¹˜ë§ˆí‚¹  
    
    > **"ë‹¨ìˆœí•œ ë²¡í„° ê²€ìƒ‰ë¶€í„° ê³ ë„í™”ëœ ëª¨ë“ˆëŸ¬ ì•„í‚¤í…ì²˜ê¹Œì§€,  
    > RAG ê¸°ìˆ ì˜ ëª¨ë“  ê²ƒì„ í•œ ê³³ì—ì„œ ê²½í—˜í•´ë³´ì„¸ìš”!"**
    """)
    
    # Fun stats
    with st.expander("ğŸ“Š **êµ¬í˜„ í†µê³„**"):
        st.markdown("""
        - ğŸ§© **ì´ ëª¨ë“ˆ ìˆ˜**: 12ê°œ (Modular RAG)
        - ğŸ¯ **ì§ˆë¬¸ ë¶„ë¥˜**: 7ê°€ì§€ ìœ í˜•
        - ğŸ” **ê²€ìƒ‰ ë°©ë²•**: 3ê°€ì§€ (Dense, Sparse, Hybrid)
        - ğŸ“Š **ì„±ëŠ¥ ë©”íŠ¸ë¦­**: 15+ ì§€í‘œ
        - âš¡ **ìµœì í™” ê¸°ë²•**: 5ê°€ì§€ (ì••ì¶•, ì¬ìˆœìœ„í™”, ë°˜ë³µ ë“±)
        - ğŸ¨ **UI ì»´í¬ë„ŒíŠ¸**: 20+ ì¸í„°ë™í‹°ë¸Œ ìš”ì†Œ
        """)
    
    st.balloons()  # ì†Œê°œ íƒ­ ë°©ë¬¸ ì¶•í•˜! ğŸ‰


def main():
    """Main application function."""
    # Apply custom font globally first (before any other UI elements)
    apply_custom_css()
    
    # Setup
    setup_page()
    initialize_session_state()
    setup_sidebar()
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“š ë¬¸ì„œ ë¡œë”©",
        "ğŸ” ë²¡í„° ìŠ¤í† ì–´",
        "ğŸ§ª RAG ì‹¤í—˜",
        "ğŸ“Š ê²°ê³¼ ë¹„êµ",
        "â„¹ï¸ ì†Œê°œ"
    ])
    
    with tab1:
        load_documents_tab()
    
    with tab2:
        create_vector_store_tab()
    
    with tab3:
        rag_experiment_tab()
    
    with tab4:
        comparison_tab()
    
    with tab5:
        about_tab()


if __name__ == "__main__":
    main()